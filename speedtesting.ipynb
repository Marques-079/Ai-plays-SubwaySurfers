{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a8b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "Benchmarking 312 frames from: /Users/marcus/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
      "\n",
      "           frame   infer(ms)   toCPU(ms)   post(ms)   total(ms)\n",
      " frame_00000.png      1673.4         1.9        0.0      1675.2\n",
      " frame_00001.png       514.1         4.3      129.1       647.4\n",
      " frame_00002.png       121.8         1.9      110.4       234.2\n",
      " frame_00003.png        76.3         1.2      142.4       219.8\n",
      " frame_00004.png       189.6         1.1      175.7       366.5\n",
      " frame_00005.png       177.6         1.0      180.8       359.4\n",
      " frame_00006.png        74.8         1.0      156.6       232.4\n",
      " frame_00007.png       106.9         1.6      173.0       281.4\n",
      " frame_00008.png        85.1         1.3      174.0       260.4\n",
      " frame_00009.png       118.6         1.1      204.2       324.0\n",
      " frame_00010.png        38.1         0.9      155.7       194.8\n",
      " frame_00011.png        73.6         0.8      155.4       229.8\n",
      " frame_00012.png        75.5         1.0      158.5       235.0\n",
      " frame_00013.png       211.4         1.0      191.4       403.8\n",
      " frame_00014.png        70.3         0.9      170.2       241.4\n",
      " frame_00015.png        77.4         1.2      218.2       296.8\n",
      " frame_00016.png        56.5         1.2      160.1       217.8\n",
      " frame_00017.png        43.7         1.1      183.6       228.3\n",
      " frame_00018.png        88.4         1.3      154.3       244.1\n",
      " frame_00019.png       113.2         1.1      160.2       274.5\n",
      " frame_00020.png        47.2         1.0      146.2       194.4\n",
      " frame_00021.png        80.4         1.0      126.5       207.9\n",
      " frame_00022.png        77.7         1.1      116.6       195.4\n",
      " frame_00023.png        56.1         1.1      155.8       213.0\n",
      " frame_00024.png        43.5         2.2      110.5       156.2\n",
      " frame_00025.png        77.0         1.0      100.7       178.7\n",
      " frame_00026.png        89.2         2.0      102.5       193.7\n",
      " frame_00027.png        37.3         0.9       81.3       119.4\n",
      " frame_00028.png        44.0         1.5       55.1       100.6\n",
      " frame_00029.png       175.2       278.8       70.7       524.6\n",
      " frame_00030.png       250.2         1.3       96.0       347.5\n",
      " frame_00031.png        44.1         3.0       97.8       144.9\n",
      " frame_00032.png        34.4         2.6      134.5       171.6\n",
      " frame_00033.png        37.0         0.9      114.1       151.9\n",
      " frame_00034.png        40.6         1.0      120.3       161.9\n",
      " frame_00035.png        77.8         1.0      120.3       199.1\n",
      " frame_00036.png        34.4         1.1      152.7       188.2\n",
      " frame_00037.png        41.0         1.6      149.4       192.0\n",
      " frame_00038.png        33.5         1.0      115.7       150.1\n",
      " frame_00039.png        42.0         2.8      117.9       162.7\n",
      " frame_00040.png        35.6         1.1      106.3       143.0\n",
      " frame_00041.png        75.0         0.8      100.5       176.4\n",
      " frame_00042.png        36.3         1.1      135.4       172.8\n",
      " frame_00043.png        36.7         1.1      133.4       171.2\n",
      " frame_00044.png        35.3         1.6      117.9       154.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 524\u001b[39m\n\u001b[32m    520\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal  : min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(total_ms_list)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  p50=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m50\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mp90=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m90\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  p99=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m99\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(total_ms_list)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 477\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>16\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33minfer(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mtoCPU(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mpost(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mtotal(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m img_paths:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Benchmark inference + analysis time on saved frames (no UI, no clicks, no overlays).\n",
    "\n",
    "- Loads images from ./frames (fallback: ./alpha/frames).\n",
    "- Runs YOLO segmentation and the same post-processing you use at runtime.\n",
    "- Prints per-frame timings and a summary (mean/min/max and p50/p90/p99, plus FPS).\n",
    "\n",
    "Usage:\n",
    "  python benchmark_frames.py\n",
    "\"\"\"\n",
    "\n",
    "import os, time, math, glob, statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter for \"green rails\"\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 200\n",
    "RAY_STEP_PX         = 20\n",
    "\n",
    "# Lane anchor points (only used for angles and band math)\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "# Class buckets\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# --- tunnel wall color gate (HSV) ---\n",
    "LOWBARRIER1_ID   = 4\n",
    "ORANGETRAIN_ID   = 6\n",
    "WALL_STRIP_PX    = 20\n",
    "WALL_MATCH_FRAC  = 0.40\n",
    "# HSV thresholds (OpenCV H: 0–179). Broad orange range; tune as needed.\n",
    "WALL_ORANGE_LO = np.array([5,  80,  60], dtype=np.uint8)\n",
    "WALL_ORANGE_HI = np.array([35, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0\n",
    "\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], [], [], []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays, hit_class_ids, hit_distances_px = [], [], [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_cls = None\n",
    "        hit_dist_px = None\n",
    "\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "\n",
    "        colours.append(None)  # unused in timing run\n",
    "        rays.append(((int(x0), int(y0)), (0, 0), float(theta)))  # minimal structure\n",
    "        hit_class_ids.append(hit_cls)\n",
    "        hit_distances_px.append(hit_dist_px)\n",
    "\n",
    "    return colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "# =======================\n",
    "# Promotion logic (LOWBARRIER1 -> ORANGETRAIN when orange wall behind)\n",
    "# =======================\n",
    "def promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np,\n",
    "                                 strip_px=WALL_STRIP_PX, frac_thresh=WALL_MATCH_FRAC):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return classes_np\n",
    "\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    wall_u8 = cv2.inRange(hsv, WALL_ORANGE_LO, WALL_ORANGE_HI)\n",
    "\n",
    "    for i, cls in enumerate(classes_np):\n",
    "        if int(cls) != LOWBARRIER1_ID:\n",
    "            continue\n",
    "\n",
    "        m = masks_np[i]\n",
    "        if m.shape != (H, W):\n",
    "            m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        else:\n",
    "            m_full = m.astype(bool, copy=False)\n",
    "\n",
    "        ys, xs = np.where(m_full)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        x0, x1 = xs.min(), xs.max()\n",
    "        y0, _  = ys.min(), ys.max()\n",
    "\n",
    "        yb0 = max(0, y0 - strip_px)\n",
    "        yb1 = y0\n",
    "        if yb1 <= yb0:\n",
    "            continue\n",
    "\n",
    "        strip = wall_u8[yb0:yb1, x0:x1+1]\n",
    "        if strip.size == 0:\n",
    "            continue\n",
    "\n",
    "        frac = float(cv2.countNonZero(strip)) / strip.size\n",
    "        if frac >= frac_thresh:\n",
    "            classes_np[i] = ORANGETRAIN_ID\n",
    "\n",
    "    return classes_np\n",
    "\n",
    "# =======================\n",
    "# Hit probing helpers used in analysis\n",
    "# =======================\n",
    "def first_red_hit_y(pos, masks_np, classes_np, H, W, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    red_idx = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    if not red_idx: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing (timing-oriented, no printing)\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "      masks_np, classes_np, rail_mask, green_mask,\n",
    "      tri_positions, tri_colours, tri_rays,\n",
    "      best_idx, best_deg, x_ref,\n",
    "      tri_hit_classes, tri_summary\n",
    "    \"\"\"\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return (None, 0, 0, 0.0, 0.0, None, None, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    classes_np = promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np)\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Choose Jake triangle (bearing)\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    x_ref = tri_positions[best_idx][0] if (lane_name == \"mid\" and best_idx is not None and 0 <= best_idx < len(tri_positions)) else xj\n",
    "\n",
    "    tri_colours, tri_rays, tri_hit_classes, tri_hit_dists = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    # Minimal summary (useful later if you want to analyze decisions offline)\n",
    "    tri_summary = []\n",
    "    for i, (x, y) in enumerate(tri_positions):\n",
    "        cid = tri_hit_classes[i] if i < len(tri_hit_classes) else None\n",
    "        hdist = tri_hit_dists[i] if i < len(tri_hit_dists) else None\n",
    "        tri_summary.append({\n",
    "            \"pos\": (int(x), int(y)),\n",
    "            \"hit_class\": None if cid is None else int(cid),\n",
    "            \"hit_label\": None if cid is None else LABELS.get(int(cid), f\"C{int(cid)}\"),\n",
    "            \"hit_dist_px\": None if hdist is None else float(hdist),\n",
    "            \"is_jake\": (i == best_idx)\n",
    "        })\n",
    "\n",
    "    return (tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms,\n",
    "            masks_np, classes_np, rail_mask, green,\n",
    "            tri_positions, tri_colours, tri_rays,\n",
    "            best_idx, best_deg, x_ref,\n",
    "            tri_hit_classes, tri_summary)\n",
    "\n",
    "# =======================\n",
    "# Main benchmark\n",
    "# =======================\n",
    "def main():\n",
    "    # Locate frames\n",
    "    root = Path.cwd()\n",
    "    frames_dir = root / \"frames\"\n",
    "    if not frames_dir.exists():\n",
    "        alt = root / \"alpha\" / \"frames\"\n",
    "        if alt.exists():\n",
    "            frames_dir = alt\n",
    "    if not frames_dir.exists():\n",
    "        raise SystemExit(\"No ./frames or ./alpha/frames directory found.\")\n",
    "\n",
    "    img_paths = sorted(\n",
    "        [p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\") for p in frames_dir.glob(ext)]\n",
    "    )\n",
    "    if not img_paths:\n",
    "        raise SystemExit(f\"No images in {frames_dir}\")\n",
    "\n",
    "    # Backend\n",
    "    cv2.setUseOptimized(True)\n",
    "    try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "    except Exception: pass\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device, half = 0, True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        try: torch.set_float32_matmul_precision('high')\n",
    "        except Exception: pass\n",
    "    elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        device, half = \"mps\", False\n",
    "    else:\n",
    "        device, half = \"cpu\", False\n",
    "\n",
    "    # Model\n",
    "    model = YOLO(weights)\n",
    "    try: model.fuse()\n",
    "    except Exception: pass\n",
    "\n",
    "    # Warmup\n",
    "    _dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "    _ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                      conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "    # Timing accumulators\n",
    "    infer_ms_list = []\n",
    "    tocpu_ms_list = []\n",
    "    post_ms_list  = []\n",
    "    total_ms_list = []\n",
    "\n",
    "    # Assume we start mid-lane for the bearing math\n",
    "    JAKE_POINT = LANE_MID\n",
    "\n",
    "    print(f\"Benchmarking {len(img_paths)} frames from: {frames_dir}\\n\")\n",
    "    print(f\"{'frame':>16}  {'infer(ms)':>10}  {'toCPU(ms)':>10}  {'post(ms)':>9}  {'total(ms)':>10}\")\n",
    "\n",
    "    for p in img_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            [img], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "        )\n",
    "        infer_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        yres = res_list[0]\n",
    "\n",
    "        # Postproc (returns component timings)\n",
    "        (_, _, _, to_cpu_ms, post_ms,\n",
    "         _, _, _, _,\n",
    "         _, _, _,\n",
    "         _, _, _,\n",
    "         _, _) = process_frame_post(img, yres, JAKE_POINT)\n",
    "\n",
    "        total_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "        infer_ms_list.append(infer_ms)\n",
    "        tocpu_ms_list.append(to_cpu_ms)\n",
    "        post_ms_list.append(post_ms)\n",
    "        total_ms_list.append(total_ms)\n",
    "\n",
    "        print(f\"{p.name:>16}  {infer_ms:10.1f}  {to_cpu_ms:10.1f}  {post_ms:9.1f}  {total_ms:10.1f}\")\n",
    "\n",
    "    # Summary\n",
    "    def q(arr, qv):  # percentile helper\n",
    "        arr_sorted = sorted(arr)\n",
    "        idx = max(0, min(len(arr_sorted)-1, int(round((qv/100.0)*(len(arr_sorted)-1)))))\n",
    "        return arr_sorted[idx]\n",
    "\n",
    "    mean_total = statistics.fmean(total_ms_list)\n",
    "    fps_mean   = 1000.0 / mean_total if mean_total > 0 else 0.0\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Frames: {len(total_ms_list)}\")\n",
    "    print(f\"Infer  : mean={statistics.fmean(infer_ms_list):.1f} ms\")\n",
    "    print(f\"toCPU  : mean={statistics.fmean(tocpu_ms_list):.1f} ms\")\n",
    "    print(f\"Post   : mean={statistics.fmean(post_ms_list):.1f} ms\")\n",
    "    print(f\"Total  : mean={mean_total:.1f} ms  |  FPS≈{fps_mean:.2f}\")\n",
    "    print(f\"Total  : min={min(total_ms_list):.1f}  p50={q(total_ms_list,50):.1f}  \"\n",
    "          f\"p90={q(total_ms_list,90):.1f}  p99={q(total_ms_list,99):.1f}  max={max(total_ms_list):.1f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d908fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[BOOT] movement muted\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "Benchmarking 312 frames from: /Users/marcus/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
      "\n",
      "           frame   infer(ms)   toCPU(ms)   post(ms)   total(ms)\n",
      " frame_00000.png       154.2         0.7        0.0       154.9\n",
      " frame_00001.png        41.0         4.6       53.0        98.7\n",
      " frame_00002.png        39.9         0.9       88.6       129.3\n",
      " frame_00003.png        50.2         2.8       86.4       139.4\n",
      " frame_00004.png        39.8         0.8      116.5       157.0\n",
      " frame_00005.png        45.2         1.0      127.8       174.0\n",
      " frame_00006.png        37.7         1.2      108.9       147.8\n",
      " frame_00007.png        58.5         2.5      139.8       200.9\n",
      " frame_00008.png        37.1         1.9      118.3       157.2\n",
      " frame_00009.png        61.6         1.1      119.9       182.5\n",
      " frame_00010.png        29.7         0.9      122.8       153.3\n",
      "[BOOT] movement unmuted\n",
      " frame_00011.png        51.7         0.8      117.4       170.0\n",
      " frame_00012.png        56.9         0.9      118.2       176.0\n",
      " frame_00013.png        53.6         1.0      124.7       179.3\n",
      " frame_00014.png        54.4         0.9      115.5       170.8\n",
      " frame_00015.png        39.7         0.9      115.5       156.0\n",
      " frame_00016.png        32.6         1.1      120.5       154.1\n",
      " frame_00017.png        33.8         1.1      138.6       173.5\n",
      " frame_00018.png        43.7         1.0      561.1       605.8\n",
      " frame_00019.png       142.2         1.2      147.9       291.3\n",
      " frame_00020.png        40.6         1.3      125.0       166.9\n",
      " frame_00021.png        59.6         1.5      279.3       340.4\n",
      " frame_00022.png        89.2         1.4      165.1       255.7\n",
      " frame_00023.png        96.2         1.2      111.9       209.4\n",
      " frame_00024.png        39.8         2.0      107.7       149.5\n",
      " frame_00025.png        46.8         1.1      100.5       148.5\n",
      " frame_00026.png        55.0         1.2      123.6       179.8\n",
      " frame_00027.png        41.4         1.3       52.2        94.9\n",
      " frame_00028.png        50.9         1.7       72.8       125.4\n",
      " frame_00029.png        55.1       463.0       79.1       597.2\n",
      " frame_00030.png       210.4         2.5      122.9       335.8\n",
      " frame_00031.png        70.8         1.4      127.2       199.5\n",
      " frame_00032.png       134.7       111.9      930.9      1177.5\n",
      " frame_00033.png       110.5         2.7      100.1       213.3\n",
      " frame_00034.png        51.3         1.2      103.0       155.5\n",
      " frame_00035.png        47.1         1.0       99.1       147.3\n",
      " frame_00036.png        34.3         0.8      112.7       147.9\n",
      " frame_00037.png        59.4         1.0      108.3       168.7\n",
      " frame_00038.png        32.6         1.0      118.9       152.5\n",
      " frame_00039.png        60.5         2.8      165.9       229.2\n",
      " frame_00040.png        34.0         1.1      102.3       137.5\n",
      " frame_00041.png        52.6         1.5      106.2       160.3\n",
      " frame_00042.png        43.6         1.2      104.8       149.6\n",
      " frame_00043.png        30.3         0.9      105.1       136.3\n",
      " frame_00044.png        44.5         0.8       93.8       139.2\n",
      " frame_00045.png        41.7         0.9      126.5       169.1\n",
      " frame_00046.png        30.4         0.9      129.3       160.7\n",
      " frame_00047.png        34.5         1.0      115.4       150.9\n",
      " frame_00048.png        28.8         1.0      107.3       137.1\n",
      " frame_00049.png        41.7         0.8      117.2       159.7\n",
      " frame_00050.png        31.2         0.9      128.2       160.2\n",
      " frame_00051.png        37.4         0.9      137.9       176.2\n",
      " frame_00052.png        46.3         0.7      110.3       157.3\n",
      " frame_00053.png        31.7         0.8      127.6       160.1\n",
      " frame_00054.png        33.6         1.7      118.5       153.8\n",
      " frame_00055.png        73.2         0.8      112.7       186.7\n",
      " frame_00056.png        38.4         1.0      115.7       155.1\n",
      " frame_00057.png        34.8         2.1      104.4       141.2\n",
      " frame_00058.png        43.3         1.0      106.3       150.6\n",
      " frame_00059.png        39.8         1.0       97.9       138.7\n",
      " frame_00060.png        35.9         1.0      118.6       155.5\n",
      " frame_00061.png        41.7         1.0      106.4       149.2\n",
      " frame_00062.png        59.0       322.2      122.0       503.2\n",
      " frame_00063.png        48.1         1.1      197.5       246.7\n",
      " frame_00064.png        76.8         1.2      182.0       260.0\n",
      " frame_00065.png        64.4         1.3      235.3       301.0\n",
      " frame_00066.png        52.4         5.1      183.9       241.4\n",
      " frame_00067.png        47.7         2.5      149.6       199.8\n",
      " frame_00068.png        80.5         1.9      171.2       253.7\n",
      " frame_00069.png       156.3         1.5      171.4       329.2\n",
      " frame_00070.png       108.2         1.4      149.1       258.6\n",
      " frame_00071.png        60.7         9.0      141.7       211.4\n",
      " frame_00072.png        45.8         2.7      200.5       249.0\n",
      " frame_00073.png        50.3         1.5      128.1       179.9\n",
      " frame_00074.png       133.7         0.9      151.8       286.3\n",
      " frame_00075.png        60.3         1.5      129.4       191.3\n",
      " frame_00076.png        50.3         1.2      106.8       158.4\n",
      " frame_00077.png        41.4         2.1      117.2       160.7\n",
      " frame_00078.png        31.5         0.8       68.9       101.3\n",
      " frame_00079.png        61.2         1.0       97.6       159.7\n",
      " frame_00080.png        46.1         1.0       93.5       140.6\n",
      " frame_00081.png        30.2         1.0      114.6       145.8\n",
      " frame_00082.png        29.9         0.8      110.7       141.4\n",
      " frame_00083.png        30.9         0.8      114.7       146.4\n",
      " frame_00084.png        32.9         1.0      121.4       155.4\n",
      " frame_00085.png        40.2         1.0      140.6       181.8\n",
      " frame_00086.png        50.7         1.4      123.1       175.2\n",
      " frame_00087.png        44.5         1.0      140.6       186.2\n",
      " frame_00088.png        32.3         1.1      110.5       143.9\n",
      " frame_00089.png        37.7         1.2      116.3       155.2\n",
      " frame_00090.png        44.3         0.9      123.1       168.3\n",
      " frame_00091.png        35.0         1.8      121.5       158.4\n",
      " frame_00092.png        27.9         1.4      181.7       210.9\n",
      " frame_00093.png        37.0         1.0      120.5       158.5\n",
      " frame_00094.png        32.7         0.6      125.1       158.4\n",
      " frame_00095.png        28.2         0.8      108.3       137.2\n",
      " frame_00096.png        44.4         0.9       94.4       139.7\n",
      " frame_00097.png        32.2         0.8       88.9       121.9\n",
      " frame_00098.png        35.2         0.9       88.6       124.6\n",
      " frame_00099.png        36.4         1.0      103.1       140.4\n",
      " frame_00100.png        32.6         1.0       82.8       116.3\n",
      " frame_00101.png        34.8         0.9      106.2       141.9\n",
      " frame_00102.png        42.3         0.9      127.7       170.9\n",
      " frame_00103.png        28.9         0.9      149.6       179.4\n",
      " frame_00104.png        58.1         1.4      217.2       276.7\n",
      " frame_00105.png        38.7         1.0      149.4       189.2\n",
      " frame_00106.png        40.5         1.1      106.0       147.6\n",
      " frame_00107.png        34.8         1.0      157.1       192.9\n",
      " frame_00108.png        33.5         1.8      141.1       176.4\n",
      " frame_00109.png        46.7         2.6      133.7       183.0\n",
      " frame_00110.png        48.4         1.4      111.9       161.8\n",
      " frame_00111.png        39.7         1.2      106.1       147.1\n",
      " frame_00112.png        28.8         2.0      110.4       141.3\n",
      " frame_00113.png        32.1         0.8       93.6       126.6\n",
      " frame_00114.png        37.5       217.5      110.4       365.3\n",
      " frame_00115.png        61.2         1.0       83.5       145.7\n",
      " frame_00116.png        41.3         1.0       95.3       137.7\n",
      " frame_00117.png        30.6         1.0       95.4       127.0\n",
      " frame_00118.png        34.7         1.0      144.3       180.0\n",
      " frame_00119.png        57.2         1.7      156.0       214.9\n",
      " frame_00120.png        49.9         1.1      151.8       202.9\n",
      " frame_00121.png        38.1         1.1      115.7       154.8\n",
      " frame_00122.png        53.1         1.3      133.7       188.0\n",
      " frame_00123.png        51.8         1.5      106.3       159.5\n",
      " frame_00124.png        47.1         1.1      141.1       189.3\n",
      " frame_00125.png        33.4         2.3      117.2       152.9\n",
      " frame_00126.png        43.1         0.9      108.1       152.2\n",
      " frame_00127.png        36.1         0.9      115.1       152.1\n",
      " frame_00128.png        31.9         1.0      131.0       163.9\n",
      " frame_00129.png        44.5         1.0      114.0       159.4\n",
      " frame_00130.png        28.3         0.7      118.8       147.8\n",
      " frame_00131.png        36.2         1.1      126.9       164.2\n",
      " frame_00132.png        34.1         0.8      114.7       149.6\n",
      " frame_00133.png        29.9         0.7       97.3       127.9\n",
      " frame_00134.png        38.7         0.9       79.3       119.0\n",
      " frame_00135.png        40.2         0.7       65.1       106.0\n",
      " frame_00136.png        28.4         0.7       72.3       101.5\n",
      " frame_00137.png        29.9         0.7       62.8        93.4\n",
      " frame_00138.png        29.6         0.7       98.0       128.4\n",
      " frame_00139.png        36.7         0.6      109.9       147.2\n",
      " frame_00140.png        35.0         0.8      109.5       145.3\n",
      " frame_00141.png        34.2         0.8      107.6       142.6\n",
      " frame_00142.png        40.7         0.8      120.1       161.6\n",
      " frame_00143.png        28.4         0.8      116.7       145.9\n",
      " frame_00144.png        30.2         0.8      105.7       136.7\n",
      " frame_00145.png        32.2         0.9       78.0       111.2\n",
      " frame_00146.png        33.4         0.9       77.1       111.4\n",
      " frame_00147.png        31.4         0.8       83.3       115.5\n",
      " frame_00148.png        35.0         0.9       73.3       109.2\n",
      " frame_00149.png        30.9       102.6       92.9       226.5\n",
      " frame_00150.png        37.2         1.4      103.7       142.3\n",
      " frame_00151.png        39.7         1.2       89.1       129.9\n",
      " frame_00152.png        33.3         0.9       92.9       127.1\n",
      " frame_00153.png        28.0         1.2       84.3       113.5\n",
      " frame_00154.png        54.3         1.0      100.3       155.7\n",
      " frame_00155.png        48.7         1.0      118.7       168.4\n",
      " frame_00156.png        34.2         1.0      107.2       142.4\n",
      " frame_00157.png        33.9         0.8       95.7       130.5\n",
      " frame_00158.png        32.4         1.0       94.2       127.6\n",
      " frame_00159.png        35.7         0.9       91.2       127.8\n",
      " frame_00160.png        31.4         0.8       97.4       129.6\n",
      " frame_00161.png        33.3         0.8       75.8       110.0\n",
      " frame_00162.png        39.8        19.3      143.8       202.9\n",
      " frame_00163.png        40.7         0.9      121.7       163.2\n",
      " frame_00164.png        31.9         0.9      109.0       141.8\n",
      " frame_00165.png        35.6         0.9      121.3       157.8\n",
      " frame_00166.png        29.8         0.9      105.1       135.8\n",
      " frame_00167.png        28.9         0.9      135.3       165.1\n",
      " frame_00168.png        36.0         0.9      109.9       146.8\n",
      " frame_00169.png        27.8         0.8      117.9       146.4\n",
      " frame_00170.png        30.5         1.1      114.2       145.8\n",
      " frame_00171.png        39.1         0.9      127.1       167.0\n",
      " frame_00172.png        34.6        24.9      116.4       175.8\n",
      " frame_00173.png        33.9         1.1      105.5       140.4\n",
      " frame_00174.png        42.8         1.2      126.6       170.6\n",
      " frame_00175.png        25.3         1.1      114.4       140.8\n",
      " frame_00176.png        31.2         0.7      105.2       137.2\n",
      " frame_00177.png        26.4         0.9       33.5        60.8\n",
      " frame_00178.png        34.6         1.0        0.0        35.7\n",
      " frame_00179.png        43.0         1.0        0.0        44.0\n",
      " frame_00180.png        52.4         1.3        0.0        53.7\n",
      " frame_00181.png        34.4         0.8       34.1        69.3\n",
      " frame_00182.png        37.8         3.1       88.5       129.4\n",
      " frame_00183.png        39.4         1.4       95.0       135.8\n",
      " frame_00184.png        38.0         0.9       94.7       133.6\n",
      " frame_00185.png        28.8         1.1       90.1       120.1\n",
      " frame_00186.png        35.1         0.9       92.4       128.4\n",
      " frame_00187.png        35.3         6.7      130.0       172.0\n",
      " frame_00188.png        29.5         0.7      118.2       148.4\n",
      " frame_00189.png        34.4         0.8       90.3       125.6\n",
      " frame_00190.png        30.8         0.8       90.2       121.8\n",
      " frame_00191.png        29.6         1.0       84.0       114.6\n",
      " frame_00192.png        27.8         0.7       87.5       116.1\n",
      " frame_00193.png        31.2         1.1       86.8       119.1\n",
      " frame_00194.png        28.9         0.7      117.3       146.9\n",
      " frame_00195.png        30.1         0.7      124.6       155.5\n",
      " frame_00196.png        31.9         0.8       86.8       119.6\n",
      " frame_00197.png        34.2         1.0       86.3       121.4\n",
      " frame_00198.png        28.7         0.8       86.8       116.3\n",
      " frame_00199.png        36.0         0.8      113.0       149.8\n",
      " frame_00200.png        38.6         0.8      110.8       150.2\n",
      " frame_00201.png        34.8         0.7       86.8       122.3\n",
      " frame_00202.png        34.3         0.8       82.5       117.6\n",
      " frame_00203.png        35.0         1.2      103.8       140.0\n",
      " frame_00204.png        41.5         0.5      116.8       158.8\n",
      " frame_00205.png        34.2         0.8      121.4       156.4\n",
      " frame_00206.png        27.9         0.8      108.8       137.4\n",
      " frame_00207.png        29.4         0.7      117.1       147.2\n",
      " frame_00208.png        35.8         0.8      116.6       153.2\n",
      " frame_00209.png        34.2         0.9      112.5       147.6\n",
      " frame_00210.png        25.8         0.9      116.6       143.2\n",
      " frame_00211.png        27.9         0.8      109.9       138.7\n",
      " frame_00212.png        26.4         0.7      114.1       141.2\n",
      " frame_00213.png        29.9         0.9      115.8       146.5\n",
      " frame_00214.png        27.6         1.8      120.5       149.9\n",
      " frame_00215.png        33.7         1.1      117.3       152.1\n",
      " frame_00216.png        37.1         1.2      111.4       149.7\n",
      " frame_00217.png        35.4         1.0      104.9       141.3\n",
      " frame_00218.png        32.9         0.8      103.6       137.3\n",
      " frame_00219.png        29.2         0.8      110.7       140.7\n",
      " frame_00220.png        26.1         0.7       95.1       122.0\n",
      " frame_00221.png        28.5         0.8       78.7       108.0\n",
      " frame_00222.png        41.3         0.9       78.7       121.0\n",
      " frame_00223.png        34.5         1.2       91.2       126.9\n",
      " frame_00224.png        33.9         1.2       83.5       118.6\n",
      " frame_00225.png        29.3         0.7       88.8       118.8\n",
      " frame_00226.png        25.1         0.8      109.2       135.1\n",
      " frame_00227.png        35.2         0.7      106.3       142.2\n",
      " frame_00228.png        24.4         0.6      110.6       135.6\n",
      " frame_00229.png        35.0         1.0       76.3       112.3\n",
      " frame_00230.png        30.4         1.9       83.4       115.6\n",
      " frame_00231.png        29.2         0.8      106.9       136.9\n",
      " frame_00232.png        33.7         0.8      121.9       156.5\n",
      " frame_00233.png        32.6         1.0      103.1       136.7\n",
      " frame_00234.png        28.8         0.9       91.6       121.3\n",
      " frame_00235.png        38.1         0.8       42.0        80.9\n",
      " frame_00236.png        26.7         0.8        0.0        27.5\n",
      " frame_00237.png        33.0         0.7        0.0        33.7\n",
      " frame_00238.png        34.1         0.9        0.0        34.9\n",
      " frame_00239.png        43.8         1.0       37.8        82.6\n",
      " frame_00240.png        36.0         0.8       59.1        95.9\n",
      " frame_00241.png        33.5         0.7       64.5        98.7\n",
      " frame_00242.png        35.9         6.1       72.6       114.6\n",
      " frame_00243.png        32.9         5.1       86.8       124.8\n",
      " frame_00244.png        32.6         0.7       86.9       120.2\n",
      " frame_00245.png        40.8         0.7      107.8       149.2\n",
      " frame_00246.png        30.9         0.8      109.6       141.2\n",
      " frame_00247.png        27.7         0.7      110.8       139.2\n",
      " frame_00248.png        33.6         0.7      107.4       141.7\n",
      " frame_00249.png        31.3         0.8      107.8       140.0\n",
      " frame_00250.png        28.0         0.8      105.5       134.3\n",
      " frame_00251.png        30.5         0.7       82.8       114.0\n",
      " frame_00252.png        32.5         0.9       85.7       119.0\n",
      " frame_00253.png        33.3         1.0       98.3       132.6\n",
      " frame_00254.png        28.9         0.7      107.0       136.6\n",
      " frame_00255.png        32.2         0.8      107.1       140.0\n",
      " frame_00256.png        30.2         0.8      108.1       139.2\n",
      " frame_00257.png        29.3         0.7      108.7       138.7\n",
      " frame_00258.png        35.5         1.0      108.8       145.3\n",
      " frame_00259.png        35.3         0.9      112.1       148.4\n",
      " frame_00260.png        30.0         1.0      104.9       135.8\n",
      " frame_00261.png        28.4         0.9      109.0       138.3\n",
      " frame_00262.png        33.5         1.0      106.8       141.3\n",
      " frame_00263.png        32.1         0.8      108.1       140.9\n",
      " frame_00264.png        32.1         0.7      101.3       134.1\n",
      " frame_00265.png        37.2         0.9      105.3       143.4\n",
      " frame_00266.png        29.9         1.0      101.1       131.9\n",
      " frame_00267.png        29.5         0.7       94.4       124.6\n",
      " frame_00268.png        33.5         0.8       75.7       110.0\n",
      " frame_00269.png        27.9         1.0       63.4        92.3\n",
      " frame_00270.png        37.8         0.6        0.0        38.5\n",
      " frame_00271.png        59.2       275.5       40.1       374.8\n",
      " frame_00272.png        57.4         1.1       56.1       114.6\n",
      " frame_00273.png        37.9         1.2       66.0       105.2\n",
      " frame_00274.png        45.8         2.2       54.0       102.0\n",
      " frame_00275.png        44.0         1.0       57.1       102.1\n",
      " frame_00276.png        33.9         1.0       53.3        88.2\n",
      " frame_00277.png        30.9         1.2      103.5       135.6\n",
      " frame_00278.png        28.3         0.9       93.0       122.1\n",
      " frame_00279.png        29.1         1.0       63.6        93.7\n",
      " frame_00280.png        40.5         1.1       91.3       132.9\n",
      " frame_00281.png        35.7         1.0       96.3       133.0\n",
      " frame_00282.png        26.6         0.8      105.6       133.1\n",
      " frame_00283.png        30.4         0.9      104.2       135.5\n",
      " frame_00284.png        32.7         7.3      109.5       149.6\n",
      " frame_00285.png        32.0         0.9      107.9       140.9\n",
      " frame_00286.png        33.8         0.8      115.3       149.9\n",
      " frame_00287.png        34.7         0.7       43.1        78.5\n",
      " frame_00288.png        37.6        27.1        0.0        64.7\n",
      " frame_00289.png        36.6         1.0        0.0        37.6\n",
      " frame_00290.png        39.1         1.2        0.0        40.3\n",
      " frame_00291.png        44.6         2.3        0.0        46.8\n",
      " frame_00292.png        28.7         1.2        0.0        29.9\n",
      " frame_00293.png        35.1         1.3        0.0        36.4\n",
      " frame_00294.png        34.0         1.3        0.0        35.4\n",
      " frame_00295.png        43.3         1.1        0.0        44.5\n",
      " frame_00296.png        34.9         1.1        0.0        36.1\n",
      " frame_00297.png        36.5         1.2        0.0        37.7\n",
      " frame_00298.png        34.6         2.3        0.0        36.9\n",
      " frame_00299.png        37.7         1.1        0.0        38.8\n",
      " frame_00300.png        32.9         1.0        0.0        33.9\n",
      " frame_00301.png        32.6         0.9        0.0        33.5\n",
      " frame_00302.png        27.5         1.1        0.0        28.6\n",
      " frame_00303.png        26.9         1.3        0.0        28.2\n",
      " frame_00304.png        27.4         1.1        0.0        28.5\n",
      " frame_00305.png        26.3         1.0        0.0        27.4\n",
      " frame_00306.png        40.3         1.1        0.0        41.4\n",
      " frame_00307.png        17.0         0.0        0.0        17.0\n",
      " frame_00308.png        18.4         0.0        0.0        18.4\n",
      " frame_00309.png        17.8         0.0        0.0        17.8\n",
      " frame_00310.png        16.2         0.0        0.0        16.2\n",
      " frame_00311.png        16.9         0.0        0.0        16.9\n",
      "\n",
      "=== Summary ===\n",
      "Frames: 312\n",
      "Infer  : mean=40.4 ms\n",
      "toCPU  : mean=6.2 ms\n",
      "Post   : mean=101.7 ms\n",
      "Total  : mean=148.3 ms  |  FPS≈6.74\n",
      "Total  : min=16.2  p50=141.7  p90=199.5  p99=503.2  max=1177.5 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Live overlays + lane-aware curved sampling (optimized postproc)\n",
    "# • Parsec focus + auto click\n",
    "# • mss live capture of a crop region\n",
    "# • Arrow keys switch lane (0/1/2) -> JAKE_POINT updates per frame\n",
    "# • Full overlay rendering + per-frame save\n",
    "# • Prints compact timing per frame\n",
    "# • RETURNS per frame: tri_positions, best_idx, tri_hit_classes, tri_summary (for movement logic)\n",
    "\n",
    "import os, time, math, subprocess, statistics\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "from ultralytics import YOLO\n",
    "from threading import Timer\n",
    "from threading import Thread\n",
    "\n",
    "# -------------------\n",
    "# Timing accumulators\n",
    "# -------------------\n",
    "infer_ms_list  = []\n",
    "tocpu_ms_list  = []\n",
    "post_ms_list   = []\n",
    "total_ms_list  = []\n",
    "loop_dt_ms_list = []\n",
    "\n",
    "t_run_start = time.perf_counter()\n",
    "\n",
    "# --- swallow AI-generated keypresses in the listener for a short window ---\n",
    "SYNTHETIC_SUPPRESS_S = 0.15  # 150 ms is plenty\n",
    "_synth_block_until = 0.0     # simple, explicit init avoids IDE warnings\n",
    "\n",
    "try:\n",
    "    _synth_block_until\n",
    "except NameError:\n",
    "    _synth_block_until = 0.0\n",
    "\n",
    "# ======================= Quick supreesion to prevent instant bailouts =======================\n",
    "\n",
    "# --- allows 0.5s of movement, then mute for 2.5s, then restore ---\n",
    "# Save originals\n",
    "__press_orig   = pyautogui.press\n",
    "__keyDown_orig = pyautogui.keyDown\n",
    "__keyUp_orig   = pyautogui.keyUp\n",
    "__hotkey_orig  = pyautogui.hotkey\n",
    "\n",
    "# near your other globals, after imports\n",
    "MOVEMENT_ENABLED = True\n",
    "\n",
    "def __mute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = False\n",
    "    pyautogui.press  = lambda *a, **k: None\n",
    "    pyautogui.keyDown = lambda *a, **k: None\n",
    "    pyautogui.keyUp   = lambda *a, **k: None\n",
    "    pyautogui.hotkey  = lambda *a, **k: None\n",
    "    print(\"[BOOT] movement muted\")\n",
    "\n",
    "def __unmute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = True\n",
    "    pyautogui.press   = __press_orig\n",
    "    pyautogui.keyDown = __keyDown_orig\n",
    "    pyautogui.keyUp   = __keyUp_orig\n",
    "    pyautogui.hotkey  = __hotkey_orig\n",
    "    print(\"[BOOT] movement unmuted\")\n",
    "\n",
    "\n",
    "# Allow movement immediately; after 0.5s, mute; after 3.0s total, unmute\n",
    "Timer(0.5, __mute_keys).start()\n",
    "Timer(4.0, __unmute_keys).start()\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "# SAVE HERE\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_live_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crop + click (set by ad layout)\n",
    "advertisement = True\n",
    "if advertisement:\n",
    "    snap_coords = (644, 77, (1149-644), (981-75))  # (left, top, width, height)\n",
    "    start_click = (1030, 900)\n",
    "else:\n",
    "    snap_coords = (483, 75, (988-483), (981-75))\n",
    "    start_click = (870, 895)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 200\n",
    "RAY_STEP_PX         = 20   # walk the ray every 20 px\n",
    "\n",
    "# ===== Bend degrees (tune here) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0  # N1\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0  # N2\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0  # N3\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0  # N4\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "COLOR_CYAN   = (255, 255, 0)\n",
    "COLOR_BLACK  = (0, 0, 0)\n",
    "\n",
    "# =======================\n",
    "# Jake lane points + dynamic JAKE_POINT\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)  # index by lane (0,1,2)\n",
    "JAKE_POINT  = LANE_MID  # will be set each frame from 'lane'\n",
    "\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "\n",
    "# ===== Movement logic (modular) HELPER FUNCTIOSNS==============================================================================================================\n",
    "\n",
    "# --- tunnel wall color gate (HSV) ---\n",
    "LOWBARRIER1_ID   = 4\n",
    "ORANGETRAIN_ID   = 6\n",
    "WALL_STRIP_PX    = 20           # vertical strip height checked just above the barrier\n",
    "WALL_MATCH_FRAC  = 0.40         # % of “wall” pixels required to relabel\n",
    "WALL_ORANGE_LO = np.array([5,  80,  60], dtype=np.uint8)   # H,S,V (lo)\n",
    "WALL_ORANGE_HI = np.array([35, 255, 255], dtype=np.uint8)  # H,S,V (hi)\n",
    "\n",
    "\n",
    "def promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np,\n",
    "                                 strip_px=WALL_STRIP_PX, frac_thresh=WALL_MATCH_FRAC):\n",
    "    \"\"\"\n",
    "    If a LOWBARRIER1 has an orange 'tunnel wall' strip right behind it,\n",
    "    relabel that instance to ORANGETRAIN (treated as RED).\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return classes_np\n",
    "\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    wall_u8 = cv2.inRange(hsv, WALL_ORANGE_LO, WALL_ORANGE_HI)  # 0/255\n",
    "\n",
    "    # iterate only over LOWBARRIER1 instances\n",
    "    for i, cls in enumerate(classes_np):\n",
    "        if int(cls) != LOWBARRIER1_ID:\n",
    "            continue\n",
    "\n",
    "        m = masks_np[i]\n",
    "        # upsample to frame size if needed\n",
    "        if m.shape != (H, W):\n",
    "            m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        else:\n",
    "            m_full = m.astype(bool, copy=False)\n",
    "\n",
    "        ys, xs = np.where(m_full)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        x0, x1 = xs.min(), xs.max()\n",
    "        y0, _  = ys.min(), ys.max()\n",
    "\n",
    "        # check a strip immediately above the barrier (toward smaller y)\n",
    "        yb0 = max(0, y0 - strip_px)\n",
    "        yb1 = y0\n",
    "        if yb1 <= yb0:\n",
    "            continue\n",
    "\n",
    "        strip = wall_u8[yb0:yb1, x0:x1+1]\n",
    "        if strip.size == 0:\n",
    "            continue\n",
    "\n",
    "        frac = float(cv2.countNonZero(strip)) / strip.size\n",
    "        if frac >= frac_thresh:\n",
    "            classes_np[i] = ORANGETRAIN_ID  # promote to a RED class\n",
    "\n",
    "    return classes_np\n",
    "\n",
    "\n",
    "# extra classes/sets\n",
    "WARN_FOR_MOVE = {2, 3, 4, 5, 8}      # yellow set that should try to sidestep if a green exists\n",
    "JUMP_SET      = {3, 5, 10}           # Jump, LowBarrier2, Sidewalk\n",
    "DUCK_SET      = {2, 4}               # HighBarrier1, LowBarrier1\n",
    "\n",
    "# action keys (change if your emulator uses different binds)\n",
    "JUMP_KEY = \"up\"\n",
    "DUCK_KEY = \"down\"\n",
    "\n",
    "# --- \"white-ish\" lane probe (5x5 box counts) ---\n",
    "# tune these if your Jake sprite/board highlight isn't pure white\n",
    "WHITE_MIN = np.array([220, 220, 220], dtype=np.uint8)  # BGR lower bound\n",
    "WHITE_MAX = np.array([255, 255, 255], dtype=np.uint8)  # BGR upper bound\n",
    "BOX_RAD   = 2  # 5x5 => radius 2\n",
    "\n",
    "def _count_white_around(img_bgr, pt, box_rad=BOX_RAD):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    x, y = pt\n",
    "    x0 = max(0, x - box_rad); x1 = min(W, x + box_rad + 1)\n",
    "    y0 = max(0, y - box_rad); y1 = min(H, y + box_rad + 1)\n",
    "    roi = img_bgr[y0:y1, x0:x1]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "    mask = cv2.inRange(roi, WHITE_MIN, WHITE_MAX)\n",
    "    return int(cv2.countNonZero(mask))\n",
    "\n",
    "def _detect_lane_by_whiteness(img_bgr):\n",
    "    # returns lane index 0/1/2 chosen by the largest white count;\n",
    "    # if all zero, returns None to keep previous lane\n",
    "    counts = [\n",
    "        _count_white_around(img_bgr, LANE_LEFT),\n",
    "        _count_white_around(img_bgr, LANE_MID),\n",
    "        _count_white_around(img_bgr, LANE_RIGHT),\n",
    "    ]\n",
    "    best_idx = int(np.argmax(counts))\n",
    "    return best_idx if counts[best_idx] > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# action cooldown so we don't spam jump/duck\n",
    "try:\n",
    "    last_action_ts\n",
    "except NameError:\n",
    "    last_action_ts = 0.0\n",
    "ACTION_COOLDOWN_S = 0.5\n",
    "\n",
    "# distance threshold (pixels) from Jake to triangle apex for action decisions\n",
    "ACTION_DIST_PX = 30\n",
    "\n",
    "def _is_warn(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in WARN_FOR_MOVE)\n",
    "\n",
    "def _dist_px(jx: int, jy: int, tx: int, ty: int) -> float:\n",
    "    return math.hypot(tx - jx, ty - jy)\n",
    "\n",
    "def _pick_best_green(cands, jx: int):\n",
    "    \"\"\"Choose the closest triangle with hit_class == None (no hit along ray).\"\"\"\n",
    "    greens = [c for c in cands if c[\"hit_class\"] is None]\n",
    "    if not greens:\n",
    "        return None\n",
    "    greens = [c for c in greens if c[\"pos\"][0] != jx] or greens\n",
    "    return min(greens, key=lambda c: abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "def _schedule(fn, *args, **kwargs):\n",
    "    Thread(target=fn, args=args, kwargs=kwargs, daemon=True).start()\n",
    "\n",
    "def _do_jump_then_duck(delay_s: float = 0.50):\n",
    "    pyautogui.press(JUMP_KEY)\n",
    "    time.sleep(delay_s)\n",
    "    pyautogui.press(DUCK_KEY)\n",
    "\n",
    "def _try_jump_then_duck():\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "    global last_action_ts\n",
    "    now = time.perf_counter()\n",
    "    if now - last_action_ts >= ACTION_COOLDOWN_S:\n",
    "        last_action_ts = now\n",
    "        _schedule(_do_jump_then_duck, 0.20)\n",
    "\n",
    "MIN_GREEN_AHEAD_PX = 400\n",
    "def _filter_green_far(cands, jake_band_y: int, min_ahead_px: int = MIN_GREEN_AHEAD_PX):\n",
    "    \"\"\"Keep only green triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:  # keep if ≥ 400 px ahead\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def first_red_hit_y(pos, masks_np, classes_np, H, W, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first RED pixel straight above `pos`, or None.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    red_idx = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    if not red_idx: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "def first_hit_y(pos, masks_np, classes_np, H, W, class_set, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first pixel (straight up) whose class ∈ class_set.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    idxs = [i for i, c in enumerate(classes_np) if int(c) in class_set]\n",
    "    if not idxs: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in idxs:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "\n",
    "# Only step from RED into a YELLOW lane if its triangle is far enough ahead\n",
    "MIN_YELLOW_AHEAD_PX = 400\n",
    "def _filter_yellow_far(cands, jake_band_y: int, min_ahead_px: int = MIN_YELLOW_AHEAD_PX):\n",
    "    \"\"\"Keep only yellow triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _try_duck():\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "    global last_action_ts\n",
    "    now = time.perf_counter()\n",
    "    if now - last_action_ts >= ACTION_COOLDOWN_S:\n",
    "        last_action_ts = now\n",
    "        _schedule(pyautogui.press, DUCK_KEY)\n",
    "try:\n",
    "    last_move_ts\n",
    "except NameError:\n",
    "    last_move_ts = 0.0\n",
    "\n",
    "MOVE_COOLDOWN_S = 0.10  # 100 ms\n",
    "\n",
    "def _is_danger(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in DANGER_RED)\n",
    "\n",
    "def _is_safe(cls_id: int | None) -> bool:\n",
    "    return not _is_danger(cls_id)\n",
    "\n",
    "def _filter_by_lane(cands, jx: int, lane_idx: int):\n",
    "    \"\"\"Prune triangles based on current lane:\n",
    "       - lane 0 (left): drop triangles with x < jx\n",
    "       - lane 2 (right): drop triangles with x > jx\n",
    "       - lane 1 (mid): keep all\n",
    "    \"\"\"\n",
    "    if lane_idx == 0:\n",
    "        return [c for c in cands if c[\"pos\"][0] >= jx]\n",
    "    if lane_idx == 2:\n",
    "        return [c for c in cands if c[\"pos\"][0] <= jx]\n",
    "    return cands\n",
    "\n",
    "def _pick_best_safe_triangle(cands, jx: int):\n",
    "    \"\"\"Prefer triangles with hit_class == None; otherwise any non-danger.\n",
    "       Break ties by smallest |x - jx|.\n",
    "    \"\"\"\n",
    "    if not cands:\n",
    "        return None\n",
    "    none_hits  = [c for c in cands if c[\"hit_class\"] is None]\n",
    "    safe_hits  = [c for c in cands if c[\"hit_class\"] is not None and _is_safe(c[\"hit_class\"])]\n",
    "    pool = none_hits if none_hits else safe_hits\n",
    "    if not pool:\n",
    "        return None\n",
    "    # exclude triangles exactly aligned with Jake in x (no direction)\n",
    "    pool = [c for c in pool if c[\"pos\"][0] != jx] or pool\n",
    "    return min(pool, key=lambda c: abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "def _issue_move_towards_x(jx: int, tx: int):\n",
    "    global lane, last_move_ts, _synth_block_until\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "\n",
    "    now = time.perf_counter()\n",
    "    if now - last_move_ts < MOVE_COOLDOWN_S:\n",
    "        return\n",
    "\n",
    "    if tx < jx and lane > MIN_LANE:\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('left')\n",
    "        lane = max(MIN_LANE, lane - 1)\n",
    "        print(f\"[AI MOVE] left -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "\n",
    "    elif tx > jx and lane < MAX_LANE:\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('right')\n",
    "        lane = min(MAX_LANE, lane + 1)\n",
    "        print(f\"[AI MOVE] right -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "    else:\n",
    "        print('WE ARE COOKED')\n",
    "\n",
    "\n",
    "#============================================================================================================================================\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Lane/keyboard state\n",
    "# =======================\n",
    "lane = 1\n",
    "MIN_LANE = 0\n",
    "MAX_LANE = 2\n",
    "running = True\n",
    "\n",
    "# ===== Debounce / cooldown =====\n",
    "COOLDOWN_MS = 20\n",
    "_last_press_ts = 0.0  # monotonic seconds\n",
    "\n",
    "def on_press(key):\n",
    "    global lane, running, _last_press_ts, _synth_block_until\n",
    "    now = time.monotonic()\n",
    "\n",
    "    # swallow AI-generated lane key events during the suppression window\n",
    "    if key in (keyboard.Key.left, keyboard.Key.right) and now < _synth_block_until:\n",
    "        return\n",
    "\n",
    "    if key != keyboard.Key.esc and (now - _last_press_ts) * 1000.0 < COOLDOWN_MS:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if key == keyboard.Key.left:\n",
    "            lane = max(MIN_LANE, lane - 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Left into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.right:\n",
    "            lane = min(MAX_LANE, lane + 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Right into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.esc:\n",
    "            running = False\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# Class buckets for probe classification\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "def _fmt_px(v):\n",
    "    return f\"{v:.1f}px\" if v is not None else \"n/a\"\n",
    "\n",
    "# =======================\n",
    "# Parsec to front + click Start (non-blocking failures)\n",
    "# =======================\n",
    "try:\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell application \"Parsec\" to activate'], check=False)\n",
    "    time.sleep(0.4)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pyautogui.click(start_click)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # must be above Jake\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "# --------- walk-the-ray classifier (first-hit wins) ----------\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], [], [], []  # colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays, hit_class_ids, hit_distances_px = [], [], [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_colour = COLOR_GREEN\n",
    "        hit_cls = None\n",
    "        hit_dist_px = None\n",
    "\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            # RED first (so if red exists at a point, we record red distance)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_RED\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then YELLOW\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_YELLOW\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then BOOTS\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_PINK\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "\n",
    "        x1 = _clampi(int(round(x0 + dx1 * sample_px)), 0, W-1)\n",
    "        y1 = _clampi(int(round(y0 + dy1 * sample_px)), 0, H-1)\n",
    "\n",
    "        colours.append(hit_colour)\n",
    "        rays.append(((int(x0), int(y0)), (x1, y1), float(theta)))\n",
    "        hit_class_ids.append(hit_cls)\n",
    "        hit_distances_px.append(hit_dist_px)\n",
    "\n",
    "    return colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    \"\"\"\n",
    "    Returns (…)\n",
    "      tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "      masks_np, classes_np, rail_mask, green_mask,\n",
    "      tri_positions, tri_colours, tri_rays,\n",
    "      best_idx, best_deg, x_ref,\n",
    "      tri_hit_classes, tri_summary\n",
    "    \"\"\"\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return (None, 0, 0, 0.0, 0.0, None, None, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    classes_np = promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np)\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Jake triangle by bearing\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    x_ref = tri_positions[best_idx][0] if (lane_name == \"mid\" and best_idx is not None and 0 <= best_idx < len(tri_positions)) else xj\n",
    "\n",
    "    tri_colours, tri_rays, tri_hit_classes, tri_hit_dists = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    # Minimal summary (useful later if you want to analyze decisions offline)\n",
    "    tri_summary = []\n",
    "    for i, (x, y) in enumerate(tri_positions):\n",
    "        cid = tri_hit_classes[i] if i < len(tri_hit_classes) else None\n",
    "        hdist = tri_hit_dists[i] if i < len(tri_hit_dists) else None\n",
    "        tri_summary.append({\n",
    "            \"pos\": (int(x), int(y)),\n",
    "            \"hit_class\": None if cid is None else int(cid),\n",
    "            \"hit_label\": None if cid is None else LABELS.get(int(cid), f\"C{int(cid)}\"),\n",
    "            \"hit_dist_px\": None if hdist is None else float(hdist),\n",
    "            \"is_jake\": (i == best_idx)\n",
    "        })\n",
    "\n",
    "    return (tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms,\n",
    "            masks_np, classes_np, rail_mask, green,\n",
    "            tri_positions, tri_colours, tri_rays,\n",
    "            best_idx, best_deg, x_ref,\n",
    "            tri_hit_classes, tri_summary)\n",
    "\n",
    "# =======================\n",
    "# Main benchmark\n",
    "# =======================\n",
    "def main():\n",
    "    # Locate frames\n",
    "    root = Path.cwd()\n",
    "    frames_dir = root / \"frames\"\n",
    "    if not frames_dir.exists():\n",
    "        alt = root / \"alpha\" / \"frames\"\n",
    "        if alt.exists():\n",
    "            frames_dir = alt\n",
    "    if not frames_dir.exists():\n",
    "        raise SystemExit(\"No ./frames or ./alpha/frames directory found.\")\n",
    "\n",
    "    img_paths = sorted(\n",
    "        [p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\") for p in frames_dir.glob(ext)]\n",
    "    )\n",
    "    if not img_paths:\n",
    "        raise SystemExit(f\"No images in {frames_dir}\")\n",
    "\n",
    "    # Backend\n",
    "    cv2.setUseOptimized(True)\n",
    "    try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "    except Exception: pass\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device, half = 0, True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        try: torch.set_float32_matmul_precision('high')\n",
    "        except Exception: pass\n",
    "    elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        device, half = \"mps\", False\n",
    "    else:\n",
    "        device, half = \"cpu\", False\n",
    "\n",
    "    # Model\n",
    "    model = YOLO(weights)\n",
    "    try: model.fuse()\n",
    "    except Exception: pass\n",
    "\n",
    "    # Warmup\n",
    "    _dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "    _ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                      conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "    # Timing accumulators\n",
    "    infer_ms_list = []\n",
    "    tocpu_ms_list = []\n",
    "    post_ms_list  = []\n",
    "    total_ms_list = []\n",
    "\n",
    "    # Assume we start mid-lane for the bearing math\n",
    "    JAKE_POINT = LANE_MID\n",
    "\n",
    "    print(f\"Benchmarking {len(img_paths)} frames from: {frames_dir}\\n\")\n",
    "    print(f\"{'frame':>16}  {'infer(ms)':>10}  {'toCPU(ms)':>10}  {'post(ms)':>9}  {'total(ms)':>10}\")\n",
    "\n",
    "    for p in img_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            [img], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "        )\n",
    "        infer_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        yres = res_list[0]\n",
    "\n",
    "        # Postproc (returns component timings)\n",
    "        (_, _, _, to_cpu_ms, post_ms,\n",
    "         _, _, _, _,\n",
    "         _, _, _,\n",
    "         _, _, _,\n",
    "         _, _) = process_frame_post(img, yres, JAKE_POINT)\n",
    "\n",
    "        total_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "        infer_ms_list.append(infer_ms)\n",
    "        tocpu_ms_list.append(to_cpu_ms)\n",
    "        post_ms_list.append(post_ms)\n",
    "        total_ms_list.append(total_ms)\n",
    "\n",
    "        print(f\"{p.name:>16}  {infer_ms:10.1f}  {to_cpu_ms:10.1f}  {post_ms:9.1f}  {total_ms:10.1f}\")\n",
    "\n",
    "    # Summary\n",
    "    def q(arr, qv):  # percentile helper\n",
    "        arr_sorted = sorted(arr)\n",
    "        idx = max(0, min(len(arr_sorted)-1, int(round((qv/100.0)*(len(arr_sorted)-1)))))\n",
    "        return arr_sorted[idx]\n",
    "\n",
    "    mean_total = statistics.fmean(total_ms_list)\n",
    "    fps_mean   = 1000.0 / mean_total if mean_total > 0 else 0.0\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Frames: {len(total_ms_list)}\")\n",
    "    print(f\"Infer  : mean={statistics.fmean(infer_ms_list):.1f} ms\")\n",
    "    print(f\"toCPU  : mean={statistics.fmean(tocpu_ms_list):.1f} ms\")\n",
    "    print(f\"Post   : mean={statistics.fmean(post_ms_list):.1f} ms\")\n",
    "    print(f\"Total  : mean={mean_total:.1f} ms  |  FPS≈{fps_mean:.2f}\")\n",
    "    print(f\"Total  : min={min(total_ms_list):.1f}  p50={q(total_ms_list,50):.1f}  \"\n",
    "          f\"p90={q(total_ms_list,90):.1f}  p99={q(total_ms_list,99):.1f}  max={max(total_ms_list):.1f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87655e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a396cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
