{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a8b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "Benchmarking 312 frames from: /Users/marcus/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
      "\n",
      "           frame   infer(ms)   toCPU(ms)   post(ms)   total(ms)\n",
      " frame_00000.png      1673.4         1.9        0.0      1675.2\n",
      " frame_00001.png       514.1         4.3      129.1       647.4\n",
      " frame_00002.png       121.8         1.9      110.4       234.2\n",
      " frame_00003.png        76.3         1.2      142.4       219.8\n",
      " frame_00004.png       189.6         1.1      175.7       366.5\n",
      " frame_00005.png       177.6         1.0      180.8       359.4\n",
      " frame_00006.png        74.8         1.0      156.6       232.4\n",
      " frame_00007.png       106.9         1.6      173.0       281.4\n",
      " frame_00008.png        85.1         1.3      174.0       260.4\n",
      " frame_00009.png       118.6         1.1      204.2       324.0\n",
      " frame_00010.png        38.1         0.9      155.7       194.8\n",
      " frame_00011.png        73.6         0.8      155.4       229.8\n",
      " frame_00012.png        75.5         1.0      158.5       235.0\n",
      " frame_00013.png       211.4         1.0      191.4       403.8\n",
      " frame_00014.png        70.3         0.9      170.2       241.4\n",
      " frame_00015.png        77.4         1.2      218.2       296.8\n",
      " frame_00016.png        56.5         1.2      160.1       217.8\n",
      " frame_00017.png        43.7         1.1      183.6       228.3\n",
      " frame_00018.png        88.4         1.3      154.3       244.1\n",
      " frame_00019.png       113.2         1.1      160.2       274.5\n",
      " frame_00020.png        47.2         1.0      146.2       194.4\n",
      " frame_00021.png        80.4         1.0      126.5       207.9\n",
      " frame_00022.png        77.7         1.1      116.6       195.4\n",
      " frame_00023.png        56.1         1.1      155.8       213.0\n",
      " frame_00024.png        43.5         2.2      110.5       156.2\n",
      " frame_00025.png        77.0         1.0      100.7       178.7\n",
      " frame_00026.png        89.2         2.0      102.5       193.7\n",
      " frame_00027.png        37.3         0.9       81.3       119.4\n",
      " frame_00028.png        44.0         1.5       55.1       100.6\n",
      " frame_00029.png       175.2       278.8       70.7       524.6\n",
      " frame_00030.png       250.2         1.3       96.0       347.5\n",
      " frame_00031.png        44.1         3.0       97.8       144.9\n",
      " frame_00032.png        34.4         2.6      134.5       171.6\n",
      " frame_00033.png        37.0         0.9      114.1       151.9\n",
      " frame_00034.png        40.6         1.0      120.3       161.9\n",
      " frame_00035.png        77.8         1.0      120.3       199.1\n",
      " frame_00036.png        34.4         1.1      152.7       188.2\n",
      " frame_00037.png        41.0         1.6      149.4       192.0\n",
      " frame_00038.png        33.5         1.0      115.7       150.1\n",
      " frame_00039.png        42.0         2.8      117.9       162.7\n",
      " frame_00040.png        35.6         1.1      106.3       143.0\n",
      " frame_00041.png        75.0         0.8      100.5       176.4\n",
      " frame_00042.png        36.3         1.1      135.4       172.8\n",
      " frame_00043.png        36.7         1.1      133.4       171.2\n",
      " frame_00044.png        35.3         1.6      117.9       154.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 524\u001b[39m\n\u001b[32m    520\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal  : min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(total_ms_list)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  p50=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m50\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    521\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mp90=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m90\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  p99=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq(total_ms_list,\u001b[32m99\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(total_ms_list)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 477\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>16\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33minfer(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mtoCPU(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mpost(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>9\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mtotal(ms)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m>10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m img_paths:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Benchmark inference + analysis time on saved frames (no UI, no clicks, no overlays).\n",
    "\n",
    "- Loads images from ./frames (fallback: ./alpha/frames).\n",
    "- Runs YOLO segmentation and the same post-processing you use at runtime.\n",
    "- Prints per-frame timings and a summary (mean/min/max and p50/p90/p99, plus FPS).\n",
    "\n",
    "Usage:\n",
    "  python benchmark_frames.py\n",
    "\"\"\"\n",
    "\n",
    "import os, time, math, glob, statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter for \"green rails\"\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 200\n",
    "RAY_STEP_PX         = 20\n",
    "\n",
    "# Lane anchor points (only used for angles and band math)\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "# Class buckets\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# --- tunnel wall color gate (HSV) ---\n",
    "LOWBARRIER1_ID   = 4\n",
    "ORANGETRAIN_ID   = 6\n",
    "WALL_STRIP_PX    = 20\n",
    "WALL_MATCH_FRAC  = 0.40\n",
    "# HSV thresholds (OpenCV H: 0–179). Broad orange range; tune as needed.\n",
    "WALL_ORANGE_LO = np.array([5,  80,  60], dtype=np.uint8)\n",
    "WALL_ORANGE_HI = np.array([35, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0\n",
    "\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], [], [], []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays, hit_class_ids, hit_distances_px = [], [], [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_cls = None\n",
    "        hit_dist_px = None\n",
    "\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_cls = int(classes_np[i]); hit_dist_px = float(t); found = True; break\n",
    "            if found: break\n",
    "\n",
    "        colours.append(None)  # unused in timing run\n",
    "        rays.append(((int(x0), int(y0)), (0, 0), float(theta)))  # minimal structure\n",
    "        hit_class_ids.append(hit_cls)\n",
    "        hit_distances_px.append(hit_dist_px)\n",
    "\n",
    "    return colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "# =======================\n",
    "# Promotion logic (LOWBARRIER1 -> ORANGETRAIN when orange wall behind)\n",
    "# =======================\n",
    "def promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np,\n",
    "                                 strip_px=WALL_STRIP_PX, frac_thresh=WALL_MATCH_FRAC):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return classes_np\n",
    "\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    wall_u8 = cv2.inRange(hsv, WALL_ORANGE_LO, WALL_ORANGE_HI)\n",
    "\n",
    "    for i, cls in enumerate(classes_np):\n",
    "        if int(cls) != LOWBARRIER1_ID:\n",
    "            continue\n",
    "\n",
    "        m = masks_np[i]\n",
    "        if m.shape != (H, W):\n",
    "            m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        else:\n",
    "            m_full = m.astype(bool, copy=False)\n",
    "\n",
    "        ys, xs = np.where(m_full)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        x0, x1 = xs.min(), xs.max()\n",
    "        y0, _  = ys.min(), ys.max()\n",
    "\n",
    "        yb0 = max(0, y0 - strip_px)\n",
    "        yb1 = y0\n",
    "        if yb1 <= yb0:\n",
    "            continue\n",
    "\n",
    "        strip = wall_u8[yb0:yb1, x0:x1+1]\n",
    "        if strip.size == 0:\n",
    "            continue\n",
    "\n",
    "        frac = float(cv2.countNonZero(strip)) / strip.size\n",
    "        if frac >= frac_thresh:\n",
    "            classes_np[i] = ORANGETRAIN_ID\n",
    "\n",
    "    return classes_np\n",
    "\n",
    "# =======================\n",
    "# Hit probing helpers used in analysis\n",
    "# =======================\n",
    "def first_red_hit_y(pos, masks_np, classes_np, H, W, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    red_idx = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    if not red_idx: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing (timing-oriented, no printing)\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "      masks_np, classes_np, rail_mask, green_mask,\n",
    "      tri_positions, tri_colours, tri_rays,\n",
    "      best_idx, best_deg, x_ref,\n",
    "      tri_hit_classes, tri_summary\n",
    "    \"\"\"\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return (None, 0, 0, 0.0, 0.0, None, None, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    classes_np = promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np)\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Choose Jake triangle (bearing)\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    x_ref = tri_positions[best_idx][0] if (lane_name == \"mid\" and best_idx is not None and 0 <= best_idx < len(tri_positions)) else xj\n",
    "\n",
    "    tri_colours, tri_rays, tri_hit_classes, tri_hit_dists = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    # Minimal summary (useful later if you want to analyze decisions offline)\n",
    "    tri_summary = []\n",
    "    for i, (x, y) in enumerate(tri_positions):\n",
    "        cid = tri_hit_classes[i] if i < len(tri_hit_classes) else None\n",
    "        hdist = tri_hit_dists[i] if i < len(tri_hit_dists) else None\n",
    "        tri_summary.append({\n",
    "            \"pos\": (int(x), int(y)),\n",
    "            \"hit_class\": None if cid is None else int(cid),\n",
    "            \"hit_label\": None if cid is None else LABELS.get(int(cid), f\"C{int(cid)}\"),\n",
    "            \"hit_dist_px\": None if hdist is None else float(hdist),\n",
    "            \"is_jake\": (i == best_idx)\n",
    "        })\n",
    "\n",
    "    return (tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms,\n",
    "            masks_np, classes_np, rail_mask, green,\n",
    "            tri_positions, tri_colours, tri_rays,\n",
    "            best_idx, best_deg, x_ref,\n",
    "            tri_hit_classes, tri_summary)\n",
    "\n",
    "# =======================\n",
    "# Main benchmark\n",
    "# =======================\n",
    "def main():\n",
    "    # Locate frames\n",
    "    root = Path.cwd()\n",
    "    frames_dir = root / \"frames\"\n",
    "    if not frames_dir.exists():\n",
    "        alt = root / \"alpha\" / \"frames\"\n",
    "        if alt.exists():\n",
    "            frames_dir = alt\n",
    "    if not frames_dir.exists():\n",
    "        raise SystemExit(\"No ./frames or ./alpha/frames directory found.\")\n",
    "\n",
    "    img_paths = sorted(\n",
    "        [p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\") for p in frames_dir.glob(ext)]\n",
    "    )\n",
    "    if not img_paths:\n",
    "        raise SystemExit(f\"No images in {frames_dir}\")\n",
    "\n",
    "    # Backend\n",
    "    cv2.setUseOptimized(True)\n",
    "    try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "    except Exception: pass\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device, half = 0, True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        try: torch.set_float32_matmul_precision('high')\n",
    "        except Exception: pass\n",
    "    elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        device, half = \"mps\", False\n",
    "    else:\n",
    "        device, half = \"cpu\", False\n",
    "\n",
    "    # Model\n",
    "    model = YOLO(weights)\n",
    "    try: model.fuse()\n",
    "    except Exception: pass\n",
    "\n",
    "    # Warmup\n",
    "    _dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "    _ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                      conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "    # Timing accumulators\n",
    "    infer_ms_list = []\n",
    "    tocpu_ms_list = []\n",
    "    post_ms_list  = []\n",
    "    total_ms_list = []\n",
    "\n",
    "    # Assume we start mid-lane for the bearing math\n",
    "    JAKE_POINT = LANE_MID\n",
    "\n",
    "    print(f\"Benchmarking {len(img_paths)} frames from: {frames_dir}\\n\")\n",
    "    print(f\"{'frame':>16}  {'infer(ms)':>10}  {'toCPU(ms)':>10}  {'post(ms)':>9}  {'total(ms)':>10}\")\n",
    "\n",
    "    for p in img_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            [img], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "        )\n",
    "        infer_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        yres = res_list[0]\n",
    "\n",
    "        # Postproc (returns component timings)\n",
    "        (_, _, _, to_cpu_ms, post_ms,\n",
    "         _, _, _, _,\n",
    "         _, _, _,\n",
    "         _, _, _,\n",
    "         _, _) = process_frame_post(img, yres, JAKE_POINT)\n",
    "\n",
    "        total_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "        infer_ms_list.append(infer_ms)\n",
    "        tocpu_ms_list.append(to_cpu_ms)\n",
    "        post_ms_list.append(post_ms)\n",
    "        total_ms_list.append(total_ms)\n",
    "\n",
    "        print(f\"{p.name:>16}  {infer_ms:10.1f}  {to_cpu_ms:10.1f}  {post_ms:9.1f}  {total_ms:10.1f}\")\n",
    "\n",
    "    # Summary\n",
    "    def q(arr, qv):  # percentile helper\n",
    "        arr_sorted = sorted(arr)\n",
    "        idx = max(0, min(len(arr_sorted)-1, int(round((qv/100.0)*(len(arr_sorted)-1)))))\n",
    "        return arr_sorted[idx]\n",
    "\n",
    "    mean_total = statistics.fmean(total_ms_list)\n",
    "    fps_mean   = 1000.0 / mean_total if mean_total > 0 else 0.0\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Frames: {len(total_ms_list)}\")\n",
    "    print(f\"Infer  : mean={statistics.fmean(infer_ms_list):.1f} ms\")\n",
    "    print(f\"toCPU  : mean={statistics.fmean(tocpu_ms_list):.1f} ms\")\n",
    "    print(f\"Post   : mean={statistics.fmean(post_ms_list):.1f} ms\")\n",
    "    print(f\"Total  : mean={mean_total:.1f} ms  |  FPS≈{fps_mean:.2f}\")\n",
    "    print(f\"Total  : min={min(total_ms_list):.1f}  p50={q(total_ms_list,50):.1f}  \"\n",
    "          f\"p90={q(total_ms_list,90):.1f}  p99={q(total_ms_list,99):.1f}  max={max(total_ms_list):.1f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908fb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[BOOT] movement muted\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "Benchmarking 42 frames from: /Users/marcus/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
      "\n",
      "           frame   infer(ms)   toCPU(ms)   post(ms)   total(ms)\n",
      "[BOOT] movement unmuted\n",
      "       00001.png       645.3         1.0      143.8       790.2\n",
      "       00002.png       144.1         2.0       80.8       226.9\n",
      "       00003.png        66.4         0.7      142.9       210.0\n",
      "       00004.png       204.6         1.1      141.7       347.4\n",
      "       00005.png        59.5         1.1      110.3       170.8\n",
      "       00006.png       133.7       179.1      138.1       450.9\n",
      "       00007.png        63.5         1.1      109.0       173.6\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Live overlays + lane-aware curved sampling (optimized postproc)\n",
    "# • Parsec focus + auto click\n",
    "# • mss live capture of a crop region\n",
    "# • Arrow keys switch lane (0/1/2) -> JAKE_POINT updates per frame\n",
    "# • Full overlay rendering + per-frame save\n",
    "# • Prints compact timing per frame\n",
    "# • RETURNS per frame: tri_positions, best_idx, tri_hit_classes, tri_summary (for movement logic)\n",
    "\n",
    "import os, time, math, subprocess, statistics\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "from ultralytics import YOLO\n",
    "from threading import Timer\n",
    "from threading import Thread\n",
    "\n",
    "# -------------------\n",
    "# Timing accumulators\n",
    "# -------------------\n",
    "infer_ms_list  = []\n",
    "tocpu_ms_list  = []\n",
    "post_ms_list   = []\n",
    "total_ms_list  = []\n",
    "loop_dt_ms_list = []\n",
    "\n",
    "t_run_start = time.perf_counter()\n",
    "\n",
    "# --- swallow AI-generated keypresses in the listener for a short window ---\n",
    "SYNTHETIC_SUPPRESS_S = 0.15  # 150 ms is plenty\n",
    "_synth_block_until = 0.0     # simple, explicit init avoids IDE warnings\n",
    "\n",
    "try:\n",
    "    _synth_block_until\n",
    "except NameError:\n",
    "    _synth_block_until = 0.0\n",
    "\n",
    "# ======================= Quick supreesion to prevent instant bailouts =======================\n",
    "\n",
    "# --- allows 0.5s of movement, then mute for 2.5s, then restore ---\n",
    "# Save originals\n",
    "__press_orig   = pyautogui.press\n",
    "__keyDown_orig = pyautogui.keyDown\n",
    "__keyUp_orig   = pyautogui.keyUp\n",
    "__hotkey_orig  = pyautogui.hotkey\n",
    "\n",
    "# near your other globals, after imports\n",
    "MOVEMENT_ENABLED = True\n",
    "\n",
    "def __mute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = False\n",
    "    pyautogui.press  = lambda *a, **k: None\n",
    "    pyautogui.keyDown = lambda *a, **k: None\n",
    "    pyautogui.keyUp   = lambda *a, **k: None\n",
    "    pyautogui.hotkey  = lambda *a, **k: None\n",
    "    print(\"[BOOT] movement muted\")\n",
    "\n",
    "def __unmute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = True\n",
    "    pyautogui.press   = __press_orig\n",
    "    pyautogui.keyDown = __keyDown_orig\n",
    "    pyautogui.keyUp   = __keyUp_orig\n",
    "    pyautogui.hotkey  = __hotkey_orig\n",
    "    print(\"[BOOT] movement unmuted\")\n",
    "\n",
    "\n",
    "# Allow movement immediately; after 0.5s, mute; after 3.0s total, unmute\n",
    "Timer(0.5, __mute_keys).start()\n",
    "Timer(4.0, __unmute_keys).start()\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "# SAVE HERE\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_live_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crop + click (set by ad layout)\n",
    "advertisement = True\n",
    "if advertisement:\n",
    "    snap_coords = (644, 77, (1149-644), (981-75))  # (left, top, width, height)\n",
    "    start_click = (1030, 900)\n",
    "else:\n",
    "    snap_coords = (483, 75, (988-483), (981-75))\n",
    "    start_click = (870, 895)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 200\n",
    "RAY_STEP_PX         = 20   # walk the ray every 20 px\n",
    "\n",
    "# ===== Bend degrees (tune here) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0  # N1\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0  # N2\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0  # N3\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0  # N4\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "COLOR_CYAN   = (255, 255, 0)\n",
    "COLOR_BLACK  = (0, 0, 0)\n",
    "\n",
    "# =======================\n",
    "# Jake lane points + dynamic JAKE_POINT\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)  # index by lane (0,1,2)\n",
    "JAKE_POINT  = LANE_MID  # will be set each frame from 'lane'\n",
    "\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "\n",
    "# ===== Movement logic (modular) HELPER FUNCTIOSNS==============================================================================================================\n",
    "\n",
    "# --- tunnel wall color gate (HSV) ---\n",
    "LOWBARRIER1_ID   = 4\n",
    "ORANGETRAIN_ID   = 6\n",
    "WALL_STRIP_PX    = 20           # vertical strip height checked just above the barrier\n",
    "WALL_MATCH_FRAC  = 0.40         # % of “wall” pixels required to relabel\n",
    "WALL_ORANGE_LO = np.array([5,  80,  60], dtype=np.uint8)   # H,S,V (lo)\n",
    "WALL_ORANGE_HI = np.array([35, 255, 255], dtype=np.uint8)  # H,S,V (hi)\n",
    "\n",
    "\n",
    "def promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np,\n",
    "                                 strip_px=WALL_STRIP_PX, frac_thresh=WALL_MATCH_FRAC):\n",
    "    \"\"\"\n",
    "    If a LOWBARRIER1 has an orange 'tunnel wall' strip right behind it,\n",
    "    relabel that instance to ORANGETRAIN (treated as RED).\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return classes_np\n",
    "\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    wall_u8 = cv2.inRange(hsv, WALL_ORANGE_LO, WALL_ORANGE_HI)  # 0/255\n",
    "\n",
    "    # iterate only over LOWBARRIER1 instances\n",
    "    for i, cls in enumerate(classes_np):\n",
    "        if int(cls) != LOWBARRIER1_ID:\n",
    "            continue\n",
    "\n",
    "        m = masks_np[i]\n",
    "        # upsample to frame size if needed\n",
    "        if m.shape != (H, W):\n",
    "            m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        else:\n",
    "            m_full = m.astype(bool, copy=False)\n",
    "\n",
    "        ys, xs = np.where(m_full)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        x0, x1 = xs.min(), xs.max()\n",
    "        y0, _  = ys.min(), ys.max()\n",
    "\n",
    "        # check a strip immediately above the barrier (toward smaller y)\n",
    "        yb0 = max(0, y0 - strip_px)\n",
    "        yb1 = y0\n",
    "        if yb1 <= yb0:\n",
    "            continue\n",
    "\n",
    "        strip = wall_u8[yb0:yb1, x0:x1+1]\n",
    "        if strip.size == 0:\n",
    "            continue\n",
    "\n",
    "        frac = float(cv2.countNonZero(strip)) / strip.size\n",
    "        if frac >= frac_thresh:\n",
    "            classes_np[i] = ORANGETRAIN_ID  # promote to a RED class\n",
    "\n",
    "    return classes_np\n",
    "\n",
    "\n",
    "# extra classes/sets\n",
    "WARN_FOR_MOVE = {2, 3, 4, 5, 8}      # yellow set that should try to sidestep if a green exists\n",
    "JUMP_SET      = {3, 5, 10}           # Jump, LowBarrier2, Sidewalk\n",
    "DUCK_SET      = {2, 4}               # HighBarrier1, LowBarrier1\n",
    "\n",
    "# action keys (change if your emulator uses different binds)\n",
    "JUMP_KEY = \"up\"\n",
    "DUCK_KEY = \"down\"\n",
    "\n",
    "# --- \"white-ish\" lane probe (5x5 box counts) ---\n",
    "# tune these if your Jake sprite/board highlight isn't pure white\n",
    "WHITE_MIN = np.array([220, 220, 220], dtype=np.uint8)  # BGR lower bound\n",
    "WHITE_MAX = np.array([255, 255, 255], dtype=np.uint8)  # BGR upper bound\n",
    "BOX_RAD   = 2  # 5x5 => radius 2\n",
    "\n",
    "def _count_white_around(img_bgr, pt, box_rad=BOX_RAD):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    x, y = pt\n",
    "    x0 = max(0, x - box_rad); x1 = min(W, x + box_rad + 1)\n",
    "    y0 = max(0, y - box_rad); y1 = min(H, y + box_rad + 1)\n",
    "    roi = img_bgr[y0:y1, x0:x1]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "    mask = cv2.inRange(roi, WHITE_MIN, WHITE_MAX)\n",
    "    return int(cv2.countNonZero(mask))\n",
    "\n",
    "def _detect_lane_by_whiteness(img_bgr):\n",
    "    # returns lane index 0/1/2 chosen by the largest white count;\n",
    "    # if all zero, returns None to keep previous lane\n",
    "    counts = [\n",
    "        _count_white_around(img_bgr, LANE_LEFT),\n",
    "        _count_white_around(img_bgr, LANE_MID),\n",
    "        _count_white_around(img_bgr, LANE_RIGHT),\n",
    "    ]\n",
    "    best_idx = int(np.argmax(counts))\n",
    "    return best_idx if counts[best_idx] > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# action cooldown so we don't spam jump/duck\n",
    "try:\n",
    "    last_action_ts\n",
    "except NameError:\n",
    "    last_action_ts = 0.0\n",
    "ACTION_COOLDOWN_S = 0.5\n",
    "\n",
    "# distance threshold (pixels) from Jake to triangle apex for action decisions\n",
    "ACTION_DIST_PX = 30\n",
    "\n",
    "def _is_warn(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in WARN_FOR_MOVE)\n",
    "\n",
    "def _dist_px(jx: int, jy: int, tx: int, ty: int) -> float:\n",
    "    return math.hypot(tx - jx, ty - jy)\n",
    "\n",
    "def _pick_best_green(cands, jx: int):\n",
    "    \"\"\"Choose the closest triangle with hit_class == None (no hit along ray).\"\"\"\n",
    "    greens = [c for c in cands if c[\"hit_class\"] is None]\n",
    "    if not greens:\n",
    "        return None\n",
    "    greens = [c for c in greens if c[\"pos\"][0] != jx] or greens\n",
    "    return min(greens, key=lambda c: abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "def _schedule(fn, *args, **kwargs):\n",
    "    Thread(target=fn, args=args, kwargs=kwargs, daemon=True).start()\n",
    "\n",
    "def _do_jump_then_duck(delay_s: float = 0.50):\n",
    "    pyautogui.press(JUMP_KEY)\n",
    "    time.sleep(delay_s)\n",
    "    pyautogui.press(DUCK_KEY)\n",
    "\n",
    "def _try_jump_then_duck():\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "    global last_action_ts\n",
    "    now = time.perf_counter()\n",
    "    if now - last_action_ts >= ACTION_COOLDOWN_S:\n",
    "        last_action_ts = now\n",
    "        _schedule(_do_jump_then_duck, 0.20)\n",
    "\n",
    "MIN_GREEN_AHEAD_PX = 400\n",
    "def _filter_green_far(cands, jake_band_y: int, min_ahead_px: int = MIN_GREEN_AHEAD_PX):\n",
    "    \"\"\"Keep only green triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:  # keep if ≥ 400 px ahead\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def first_red_hit_y(pos, masks_np, classes_np, H, W, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first RED pixel straight above `pos`, or None.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    red_idx = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    if not red_idx: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "def first_hit_y(pos, masks_np, classes_np, H, W, class_set, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first pixel (straight up) whose class ∈ class_set.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    idxs = [i for i, c in enumerate(classes_np) if int(c) in class_set]\n",
    "    if not idxs: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in idxs:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "\n",
    "# Only step from RED into a YELLOW lane if its triangle is far enough ahead\n",
    "MIN_YELLOW_AHEAD_PX = 400\n",
    "def _filter_yellow_far(cands, jake_band_y: int, min_ahead_px: int = MIN_YELLOW_AHEAD_PX):\n",
    "    \"\"\"Keep only yellow triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _try_duck():\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "    global last_action_ts\n",
    "    now = time.perf_counter()\n",
    "    if now - last_action_ts >= ACTION_COOLDOWN_S:\n",
    "        last_action_ts = now\n",
    "        _schedule(pyautogui.press, DUCK_KEY)\n",
    "try:\n",
    "    last_move_ts\n",
    "except NameError:\n",
    "    last_move_ts = 0.0\n",
    "\n",
    "MOVE_COOLDOWN_S = 0.10  # 100 ms\n",
    "\n",
    "def _is_danger(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in DANGER_RED)\n",
    "\n",
    "def _is_safe(cls_id: int | None) -> bool:\n",
    "    return not _is_danger(cls_id)\n",
    "\n",
    "def _filter_by_lane(cands, jx: int, lane_idx: int):\n",
    "    \"\"\"Prune triangles based on current lane:\n",
    "       - lane 0 (left): drop triangles with x < jx\n",
    "       - lane 2 (right): drop triangles with x > jx\n",
    "       - lane 1 (mid): keep all\n",
    "    \"\"\"\n",
    "    if lane_idx == 0:\n",
    "        return [c for c in cands if c[\"pos\"][0] >= jx]\n",
    "    if lane_idx == 2:\n",
    "        return [c for c in cands if c[\"pos\"][0] <= jx]\n",
    "    return cands\n",
    "\n",
    "def _pick_best_safe_triangle(cands, jx: int):\n",
    "    \"\"\"Prefer triangles with hit_class == None; otherwise any non-danger.\n",
    "       Break ties by smallest |x - jx|.\n",
    "    \"\"\"\n",
    "    if not cands:\n",
    "        return None\n",
    "    none_hits  = [c for c in cands if c[\"hit_class\"] is None]\n",
    "    safe_hits  = [c for c in cands if c[\"hit_class\"] is not None and _is_safe(c[\"hit_class\"])]\n",
    "    pool = none_hits if none_hits else safe_hits\n",
    "    if not pool:\n",
    "        return None\n",
    "    # exclude triangles exactly aligned with Jake in x (no direction)\n",
    "    pool = [c for c in pool if c[\"pos\"][0] != jx] or pool\n",
    "    return min(pool, key=lambda c: abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "def _issue_move_towards_x(jx: int, tx: int):\n",
    "    global lane, last_move_ts, _synth_block_until\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "\n",
    "    now = time.perf_counter()\n",
    "    if now - last_move_ts < MOVE_COOLDOWN_S:\n",
    "        return\n",
    "\n",
    "    if tx < jx and lane > MIN_LANE:\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('left')\n",
    "        lane = max(MIN_LANE, lane - 1)\n",
    "        print(f\"[AI MOVE] left -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "\n",
    "    elif tx > jx and lane < MAX_LANE:\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('right')\n",
    "        lane = min(MAX_LANE, lane + 1)\n",
    "        print(f\"[AI MOVE] right -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "    else:\n",
    "        print('WE ARE COOKED')\n",
    "\n",
    "\n",
    "#============================================================================================================================================\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Lane/keyboard state\n",
    "# =======================\n",
    "lane = 1\n",
    "MIN_LANE = 0\n",
    "MAX_LANE = 2\n",
    "running = True\n",
    "\n",
    "# ===== Debounce / cooldown =====\n",
    "COOLDOWN_MS = 20\n",
    "_last_press_ts = 0.0  # monotonic seconds\n",
    "\n",
    "def on_press(key):\n",
    "    global lane, running, _last_press_ts, _synth_block_until\n",
    "    now = time.monotonic()\n",
    "\n",
    "    # swallow AI-generated lane key events during the suppression window\n",
    "    if key in (keyboard.Key.left, keyboard.Key.right) and now < _synth_block_until:\n",
    "        return\n",
    "\n",
    "    if key != keyboard.Key.esc and (now - _last_press_ts) * 1000.0 < COOLDOWN_MS:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if key == keyboard.Key.left:\n",
    "            lane = max(MIN_LANE, lane - 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Left into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.right:\n",
    "            lane = min(MAX_LANE, lane + 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Right into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.esc:\n",
    "            running = False\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# Class buckets for probe classification\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "def _fmt_px(v):\n",
    "    return f\"{v:.1f}px\" if v is not None else \"n/a\"\n",
    "\n",
    "# =======================\n",
    "# Parsec to front + click Start (non-blocking failures)\n",
    "# =======================\n",
    "try:\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell application \"Parsec\" to activate'], check=False)\n",
    "    time.sleep(0.4)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pyautogui.click(start_click)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # must be above Jake\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "# --------- walk-the-ray classifier (first-hit wins) ----------\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], [], [], []  # colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays, hit_class_ids, hit_distances_px = [], [], [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_colour = COLOR_GREEN\n",
    "        hit_cls = None\n",
    "        hit_dist_px = None\n",
    "\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            # RED first (so if red exists at a point, we record red distance)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_RED\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then YELLOW\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_YELLOW\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then BOOTS\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_PINK\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "\n",
    "        x1 = _clampi(int(round(x0 + dx1 * sample_px)), 0, W-1)\n",
    "        y1 = _clampi(int(round(y0 + dy1 * sample_px)), 0, H-1)\n",
    "\n",
    "        colours.append(hit_colour)\n",
    "        rays.append(((int(x0), int(y0)), (x1, y1), float(theta)))\n",
    "        hit_class_ids.append(hit_cls)\n",
    "        hit_distances_px.append(hit_dist_px)\n",
    "\n",
    "    return colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    \"\"\"\n",
    "    Returns (…)\n",
    "      tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "      masks_np, classes_np, rail_mask, green_mask,\n",
    "      tri_positions, tri_colours, tri_rays,\n",
    "      best_idx, best_deg, x_ref,\n",
    "      tri_hit_classes, tri_summary\n",
    "    \"\"\"\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return (None, 0, 0, 0.0, 0.0, None, None, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    classes_np = promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np)\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Jake triangle by bearing\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    x_ref = tri_positions[best_idx][0] if (lane_name == \"mid\" and best_idx is not None and 0 <= best_idx < len(tri_positions)) else xj\n",
    "\n",
    "    tri_colours, tri_rays, tri_hit_classes, tri_hit_dists = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    # Minimal summary (useful later if you want to analyze decisions offline)\n",
    "    tri_summary = []\n",
    "    for i, (x, y) in enumerate(tri_positions):\n",
    "        cid = tri_hit_classes[i] if i < len(tri_hit_classes) else None\n",
    "        hdist = tri_hit_dists[i] if i < len(tri_hit_dists) else None\n",
    "        tri_summary.append({\n",
    "            \"pos\": (int(x), int(y)),\n",
    "            \"hit_class\": None if cid is None else int(cid),\n",
    "            \"hit_label\": None if cid is None else LABELS.get(int(cid), f\"C{int(cid)}\"),\n",
    "            \"hit_dist_px\": None if hdist is None else float(hdist),\n",
    "            \"is_jake\": (i == best_idx)\n",
    "        })\n",
    "\n",
    "    return (tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms,\n",
    "            masks_np, classes_np, rail_mask, green,\n",
    "            tri_positions, tri_colours, tri_rays,\n",
    "            best_idx, best_deg, x_ref,\n",
    "            tri_hit_classes, tri_summary)\n",
    "\n",
    "# =======================\n",
    "# Main benchmark\n",
    "# =======================\n",
    "def main():\n",
    "    # Locate frames\n",
    "    root = Path.cwd()\n",
    "    frames_dir = root / \"frames\"\n",
    "    if not frames_dir.exists():\n",
    "        alt = root / \"alpha\" / \"frames\"\n",
    "        if alt.exists():\n",
    "            frames_dir = alt\n",
    "    if not frames_dir.exists():\n",
    "        raise SystemExit(\"No ./frames or ./alpha/frames directory found.\")\n",
    "\n",
    "    img_paths = sorted(\n",
    "        [p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\") for p in frames_dir.glob(ext)]\n",
    "    )\n",
    "    if not img_paths:\n",
    "        raise SystemExit(f\"No images in {frames_dir}\")\n",
    "\n",
    "    # Backend\n",
    "    cv2.setUseOptimized(True)\n",
    "    try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "    except Exception: pass\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device, half = 0, True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        try: torch.set_float32_matmul_precision('high')\n",
    "        except Exception: pass\n",
    "    elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        device, half = \"mps\", False\n",
    "    else:\n",
    "        device, half = \"cpu\", False\n",
    "\n",
    "    # Model\n",
    "    model = YOLO(weights)\n",
    "    try: model.fuse()\n",
    "    except Exception: pass\n",
    "\n",
    "    # Warmup\n",
    "    _dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "    _ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                      conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "    # Timing accumulators\n",
    "    infer_ms_list = []\n",
    "    tocpu_ms_list = []\n",
    "    post_ms_list  = []\n",
    "    total_ms_list = []\n",
    "\n",
    "    # Assume we start mid-lane for the bearing math\n",
    "    JAKE_POINT = LANE_MID\n",
    "\n",
    "    print(f\"Benchmarking {len(img_paths)} frames from: {frames_dir}\\n\")\n",
    "    print(f\"{'frame':>16}  {'infer(ms)':>10}  {'toCPU(ms)':>10}  {'post(ms)':>9}  {'total(ms)':>10}\")\n",
    "\n",
    "    for p in img_paths:\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            [img], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "        )\n",
    "        infer_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        yres = res_list[0]\n",
    "\n",
    "        # Postproc (returns component timings)\n",
    "        (_, _, _, to_cpu_ms, post_ms,\n",
    "         _, _, _, _,\n",
    "         _, _, _,\n",
    "         _, _, _,\n",
    "         _, _) = process_frame_post(img, yres, JAKE_POINT)\n",
    "\n",
    "        total_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "        infer_ms_list.append(infer_ms)\n",
    "        tocpu_ms_list.append(to_cpu_ms)\n",
    "        post_ms_list.append(post_ms)\n",
    "        total_ms_list.append(total_ms)\n",
    "\n",
    "        print(f\"{p.name:>16}  {infer_ms:10.1f}  {to_cpu_ms:10.1f}  {post_ms:9.1f}  {total_ms:10.1f}\")\n",
    "\n",
    "    # Summary\n",
    "    def q(arr, qv):  # percentile helper\n",
    "        arr_sorted = sorted(arr)\n",
    "        idx = max(0, min(len(arr_sorted)-1, int(round((qv/100.0)*(len(arr_sorted)-1)))))\n",
    "        return arr_sorted[idx]\n",
    "\n",
    "    mean_total = statistics.fmean(total_ms_list)\n",
    "    fps_mean   = 1000.0 / mean_total if mean_total > 0 else 0.0\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Frames: {len(total_ms_list)}\")\n",
    "    print(f\"Infer  : mean={statistics.fmean(infer_ms_list):.1f} ms\")\n",
    "    print(f\"toCPU  : mean={statistics.fmean(tocpu_ms_list):.1f} ms\")\n",
    "    print(f\"Post   : mean={statistics.fmean(post_ms_list):.1f} ms\")\n",
    "    print(f\"Total  : mean={mean_total:.1f} ms  |  FPS≈{fps_mean:.2f}\")\n",
    "    print(f\"Total  : min={min(total_ms_list):.1f}  p50={q(total_ms_list,50):.1f}  \"\n",
    "          f\"p90={q(total_ms_list,90):.1f}  p99={q(total_ms_list,99):.1f}  max={max(total_ms_list):.1f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a396cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[BOOT] movement muted\n",
      "/n\n",
      "===================================== Operating on frame 1 =====================================\n",
      "[SYS] CPU: 23.6%  |  RAM: 480.3 MB\n",
      "[TIMINGS] Grab=82.75 ms | PixelChk=28.88 ms | LaneDet=0.24 ms | Inference=657.43 ms | Postproc=165.52 ms | Overlay=0.00 ms | TOTAL=937.34 ms\n",
      "/n\n",
      "===================================== Operating on frame 2 =====================================\n",
      "[SYS] CPU: 41.2%  |  RAM: 556.2 MB\n",
      "[TIMINGS] Grab=50.97 ms | PixelChk=29.02 ms | LaneDet=0.08 ms | Inference=42.60 ms | Postproc=125.46 ms | Overlay=0.00 ms | TOTAL=248.30 ms\n",
      "/n\n",
      "===================================== Operating on frame 3 =====================================\n",
      "[BOOT] movement unmuted\n",
      "[SYS] CPU: 52.5%  |  RAM: 528.9 MB\n",
      "[TIMINGS] Grab=36.85 ms | PixelChk=24.61 ms | LaneDet=0.04 ms | Inference=38.20 ms | Postproc=128.72 ms | Overlay=0.00 ms | TOTAL=228.86 ms\n",
      "/n\n",
      "===================================== Operating on frame 4 =====================================\n",
      "[SYS] CPU: 44.1%  |  RAM: 544.8 MB\n",
      "[TIMINGS] Grab=23.32 ms | PixelChk=16.72 ms | LaneDet=0.05 ms | Inference=65.48 ms | Postproc=135.21 ms | Overlay=0.00 ms | TOTAL=240.92 ms\n",
      "/n\n",
      "===================================== Operating on frame 5 =====================================\n",
      "[SYS] CPU: 35.6%  |  RAM: 570.9 MB\n",
      "[TIMINGS] Grab=30.75 ms | PixelChk=19.81 ms | LaneDet=0.05 ms | Inference=38.06 ms | Postproc=130.32 ms | Overlay=0.00 ms | TOTAL=219.21 ms\n",
      "/n\n",
      "===================================== Operating on frame 6 =====================================\n",
      "[SYS] CPU: 39.4%  |  RAM: 541.3 MB\n",
      "[TIMINGS] Grab=27.16 ms | PixelChk=19.75 ms | LaneDet=0.04 ms | Inference=38.37 ms | Postproc=135.42 ms | Overlay=0.00 ms | TOTAL=220.90 ms\n",
      "/n\n",
      "===================================== Operating on frame 7 =====================================\n",
      "[SYS] CPU: 46.6%  |  RAM: 536.0 MB\n",
      "[TIMINGS] Grab=46.97 ms | PixelChk=35.62 ms | LaneDet=0.05 ms | Inference=155.29 ms | Postproc=133.78 ms | Overlay=0.00 ms | TOTAL=371.97 ms\n",
      "/n\n",
      "===================================== Operating on frame 8 =====================================\n",
      "[SYS] CPU: 29.0%  |  RAM: 495.5 MB\n",
      "[TIMINGS] Grab=34.71 ms | PixelChk=18.11 ms | LaneDet=0.05 ms | Inference=28.88 ms | Postproc=0.79 ms | Overlay=0.00 ms | TOTAL=82.72 ms\n",
      "/n\n",
      "===================================== Operating on frame 9 =====================================\n",
      "[SYS] CPU: 27.6%  |  RAM: 518.0 MB\n",
      "[TIMINGS] Grab=26.31 ms | PixelChk=18.31 ms | LaneDet=0.05 ms | Inference=28.94 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=73.88 ms\n",
      "/n\n",
      "===================================== Operating on frame 10 =====================================\n",
      "[SYS] CPU: 45.2%  |  RAM: 504.5 MB\n",
      "[TIMINGS] Grab=33.41 ms | PixelChk=25.98 ms | LaneDet=0.05 ms | Inference=30.81 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=90.72 ms\n",
      "/n\n",
      "===================================== Operating on frame 11 =====================================\n",
      "[SYS] CPU: 21.7%  |  RAM: 505.1 MB\n",
      "[TIMINGS] Grab=26.65 ms | PixelChk=20.80 ms | LaneDet=0.06 ms | Inference=28.60 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=76.34 ms\n",
      "/n\n",
      "===================================== Operating on frame 12 =====================================\n",
      "[SYS] CPU: 23.8%  |  RAM: 505.7 MB\n",
      "[TIMINGS] Grab=31.08 ms | PixelChk=16.89 ms | LaneDet=0.05 ms | Inference=29.16 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=77.33 ms\n",
      "/n\n",
      "===================================== Operating on frame 13 =====================================\n",
      "[SYS] CPU: 40.3%  |  RAM: 484.6 MB\n",
      "[TIMINGS] Grab=37.86 ms | PixelChk=18.00 ms | LaneDet=0.05 ms | Inference=29.12 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=85.16 ms\n",
      "/n\n",
      "===================================== Operating on frame 14 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 489.3 MB\n",
      "[TIMINGS] Grab=27.78 ms | PixelChk=19.07 ms | LaneDet=0.04 ms | Inference=24.87 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=71.93 ms\n",
      "/n\n",
      "===================================== Operating on frame 15 =====================================\n",
      "[SYS] CPU: 36.5%  |  RAM: 481.8 MB\n",
      "[TIMINGS] Grab=36.10 ms | PixelChk=22.39 ms | LaneDet=0.05 ms | Inference=29.92 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=89.35 ms\n",
      "/n\n",
      "===================================== Operating on frame 16 =====================================\n",
      "[SYS] CPU: 65.2%  |  RAM: 474.3 MB\n",
      "[TIMINGS] Grab=28.17 ms | PixelChk=25.53 ms | LaneDet=0.06 ms | Inference=31.07 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=85.17 ms\n",
      "/n\n",
      "===================================== Operating on frame 17 =====================================\n",
      "[SYS] CPU: 49.2%  |  RAM: 457.4 MB\n",
      "[TIMINGS] Grab=26.69 ms | PixelChk=24.04 ms | LaneDet=0.07 ms | Inference=30.19 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=81.15 ms\n",
      "/n\n",
      "===================================== Operating on frame 18 =====================================\n",
      "[SYS] CPU: 33.9%  |  RAM: 472.2 MB\n",
      "[TIMINGS] Grab=24.38 ms | PixelChk=19.26 ms | LaneDet=0.05 ms | Inference=85.61 ms | Postproc=11.60 ms | Overlay=0.00 ms | TOTAL=141.04 ms\n",
      "/n\n",
      "===================================== Operating on frame 19 =====================================\n",
      "[SYS] CPU: 22.4%  |  RAM: 567.1 MB\n",
      "[TIMINGS] Grab=21.34 ms | PixelChk=16.35 ms | LaneDet=0.05 ms | Inference=38.89 ms | Postproc=125.66 ms | Overlay=0.00 ms | TOTAL=202.47 ms\n",
      "/n\n",
      "===================================== Operating on frame 20 =====================================\n",
      "[SYS] CPU: 23.6%  |  RAM: 574.5 MB\n",
      "[TIMINGS] Grab=24.25 ms | PixelChk=16.31 ms | LaneDet=0.04 ms | Inference=37.07 ms | Postproc=123.18 ms | Overlay=0.00 ms | TOTAL=201.11 ms\n",
      "/n\n",
      "===================================== Operating on frame 21 =====================================\n",
      "[SYS] CPU: 33.3%  |  RAM: 579.0 MB\n",
      "[TIMINGS] Grab=22.41 ms | PixelChk=18.03 ms | LaneDet=0.04 ms | Inference=39.55 ms | Postproc=127.15 ms | Overlay=0.00 ms | TOTAL=207.36 ms\n",
      "/n\n",
      "===================================== Operating on frame 22 =====================================\n",
      "[SYS] CPU: 37.2%  |  RAM: 590.4 MB\n",
      "[TIMINGS] Grab=23.74 ms | PixelChk=17.26 ms | LaneDet=0.06 ms | Inference=36.57 ms | Postproc=126.26 ms | Overlay=0.00 ms | TOTAL=204.13 ms\n",
      "/n\n",
      "===================================== Operating on frame 23 =====================================\n",
      "[SYS] CPU: 52.0%  |  RAM: 520.4 MB\n",
      "[TIMINGS] Grab=25.74 ms | PixelChk=17.97 ms | LaneDet=0.05 ms | Inference=41.70 ms | Postproc=130.15 ms | Overlay=0.00 ms | TOTAL=215.85 ms\n",
      "/n\n",
      "===================================== Operating on frame 24 =====================================\n",
      "[SYS] CPU: 31.9%  |  RAM: 562.0 MB\n",
      "[TIMINGS] Grab=33.50 ms | PixelChk=20.63 ms | LaneDet=0.05 ms | Inference=64.89 ms | Postproc=136.36 ms | Overlay=0.00 ms | TOTAL=255.79 ms\n",
      "/n\n",
      "===================================== Operating on frame 25 =====================================\n",
      "[SYS] CPU: 38.8%  |  RAM: 579.9 MB\n",
      "[TIMINGS] Grab=28.05 ms | PixelChk=16.87 ms | LaneDet=0.04 ms | Inference=38.13 ms | Postproc=127.08 ms | Overlay=0.00 ms | TOTAL=210.61 ms\n",
      "/n\n",
      "===================================== Operating on frame 26 =====================================\n",
      "[SYS] CPU: 22.9%  |  RAM: 595.9 MB\n",
      "[TIMINGS] Grab=36.02 ms | PixelChk=17.12 ms | LaneDet=0.06 ms | Inference=37.64 ms | Postproc=125.72 ms | Overlay=0.00 ms | TOTAL=216.95 ms\n",
      "/n\n",
      "===================================== Operating on frame 27 =====================================\n",
      "[SYS] CPU: 29.5%  |  RAM: 574.4 MB\n",
      "[TIMINGS] Grab=33.06 ms | PixelChk=17.24 ms | LaneDet=0.04 ms | Inference=38.44 ms | Postproc=126.53 ms | Overlay=0.00 ms | TOTAL=215.49 ms\n",
      "/n\n",
      "===================================== Operating on frame 28 =====================================\n",
      "[SYS] CPU: 36.5%  |  RAM: 579.6 MB\n",
      "[TIMINGS] Grab=26.36 ms | PixelChk=19.02 ms | LaneDet=0.05 ms | Inference=38.91 ms | Postproc=126.28 ms | Overlay=0.00 ms | TOTAL=210.90 ms\n",
      "/n\n",
      "===================================== Operating on frame 29 =====================================\n",
      "[SYS] CPU: 31.1%  |  RAM: 593.7 MB\n",
      "[TIMINGS] Grab=25.35 ms | PixelChk=17.03 ms | LaneDet=0.04 ms | Inference=36.92 ms | Postproc=124.80 ms | Overlay=0.00 ms | TOTAL=204.27 ms\n",
      "/n\n",
      "===================================== Operating on frame 30 =====================================\n",
      "[SYS] CPU: 31.0%  |  RAM: 596.3 MB\n",
      "[TIMINGS] Grab=24.36 ms | PixelChk=17.45 ms | LaneDet=0.05 ms | Inference=39.18 ms | Postproc=126.07 ms | Overlay=0.00 ms | TOTAL=207.30 ms\n",
      "/n\n",
      "===================================== Operating on frame 31 =====================================\n",
      "[SYS] CPU: 28.3%  |  RAM: 587.4 MB\n",
      "[TIMINGS] Grab=22.84 ms | PixelChk=16.73 ms | LaneDet=0.04 ms | Inference=40.21 ms | Postproc=122.47 ms | Overlay=0.00 ms | TOTAL=202.50 ms\n",
      "/n\n",
      "===================================== Operating on frame 32 =====================================\n",
      "[SYS] CPU: 25.7%  |  RAM: 615.1 MB\n",
      "[TIMINGS] Grab=28.17 ms | PixelChk=19.30 ms | LaneDet=0.04 ms | Inference=38.04 ms | Postproc=124.25 ms | Overlay=0.00 ms | TOTAL=210.22 ms\n",
      "/n\n",
      "===================================== Operating on frame 33 =====================================\n",
      "[SYS] CPU: 53.3%  |  RAM: 609.4 MB\n",
      "[TIMINGS] Grab=44.50 ms | PixelChk=20.44 ms | LaneDet=0.05 ms | Inference=37.83 ms | Postproc=141.11 ms | Overlay=0.00 ms | TOTAL=244.06 ms\n",
      "/n\n",
      "===================================== Operating on frame 34 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 623.7 MB\n",
      "[TIMINGS] Grab=24.64 ms | PixelChk=17.67 ms | LaneDet=0.04 ms | Inference=35.53 ms | Postproc=121.93 ms | Overlay=0.00 ms | TOTAL=200.07 ms\n",
      "/n\n",
      "===================================== Operating on frame 35 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 634.6 MB\n",
      "[TIMINGS] Grab=23.15 ms | PixelChk=18.40 ms | LaneDet=0.04 ms | Inference=35.75 ms | Postproc=125.95 ms | Overlay=0.00 ms | TOTAL=204.05 ms\n",
      "/n\n",
      "===================================== Operating on frame 36 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 644.3 MB\n",
      "[TIMINGS] Grab=23.84 ms | PixelChk=17.16 ms | LaneDet=0.05 ms | Inference=37.95 ms | Postproc=124.82 ms | Overlay=0.00 ms | TOTAL=203.95 ms\n",
      "/n\n",
      "===================================== Operating on frame 37 =====================================\n",
      "[SYS] CPU: 33.1%  |  RAM: 595.6 MB\n",
      "[TIMINGS] Grab=29.78 ms | PixelChk=18.55 ms | LaneDet=0.05 ms | Inference=37.89 ms | Postproc=122.97 ms | Overlay=0.00 ms | TOTAL=210.17 ms\n",
      "/n\n",
      "===================================== Operating on frame 38 =====================================\n",
      "[SYS] CPU: 22.6%  |  RAM: 597.9 MB\n",
      "[TIMINGS] Grab=23.20 ms | PixelChk=16.98 ms | LaneDet=0.04 ms | Inference=38.08 ms | Postproc=121.70 ms | Overlay=0.00 ms | TOTAL=200.39 ms\n",
      "/n\n",
      "===================================== Operating on frame 39 =====================================\n",
      "[SYS] CPU: 23.4%  |  RAM: 598.0 MB\n",
      "[TIMINGS] Grab=31.41 ms | PixelChk=18.07 ms | LaneDet=0.04 ms | Inference=37.33 ms | Postproc=121.25 ms | Overlay=0.00 ms | TOTAL=208.23 ms\n",
      "/n\n",
      "===================================== Operating on frame 40 =====================================\n",
      "[SYS] CPU: 30.2%  |  RAM: 608.5 MB\n",
      "[TIMINGS] Grab=39.24 ms | PixelChk=26.64 ms | LaneDet=0.05 ms | Inference=39.17 ms | Postproc=123.29 ms | Overlay=0.00 ms | TOTAL=228.62 ms\n",
      "/n\n",
      "===================================== Operating on frame 41 =====================================\n",
      "[SYS] CPU: 36.2%  |  RAM: 604.1 MB\n",
      "[TIMINGS] Grab=21.71 ms | PixelChk=17.96 ms | LaneDet=0.05 ms | Inference=74.29 ms | Postproc=119.45 ms | Overlay=0.00 ms | TOTAL=234.38 ms\n",
      "/n\n",
      "===================================== Operating on frame 42 =====================================\n",
      "[SYS] CPU: 22.1%  |  RAM: 622.8 MB\n",
      "[TIMINGS] Grab=36.49 ms | PixelChk=18.89 ms | LaneDet=0.04 ms | Inference=37.56 ms | Postproc=123.40 ms | Overlay=0.00 ms | TOTAL=216.51 ms\n",
      "/n\n",
      "===================================== Operating on frame 43 =====================================\n",
      "[SYS] CPU: 26.7%  |  RAM: 624.5 MB\n",
      "[TIMINGS] Grab=30.26 ms | PixelChk=18.63 ms | LaneDet=0.04 ms | Inference=36.40 ms | Postproc=119.41 ms | Overlay=0.00 ms | TOTAL=204.90 ms\n",
      "/n\n",
      "===================================== Operating on frame 44 =====================================\n",
      "[SYS] CPU: 32.9%  |  RAM: 619.7 MB\n",
      "[TIMINGS] Grab=25.26 ms | PixelChk=17.85 ms | LaneDet=0.04 ms | Inference=38.05 ms | Postproc=123.28 ms | Overlay=0.00 ms | TOTAL=204.74 ms\n",
      "/n\n",
      "===================================== Operating on frame 45 =====================================\n",
      "[SYS] CPU: 24.3%  |  RAM: 605.5 MB\n",
      "[TIMINGS] Grab=29.29 ms | PixelChk=22.11 ms | LaneDet=0.05 ms | Inference=37.66 ms | Postproc=124.26 ms | Overlay=0.00 ms | TOTAL=213.51 ms\n",
      "/n\n",
      "===================================== Operating on frame 46 =====================================\n",
      "[SYS] CPU: 19.6%  |  RAM: 618.0 MB\n",
      "[TIMINGS] Grab=22.91 ms | PixelChk=18.25 ms | LaneDet=0.05 ms | Inference=38.05 ms | Postproc=118.55 ms | Overlay=0.00 ms | TOTAL=198.17 ms\n",
      "/n\n",
      "===================================== Operating on frame 47 =====================================\n",
      "[SYS] CPU: 23.4%  |  RAM: 620.1 MB\n",
      "[TIMINGS] Grab=33.14 ms | PixelChk=18.55 ms | LaneDet=0.05 ms | Inference=39.67 ms | Postproc=122.59 ms | Overlay=0.00 ms | TOTAL=214.14 ms\n",
      "/n\n",
      "===================================== Operating on frame 48 =====================================\n",
      "[SYS] CPU: 25.9%  |  RAM: 620.2 MB\n",
      "[TIMINGS] Grab=28.63 ms | PixelChk=17.52 ms | LaneDet=0.04 ms | Inference=37.30 ms | Postproc=122.50 ms | Overlay=0.00 ms | TOTAL=206.43 ms\n",
      "/n\n",
      "===================================== Operating on frame 49 =====================================\n",
      "[SYS] CPU: 28.4%  |  RAM: 622.9 MB\n",
      "[TIMINGS] Grab=35.50 ms | PixelChk=18.74 ms | LaneDet=0.04 ms | Inference=70.50 ms | Postproc=137.96 ms | Overlay=0.00 ms | TOTAL=263.14 ms\n",
      "/n\n",
      "===================================== Operating on frame 50 =====================================\n",
      "[SYS] CPU: 25.3%  |  RAM: 611.4 MB\n",
      "[TIMINGS] Grab=23.56 ms | PixelChk=16.61 ms | LaneDet=0.04 ms | Inference=45.13 ms | Postproc=123.94 ms | Overlay=0.00 ms | TOTAL=209.44 ms\n",
      "/n\n",
      "===================================== Operating on frame 51 =====================================\n",
      "[SYS] CPU: 22.6%  |  RAM: 611.5 MB\n",
      "[TIMINGS] Grab=29.57 ms | PixelChk=18.75 ms | LaneDet=0.04 ms | Inference=37.41 ms | Postproc=124.14 ms | Overlay=0.00 ms | TOTAL=210.07 ms\n",
      "/n\n",
      "===================================== Operating on frame 52 =====================================\n",
      "[SYS] CPU: 32.5%  |  RAM: 626.3 MB\n",
      "[TIMINGS] Grab=28.50 ms | PixelChk=19.68 ms | LaneDet=0.04 ms | Inference=33.00 ms | Postproc=122.44 ms | Overlay=0.00 ms | TOTAL=203.81 ms\n",
      "/n\n",
      "===================================== Operating on frame 53 =====================================\n",
      "[SYS] CPU: 19.0%  |  RAM: 629.0 MB\n",
      "[TIMINGS] Grab=22.03 ms | PixelChk=16.25 ms | LaneDet=0.04 ms | Inference=38.50 ms | Postproc=122.56 ms | Overlay=0.00 ms | TOTAL=199.53 ms\n",
      "/n\n",
      "===================================== Operating on frame 54 =====================================\n",
      "[SYS] CPU: 20.0%  |  RAM: 623.8 MB\n",
      "[TIMINGS] Grab=30.81 ms | PixelChk=17.85 ms | LaneDet=0.04 ms | Inference=38.75 ms | Postproc=121.01 ms | Overlay=0.00 ms | TOTAL=208.60 ms\n",
      "/n\n",
      "===================================== Operating on frame 55 =====================================\n",
      "[SYS] CPU: 23.0%  |  RAM: 623.9 MB\n",
      "[TIMINGS] Grab=20.83 ms | PixelChk=19.43 ms | LaneDet=0.04 ms | Inference=39.08 ms | Postproc=120.71 ms | Overlay=0.00 ms | TOTAL=201.12 ms\n",
      "/n\n",
      "===================================== Operating on frame 56 =====================================\n",
      "[SYS] CPU: 88.7%  |  RAM: 540.8 MB\n",
      "[TIMINGS] Grab=33.72 ms | PixelChk=52.51 ms | LaneDet=0.05 ms | Inference=45.98 ms | Postproc=145.72 ms | Overlay=0.00 ms | TOTAL=278.32 ms\n",
      "/n\n",
      "===================================== Operating on frame 57 =====================================\n",
      "[SYS] CPU: 79.4%  |  RAM: 554.6 MB\n",
      "[TIMINGS] Grab=42.99 ms | PixelChk=20.34 ms | LaneDet=0.05 ms | Inference=38.90 ms | Postproc=130.75 ms | Overlay=0.00 ms | TOTAL=233.37 ms\n",
      "/n\n",
      "===================================== Operating on frame 58 =====================================\n",
      "[SYS] CPU: 27.3%  |  RAM: 530.5 MB\n",
      "[TIMINGS] Grab=34.26 ms | PixelChk=19.80 ms | LaneDet=0.05 ms | Inference=39.23 ms | Postproc=122.44 ms | Overlay=0.00 ms | TOTAL=216.06 ms\n",
      "/n\n",
      "===================================== Operating on frame 59 =====================================\n",
      "[SYS] CPU: 18.2%  |  RAM: 531.5 MB\n",
      "[TIMINGS] Grab=23.32 ms | PixelChk=16.41 ms | LaneDet=0.04 ms | Inference=38.70 ms | Postproc=123.32 ms | Overlay=0.00 ms | TOTAL=201.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 60 =====================================\n",
      "[SYS] CPU: 34.3%  |  RAM: 496.6 MB\n",
      "[TIMINGS] Grab=29.41 ms | PixelChk=17.96 ms | LaneDet=0.05 ms | Inference=38.97 ms | Postproc=119.86 ms | Overlay=0.00 ms | TOTAL=206.39 ms\n",
      "/n\n",
      "===================================== Operating on frame 61 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 424.8 MB\n",
      "[TIMINGS] Grab=73.38 ms | PixelChk=51.57 ms | LaneDet=0.07 ms | Inference=40.70 ms | Postproc=146.61 ms | Overlay=0.00 ms | TOTAL=312.47 ms\n",
      "/n\n",
      "===================================== Operating on frame 62 =====================================\n",
      "[SYS] CPU: 53.9%  |  RAM: 433.9 MB\n",
      "[TIMINGS] Grab=24.97 ms | PixelChk=17.24 ms | LaneDet=0.10 ms | Inference=29.10 ms | Postproc=0.83 ms | Overlay=0.00 ms | TOTAL=72.65 ms\n",
      "/n\n",
      "===================================== Operating on frame 63 =====================================\n",
      "[SYS] CPU: 21.4%  |  RAM: 447.8 MB\n",
      "[TIMINGS] Grab=28.19 ms | PixelChk=18.08 ms | LaneDet=0.05 ms | Inference=25.47 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=71.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 64 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 413.8 MB\n",
      "[TIMINGS] Grab=30.98 ms | PixelChk=19.65 ms | LaneDet=0.04 ms | Inference=29.25 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=80.35 ms\n",
      "/n\n",
      "===================================== Operating on frame 65 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 415.3 MB\n",
      "[TIMINGS] Grab=24.50 ms | PixelChk=18.41 ms | LaneDet=0.05 ms | Inference=29.74 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=72.86 ms\n",
      "/n\n",
      "===================================== Operating on frame 66 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 407.5 MB\n",
      "[TIMINGS] Grab=25.11 ms | PixelChk=20.33 ms | LaneDet=0.11 ms | Inference=35.82 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=81.50 ms\n",
      "/n\n",
      "===================================== Operating on frame 67 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 408.2 MB\n",
      "[TIMINGS] Grab=26.05 ms | PixelChk=17.10 ms | LaneDet=0.04 ms | Inference=29.15 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=72.48 ms\n",
      "/n\n",
      "===================================== Operating on frame 68 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 408.6 MB\n",
      "[TIMINGS] Grab=23.66 ms | PixelChk=17.80 ms | LaneDet=0.04 ms | Inference=29.23 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=70.88 ms\n",
      "/n\n",
      "===================================== Operating on frame 69 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 418.9 MB\n",
      "[TIMINGS] Grab=21.44 ms | PixelChk=16.91 ms | LaneDet=0.04 ms | Inference=29.57 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=68.74 ms\n",
      "/n\n",
      "===================================== Operating on frame 70 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 422.6 MB\n",
      "[TIMINGS] Grab=32.85 ms | PixelChk=26.07 ms | LaneDet=0.04 ms | Inference=29.93 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=89.04 ms\n",
      "/n\n",
      "===================================== Operating on frame 71 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 422.6 MB\n",
      "[TIMINGS] Grab=22.07 ms | PixelChk=17.02 ms | LaneDet=0.04 ms | Inference=29.66 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=68.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 72 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 423.7 MB\n",
      "[TIMINGS] Grab=23.89 ms | PixelChk=17.32 ms | LaneDet=0.04 ms | Inference=29.51 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=71.11 ms\n",
      "/n\n",
      "===================================== Operating on frame 73 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 421.5 MB\n",
      "[TIMINGS] Grab=27.38 ms | PixelChk=24.85 ms | LaneDet=0.05 ms | Inference=31.09 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=83.74 ms\n",
      "/n\n",
      "===================================== Operating on frame 74 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 421.0 MB\n",
      "[TIMINGS] Grab=40.99 ms | PixelChk=27.59 ms | LaneDet=0.12 ms | Inference=35.51 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=104.46 ms\n",
      "/n\n",
      "===================================== Operating on frame 75 =====================================\n",
      "[SYS] CPU: 45.3%  |  RAM: 416.0 MB\n",
      "[TIMINGS] Grab=27.64 ms | PixelChk=18.30 ms | LaneDet=0.05 ms | Inference=29.22 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=75.49 ms\n",
      "/n\n",
      "===================================== Operating on frame 76 =====================================\n",
      "[SYS] CPU: 80.0%  |  RAM: 409.7 MB\n",
      "[TIMINGS] Grab=32.64 ms | PixelChk=21.07 ms | LaneDet=0.05 ms | Inference=33.03 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=86.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 77 =====================================\n",
      "[SYS] CPU: 89.2%  |  RAM: 335.0 MB\n",
      "[TIMINGS] Grab=41.63 ms | PixelChk=28.75 ms | LaneDet=0.05 ms | Inference=32.66 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=105.62 ms\n",
      "/n\n",
      "===================================== Operating on frame 78 =====================================\n",
      "[SYS] CPU: 81.9%  |  RAM: 312.3 MB\n",
      "[TIMINGS] Grab=49.61 ms | PixelChk=31.96 ms | LaneDet=0.05 ms | Inference=38.15 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=120.43 ms\n",
      "/n\n",
      "===================================== Operating on frame 79 =====================================\n",
      "[SYS] CPU: 94.0%  |  RAM: 314.2 MB\n",
      "[TIMINGS] Grab=47.14 ms | PixelChk=22.68 ms | LaneDet=0.06 ms | Inference=33.45 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=104.27 ms\n",
      "/n\n",
      "===================================== Operating on frame 80 =====================================\n",
      "[SYS] CPU: 80.6%  |  RAM: 313.6 MB\n",
      "[TIMINGS] Grab=30.99 ms | PixelChk=20.22 ms | LaneDet=0.06 ms | Inference=31.11 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=83.16 ms\n",
      "/n\n",
      "===================================== Operating on frame 81 =====================================\n",
      "[SYS] CPU: 62.9%  |  RAM: 326.2 MB\n",
      "[TIMINGS] Grab=23.39 ms | PixelChk=18.55 ms | LaneDet=0.06 ms | Inference=34.00 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=76.25 ms\n",
      "/n\n",
      "===================================== Operating on frame 82 =====================================\n",
      "[SYS] CPU: 85.2%  |  RAM: 322.4 MB\n",
      "[TIMINGS] Grab=37.38 ms | PixelChk=26.21 ms | LaneDet=0.05 ms | Inference=46.60 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=110.88 ms\n",
      "/n\n",
      "===================================== Operating on frame 83 =====================================\n",
      "[SYS] CPU: 59.6%  |  RAM: 322.9 MB\n",
      "[TIMINGS] Grab=59.30 ms | PixelChk=26.18 ms | LaneDet=0.05 ms | Inference=29.97 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=115.85 ms\n",
      "/n\n",
      "===================================== Operating on frame 84 =====================================\n",
      "[SYS] CPU: 56.9%  |  RAM: 343.1 MB\n",
      "[TIMINGS] Grab=38.45 ms | PixelChk=17.99 ms | LaneDet=0.05 ms | Inference=30.02 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=86.66 ms\n",
      "/n\n",
      "===================================== Operating on frame 85 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 349.2 MB\n",
      "[TIMINGS] Grab=22.38 ms | PixelChk=17.51 ms | LaneDet=0.05 ms | Inference=28.79 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=68.90 ms\n",
      "/n\n",
      "===================================== Operating on frame 86 =====================================\n",
      "[SYS] CPU: 55.0%  |  RAM: 351.7 MB\n",
      "[TIMINGS] Grab=21.87 ms | PixelChk=20.17 ms | LaneDet=0.05 ms | Inference=30.46 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=72.89 ms\n",
      "/n\n",
      "===================================== Operating on frame 87 =====================================\n",
      "[SYS] CPU: 83.1%  |  RAM: 356.6 MB\n",
      "[TIMINGS] Grab=28.82 ms | PixelChk=52.13 ms | LaneDet=0.05 ms | Inference=31.99 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=113.14 ms\n",
      "/n\n",
      "===================================== Operating on frame 88 =====================================\n",
      "[SYS] CPU: 63.0%  |  RAM: 342.4 MB\n",
      "[TIMINGS] Grab=34.95 ms | PixelChk=22.95 ms | LaneDet=0.05 ms | Inference=30.34 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=88.70 ms\n",
      "/n\n",
      "===================================== Operating on frame 89 =====================================\n",
      "[SYS] CPU: 54.1%  |  RAM: 342.3 MB\n",
      "[TIMINGS] Grab=27.17 ms | PixelChk=24.31 ms | LaneDet=0.04 ms | Inference=26.28 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=78.12 ms\n",
      "/n\n",
      "===================================== Operating on frame 90 =====================================\n",
      "[SYS] CPU: 21.8%  |  RAM: 349.7 MB\n",
      "[TIMINGS] Grab=23.78 ms | PixelChk=18.58 ms | LaneDet=0.05 ms | Inference=28.80 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=71.35 ms\n",
      "/n\n",
      "===================================== Operating on frame 91 =====================================\n",
      "[SYS] CPU: 30.3%  |  RAM: 355.1 MB\n",
      "[TIMINGS] Grab=31.33 ms | PixelChk=18.91 ms | LaneDet=0.04 ms | Inference=26.11 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=76.56 ms\n",
      "/n\n",
      "===================================== Operating on frame 92 =====================================\n",
      "[SYS] CPU: 41.9%  |  RAM: 354.7 MB\n",
      "[TIMINGS] Grab=48.06 ms | PixelChk=18.99 ms | LaneDet=0.05 ms | Inference=28.44 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=95.68 ms\n",
      "/n\n",
      "===================================== Operating on frame 93 =====================================\n",
      "[SYS] CPU: 41.9%  |  RAM: 348.9 MB\n",
      "[TIMINGS] Grab=25.58 ms | PixelChk=22.45 ms | LaneDet=0.05 ms | Inference=28.75 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=77.29 ms\n",
      "/n\n",
      "===================================== Operating on frame 94 =====================================\n",
      "[SYS] CPU: 25.4%  |  RAM: 348.9 MB\n",
      "[TIMINGS] Grab=26.40 ms | PixelChk=19.24 ms | LaneDet=0.04 ms | Inference=25.95 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=71.80 ms\n",
      "/n\n",
      "===================================== Operating on frame 95 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 349.2 MB\n",
      "[TIMINGS] Grab=26.00 ms | PixelChk=19.88 ms | LaneDet=0.04 ms | Inference=28.88 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=74.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 96 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 351.0 MB\n",
      "[TIMINGS] Grab=30.34 ms | PixelChk=16.95 ms | LaneDet=0.04 ms | Inference=29.02 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=76.92 ms\n",
      "/n\n",
      "===================================== Operating on frame 97 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 351.3 MB\n",
      "[TIMINGS] Grab=23.72 ms | PixelChk=20.11 ms | LaneDet=0.04 ms | Inference=28.92 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=72.95 ms\n",
      "/n\n",
      "===================================== Operating on frame 98 =====================================\n",
      "[SYS] CPU: 0.0%  |  RAM: 357.0 MB\n",
      "[TIMINGS] Grab=28.05 ms | PixelChk=17.29 ms | LaneDet=0.04 ms | Inference=29.76 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=75.39 ms\n",
      "/n\n",
      "===================================== Operating on frame 99 =====================================\n",
      "[SYS] CPU: 35.6%  |  RAM: 305.0 MB\n",
      "[TIMINGS] Grab=41.40 ms | PixelChk=24.96 ms | LaneDet=0.04 ms | Inference=51.97 ms | Postproc=0.01 ms | Overlay=0.00 ms | TOTAL=118.79 ms\n",
      "/n\n",
      "===================================== Operating on frame 100 =====================================\n",
      "[SYS] CPU: 44.6%  |  RAM: 295.6 MB\n",
      "[TIMINGS] Grab=37.15 ms | PixelChk=25.10 ms | LaneDet=0.08 ms | Inference=29.91 ms | Postproc=0.00 ms | Overlay=0.00 ms | TOTAL=92.38 ms\n",
      "/n\n",
      "===================================== Operating on frame 101 =====================================\n",
      "[SYS] CPU: 38.6%  |  RAM: 426.3 MB\n",
      "[TIMINGS] Grab=25.76 ms | PixelChk=18.45 ms | LaneDet=0.05 ms | Inference=93.14 ms | Postproc=149.19 ms | Overlay=0.00 ms | TOTAL=286.98 ms\n",
      "/n\n",
      "===================================== Operating on frame 102 =====================================\n",
      "[SYS] CPU: 25.6%  |  RAM: 457.3 MB\n",
      "[TIMINGS] Grab=28.93 ms | PixelChk=20.89 ms | LaneDet=0.05 ms | Inference=39.47 ms | Postproc=130.39 ms | Overlay=0.00 ms | TOTAL=219.87 ms\n",
      "/n\n",
      "===================================== Operating on frame 103 =====================================\n",
      "[SYS] CPU: 49.5%  |  RAM: 492.5 MB\n",
      "[TIMINGS] Grab=29.04 ms | PixelChk=20.59 ms | LaneDet=0.06 ms | Inference=45.75 ms | Postproc=137.04 ms | Overlay=0.00 ms | TOTAL=232.78 ms\n",
      "/n\n",
      "===================================== Operating on frame 104 =====================================\n",
      "[SYS] CPU: 33.7%  |  RAM: 519.3 MB\n",
      "[TIMINGS] Grab=36.48 ms | PixelChk=17.58 ms | LaneDet=0.05 ms | Inference=39.41 ms | Postproc=129.08 ms | Overlay=0.00 ms | TOTAL=222.72 ms\n",
      "/n\n",
      "===================================== Operating on frame 105 =====================================\n",
      "[SYS] CPU: 25.5%  |  RAM: 516.0 MB\n",
      "[TIMINGS] Grab=24.36 ms | PixelChk=17.74 ms | LaneDet=0.07 ms | Inference=37.94 ms | Postproc=131.75 ms | Overlay=0.00 ms | TOTAL=212.04 ms\n",
      "/n\n",
      "===================================== Operating on frame 106 =====================================\n",
      "[SYS] CPU: 47.5%  |  RAM: 505.8 MB\n",
      "[TIMINGS] Grab=28.06 ms | PixelChk=19.14 ms | LaneDet=0.05 ms | Inference=38.06 ms | Postproc=136.47 ms | Overlay=0.00 ms | TOTAL=221.90 ms\n",
      "/n\n",
      "===================================== Operating on frame 107 =====================================\n",
      "[SYS] CPU: 61.4%  |  RAM: 484.9 MB\n",
      "[TIMINGS] Grab=53.24 ms | PixelChk=19.32 ms | LaneDet=0.05 ms | Inference=56.68 ms | Postproc=129.89 ms | Overlay=0.00 ms | TOTAL=259.48 ms\n",
      "/n\n",
      "===================================== Operating on frame 108 =====================================\n",
      "[SYS] CPU: 28.7%  |  RAM: 487.9 MB\n",
      "[TIMINGS] Grab=25.49 ms | PixelChk=17.58 ms | LaneDet=0.04 ms | Inference=38.70 ms | Postproc=127.38 ms | Overlay=0.00 ms | TOTAL=209.34 ms\n",
      "/n\n",
      "===================================== Operating on frame 109 =====================================\n",
      "[SYS] CPU: 42.2%  |  RAM: 528.9 MB\n",
      "[TIMINGS] Grab=35.22 ms | PixelChk=17.64 ms | LaneDet=0.05 ms | Inference=36.89 ms | Postproc=150.29 ms | Overlay=0.00 ms | TOTAL=240.88 ms\n",
      "/n\n",
      "===================================== Operating on frame 110 =====================================\n",
      "[SYS] CPU: 39.7%  |  RAM: 529.6 MB\n",
      "[TIMINGS] Grab=29.38 ms | PixelChk=26.51 ms | LaneDet=0.06 ms | Inference=68.27 ms | Postproc=148.84 ms | Overlay=0.00 ms | TOTAL=273.24 ms\n",
      "/n\n",
      "===================================== Operating on frame 111 =====================================\n",
      "[SYS] CPU: 41.3%  |  RAM: 562.7 MB\n",
      "[TIMINGS] Grab=33.32 ms | PixelChk=18.64 ms | LaneDet=0.04 ms | Inference=40.74 ms | Postproc=132.22 ms | Overlay=0.00 ms | TOTAL=225.29 ms\n",
      "/n\n",
      "===================================== Operating on frame 112 =====================================\n",
      "[SYS] CPU: 32.1%  |  RAM: 565.7 MB\n",
      "[TIMINGS] Grab=23.75 ms | PixelChk=18.15 ms | LaneDet=0.04 ms | Inference=39.33 ms | Postproc=130.33 ms | Overlay=0.00 ms | TOTAL=211.80 ms\n",
      "/n\n",
      "===================================== Operating on frame 113 =====================================\n",
      "[SYS] CPU: 35.7%  |  RAM: 587.4 MB\n",
      "[TIMINGS] Grab=29.71 ms | PixelChk=19.14 ms | LaneDet=0.05 ms | Inference=38.55 ms | Postproc=126.95 ms | Overlay=0.00 ms | TOTAL=214.57 ms\n",
      "/n\n",
      "===================================== Operating on frame 114 =====================================\n",
      "[SYS] CPU: 36.5%  |  RAM: 578.2 MB\n",
      "[TIMINGS] Grab=25.27 ms | PixelChk=17.17 ms | LaneDet=0.04 ms | Inference=51.46 ms | Postproc=140.51 ms | Overlay=0.00 ms | TOTAL=234.77 ms\n",
      "/n\n",
      "===================================== Operating on frame 115 =====================================\n",
      "[SYS] CPU: 27.9%  |  RAM: 584.5 MB\n",
      "[TIMINGS] Grab=24.15 ms | PixelChk=19.81 ms | LaneDet=0.05 ms | Inference=39.82 ms | Postproc=126.42 ms | Overlay=0.00 ms | TOTAL=210.55 ms\n",
      "/n\n",
      "===================================== Operating on frame 116 =====================================\n",
      "[SYS] CPU: 35.3%  |  RAM: 591.1 MB\n",
      "[TIMINGS] Grab=23.21 ms | PixelChk=17.91 ms | LaneDet=0.05 ms | Inference=37.04 ms | Postproc=134.32 ms | Overlay=0.00 ms | TOTAL=212.67 ms\n",
      "/n\n",
      "===================================== Operating on frame 117 =====================================\n",
      "[SYS] CPU: 63.3%  |  RAM: 442.7 MB\n",
      "[TIMINGS] Grab=24.79 ms | PixelChk=23.23 ms | LaneDet=1.06 ms | Inference=39.32 ms | Postproc=155.30 ms | Overlay=0.00 ms | TOTAL=243.96 ms\n",
      "/n\n",
      "===================================== Operating on frame 118 =====================================\n",
      "[SYS] CPU: 42.6%  |  RAM: 450.4 MB\n",
      "[TIMINGS] Grab=29.47 ms | PixelChk=19.10 ms | LaneDet=0.05 ms | Inference=40.96 ms | Postproc=99.18 ms | Overlay=0.00 ms | TOTAL=188.93 ms\n",
      "/n\n",
      "===================================== Operating on frame 119 =====================================\n",
      "[SYS] CPU: 51.5%  |  RAM: 459.4 MB\n",
      "[TIMINGS] Grab=43.24 ms | PixelChk=21.72 ms | LaneDet=0.05 ms | Inference=38.10 ms | Postproc=111.45 ms | Overlay=0.00 ms | TOTAL=214.94 ms\n",
      "/n\n",
      "===================================== Operating on frame 120 =====================================\n",
      "[SYS] CPU: 35.9%  |  RAM: 448.0 MB\n",
      "[TIMINGS] Grab=24.85 ms | PixelChk=17.14 ms | LaneDet=0.04 ms | Inference=61.55 ms | Postproc=106.71 ms | Overlay=0.00 ms | TOTAL=210.99 ms\n",
      "Script halted.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Live overlays + lane-aware curved sampling (optimized postproc)\n",
    "# • Parsec focus + auto click\n",
    "# • mss live capture of a crop region\n",
    "# • Arrow keys switch lane (0/1/2) -> JAKE_POINT updates per frame\n",
    "# • Full overlay rendering + per-frame save\n",
    "# • Prints compact timing per frame\n",
    "# • RETURNS per frame: tri_positions, best_idx, tri_hit_classes, tri_summary (for movement logic)\n",
    "\n",
    "import os, time, math, subprocess\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "from ultralytics import YOLO\n",
    "from threading import Timer\n",
    "from threading import Thread\n",
    "import time\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "\n",
    "\n",
    "# --- swallow AI-generated keypresses in the listener for a short window ---\n",
    "SYNTHETIC_SUPPRESS_S = 0.15  # 150 ms is plenty\n",
    "_synth_block_until = 0.0     # simple, explicit init avoids IDE warnings\n",
    "\n",
    "try:\n",
    "    _synth_block_until\n",
    "except NameError:\n",
    "    _synth_block_until = 0.0\n",
    "\n",
    "# ======================= Quick supreesion to prevent instant bailouts =======================\n",
    "\n",
    "# --- allows 0.5s of movement, then mute for 2.5s, then restore ---\n",
    "# Save originals\n",
    "__press_orig   = pyautogui.press\n",
    "__keyDown_orig = pyautogui.keyDown\n",
    "__keyUp_orig   = pyautogui.keyUp\n",
    "__hotkey_orig  = pyautogui.hotkey\n",
    "\n",
    "# near your other globals, after imports\n",
    "MOVEMENT_ENABLED = True\n",
    "\n",
    "def __mute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = False\n",
    "    pyautogui.press  = lambda *a, **k: None\n",
    "    pyautogui.keyDown = lambda *a, **k: None\n",
    "    pyautogui.keyUp   = lambda *a, **k: None\n",
    "    pyautogui.hotkey  = lambda *a, **k: None\n",
    "    print(\"[BOOT] movement muted\")\n",
    "\n",
    "def __unmute_keys():\n",
    "    global MOVEMENT_ENABLED\n",
    "    MOVEMENT_ENABLED = True\n",
    "    pyautogui.press   = __press_orig\n",
    "    pyautogui.keyDown = __keyDown_orig\n",
    "    pyautogui.keyUp   = __keyUp_orig\n",
    "    pyautogui.hotkey  = __hotkey_orig\n",
    "    print(\"[BOOT] movement unmuted\")\n",
    "\n",
    "\n",
    "# Allow movement immediately; after 0.5s, mute; after 3.0s total, unmute\n",
    "Timer(0.5, __mute_keys).start()\n",
    "Timer(4.0, __unmute_keys).start()\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "# SAVE HERE\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_live_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crop + click (set by ad layout)\n",
    "advertisement = True\n",
    "if advertisement:\n",
    "    snap_coords = (644, 77, (1149-644), (981-75))  # (left, top, width, height)\n",
    "    start_click = (1030, 900)\n",
    "else:\n",
    "    snap_coords = (483, 75, (988-483), (981-75))\n",
    "    start_click = (870, 895)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 200\n",
    "RAY_STEP_PX         = 20   # walk the ray every 20 px\n",
    "\n",
    "# ===== Bend degrees (tune here) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0  # N1\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0  # N2\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0  # N3\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0  # N4\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "COLOR_CYAN   = (255, 255, 0)\n",
    "COLOR_BLACK  = (0, 0, 0)\n",
    "\n",
    "# =======================\n",
    "# Jake lane points + dynamic JAKE_POINT\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)  # index by lane (0,1,2)\n",
    "JAKE_POINT  = LANE_MID  # will be set each frame from 'lane'\n",
    "\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "\n",
    "# ===== Movement logic (modular) HELPER FUNCTIOSNS==============================================================================================================\n",
    "\n",
    "\n",
    "# --- inference pause gate (after imports/globals) ---\n",
    "PAUSE_AFTER_MOVE_S = 0.40\n",
    "\n",
    "try:\n",
    "    PAUSE_UNTIL\n",
    "except NameError:\n",
    "    PAUSE_UNTIL = 0.0  # monotonic timestamp\n",
    "\n",
    "def pause_inference(sec: float = PAUSE_AFTER_MOVE_S):\n",
    "    \"\"\"Freeze the main loop for `sec` seconds from NOW.\"\"\"\n",
    "    global PAUSE_UNTIL\n",
    "    PAUSE_UNTIL = time.monotonic() + sec\n",
    "\n",
    "\n",
    "# One-shot gating\n",
    "try:\n",
    "    IMPACT_TOKEN\n",
    "except NameError:\n",
    "    IMPACT_TOKEN = None  # (lane, class_id)\n",
    "\n",
    "def _fire_action_key(key: str, token_snapshot):\n",
    "    global IMPACT_TOKEN\n",
    "    if MOVEMENT_ENABLED:\n",
    "        pyautogui.press(key)\n",
    "        print(f\"[TIMER FIRE] pressed {key}\")\n",
    "    # allow instant re-arm for the next identical obstacle\n",
    "    if IMPACT_TOKEN == token_snapshot:\n",
    "        IMPACT_TOKEN = None\n",
    "\n",
    "\n",
    "# Only arm timer when distance is strictly inside this window (px)\n",
    "IMPACT_MIN_PX = 100\n",
    "IMPACT_MAX_PX = 650\n",
    "\n",
    "# ===== Impact delay lookup (distance px -> seconds) =====\n",
    "# Fill these with your *monotone ascending* distances (px) and corresponding delays (seconds).\n",
    "# Example placeholders; REPLACE with your numbers:\n",
    "LUT_PX = np.array([100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 725, 750, 775, 800], dtype=float)\n",
    "\n",
    "SHORTEN_S = 0.35 #Shortnen by 100ms\n",
    "# Safety clamps so Timer never explodes or becomes a no-op\n",
    "MIN_DELAY_S = 0.03   # 30 ms\n",
    "MAX_DELAY_S = 2.00   # 2 s\n",
    "\n",
    "LUT_S = np.clip(np.array([0.0259, 0.0303, 0.0353, 0.0412, 0.0481, 0.0561, 0.0655, 0.0765, 0.0893, 0.1042, 0.1216, 0.1419, 0.1656, 0.1933, 0.2256, 0.2633, 0.3073, 0.3586, 0.4185, 0.4885, 0.5701, 0.6654, 0.7765, 0.9063, 1.0578, 1.2345, 1.4408, 1.6815, 1.9625], dtype=float) - SHORTEN_S, MIN_DELAY_S, MAX_DELAY_S)\n",
    "\n",
    "\n",
    "def first_mask_hit_starburst_then_ray_for_set(\n",
    "    jake_point, tri_pos, theta_deg, masks_np, classes_np, H, W,\n",
    "    allowed_classes, up2_px=SAMPLE_UP_PX, step_px=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Same as first_mask_hit_starburst_then_ray, but only counts hits whose class ∈ allowed_classes.\n",
    "    Returns (dist_px_from_jake, (x_hit, y_hit), class_id) or (None, None, None).\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return (None, None, None)\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    allowed = set(int(c) for c in allowed_classes)\n",
    "    idxs = [i for i, c in enumerate(classes_np) if int(c) in allowed]\n",
    "    if not idxs:\n",
    "        return (None, None, None)\n",
    "\n",
    "    def _hit_at(xs, ys):\n",
    "        mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "        my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "        for i in idxs:\n",
    "            if masks_np[i][my, mx] > 0.5:\n",
    "                return int(classes_np[i])\n",
    "        return None\n",
    "\n",
    "    x0, y0 = map(int, jake_point)\n",
    "    x1, y1 = map(int, tri_pos)\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "    x1 = _clampi(x1, 0, W-1); y1 = _clampi(y1, 0, H-1)\n",
    "\n",
    "    dx = x1 - x0; dy = y1 - y0\n",
    "    seg1_len = max(1e-6, math.hypot(dx, dy))\n",
    "    n1 = max(1, int(seg1_len // max(1, step_px)))\n",
    "    for k in range(1, n1 + 1):\n",
    "        t = min(1.0, (k * step_px) / seg1_len)\n",
    "        xs = _clampi(int(round(x0 + dx * t)), 0, W-1)\n",
    "        ys = _clampi(int(round(y0 + dy * t)), 0, H-1)\n",
    "        cls_hit = _hit_at(xs, ys)\n",
    "        if cls_hit is not None:\n",
    "            dist = math.hypot(xs - x0, ys - y0)\n",
    "            return (float(dist), (int(xs), int(ys)), int(cls_hit))\n",
    "\n",
    "    dxr, dyr = TRIG_TABLE.get(theta_deg, (0.0, -1.0))\n",
    "    n2 = max(1, int(up2_px // max(1, step_px)))\n",
    "    for k in range(1, n2 + 1):\n",
    "        t = k * step_px\n",
    "        xs = _clampi(int(round(x1 + dxr * t)), 0, W-1)\n",
    "        ys = _clampi(int(round(y1 + dyr * t)), 0, H-1)\n",
    "        cls_hit = _hit_at(xs, ys)\n",
    "        if cls_hit is not None:\n",
    "            dist = seg1_len + math.hypot(xs - x1, ys - y1)\n",
    "            return (float(dist), (int(xs), int(ys)), int(cls_hit))\n",
    "\n",
    "    return (None, None, None)\n",
    "\n",
    "\n",
    "# ===== Impact-timer overhaul (single-triangle action) =====\n",
    "# Classes to act on (exact mapping)\n",
    "IMPACT_CLASSES = {2, 3, 4, 5}  # 2:HIGHBARRIER1, 3:JUMP, 4:LOWBARRIER1, 5:LOWBARRIER2\n",
    "ACTION_BY_CLASS = {3: \"up\", 5: \"up\", 4: \"down\", 2: \"down\"}  # per spec\n",
    "\n",
    "# Global timer handle (overwritten when re-arming)\n",
    "try:\n",
    "    IMPACT_TIMER\n",
    "except NameError:\n",
    "    IMPACT_TIMER = None\n",
    "\n",
    "\n",
    "def _cancel_impact_timer(reason=None):\n",
    "    global IMPACT_TIMER\n",
    "    if IMPACT_TIMER is not None and getattr(IMPACT_TIMER, \"is_alive\", lambda: False)():\n",
    "        print(\"[TIMER] cancelled\" + (f\" ({reason})\" if reason else \"\"))\n",
    "        try:\n",
    "            IMPACT_TIMER.cancel()\n",
    "        except Exception:\n",
    "            pass\n",
    "    IMPACT_TIMER = None\n",
    "\n",
    "\n",
    "\n",
    "def _impact_delay_seconds(dist_px: float) -> float:\n",
    "    \"\"\"\n",
    "    O(1) lookup + linear interpolation from a monotone table (px -> seconds).\n",
    "    - Dist is cropped to [IMPACT_MIN_PX, IMPACT_MAX_PX] to preserve your windowing.\n",
    "    - Result is clamped to [MIN_DELAY_S, MAX_DELAY_S] for Timer safety.\n",
    "    \"\"\"\n",
    "    if not math.isfinite(dist_px):\n",
    "        return MIN_DELAY_S\n",
    "\n",
    "    # Respect your arming window; crop inside it so behavior matches old gating.\n",
    "    d = max(IMPACT_MIN_PX, min(float(dist_px), IMPACT_MAX_PX))\n",
    "\n",
    "    # Interpolate within the table’s range\n",
    "    lo = float(LUT_PX[0]); hi = float(LUT_PX[-1])\n",
    "    d_clamped = max(lo, min(d, hi))\n",
    "\n",
    "    delay = float(np.interp(d_clamped, LUT_PX, LUT_S))\n",
    "    # Final safety clamp\n",
    "    return max(MIN_DELAY_S, min(delay, MAX_DELAY_S))\n",
    "\n",
    "\n",
    "def _arm_impact_timer(dist_px: float, cls_id: int):\n",
    "    \"\"\"\n",
    "    Overwrite-or-set the global timer if dist is in (400, 800) px and class is in IMPACT_CLASSES.\n",
    "    Prints whether we armed a NEW timer or UPDATED (overwrote) an existing one.\n",
    "    \"\"\"\n",
    "    if cls_id not in IMPACT_CLASSES:\n",
    "        return\n",
    "\n",
    "    if not (IMPACT_MIN_PX < dist_px < IMPACT_MAX_PX):\n",
    "        # Optional debug: show why we didn't arm\n",
    "        print(f\"[TIMER] skip: dist {dist_px:.1f}px outside ({IMPACT_MIN_PX},{IMPACT_MAX_PX}) for {LABELS.get(int(cls_id), cls_id)}\")\n",
    "        return\n",
    "\n",
    "    key = ACTION_BY_CLASS.get(int(cls_id))\n",
    "    if not key:\n",
    "        return\n",
    "\n",
    "    delay_s = _impact_delay_seconds(dist_px)\n",
    "\n",
    "    if not math.isfinite(delay_s) or delay_s <= 0.0:\n",
    "        print(f\"[TIMER] skip: invalid delay {delay_s} for dist={dist_px:.1f}px, cls={LABELS.get(int(cls_id), cls_id)}\")\n",
    "        return\n",
    "\n",
    "    # detect whether we are overwriting a live timer\n",
    "    # detect whether we are overwriting a live timer\n",
    "    global IMPACT_TIMER, IMPACT_TOKEN\n",
    "    was_live = (IMPACT_TIMER is not None and getattr(IMPACT_TIMER, \"is_alive\", lambda: False)())\n",
    "\n",
    "    _cancel_impact_timer()  # overwrite existing timer if any\n",
    "\n",
    "    # --- REPLACEMENT: arm with a token so post-fire re-arm is instant ---\n",
    "    new_token = (lane, int(cls_id))            # <-- build token for THIS arm\n",
    "    from threading import Timer\n",
    "    IMPACT_TIMER = Timer(delay_s, _fire_action_key, args=(key, new_token))\n",
    "    IMPACT_TIMER.daemon = True\n",
    "    IMPACT_TIMER.start()\n",
    "\n",
    "    IMPACT_TOKEN = new_token                   # remember what we armed\n",
    "    status = \"updated\" if was_live else \"armed\"\n",
    "    print(f\"[TIMER] {status}: key={key} in {delay_s:.3f}s  (dist={dist_px:.1f}px, cls={LABELS.get(int(cls_id), cls_id)})\")\n",
    "\n",
    "\n",
    "def first_mask_hit_starburst_then_ray(\n",
    "    jake_point, tri_pos, theta_deg, masks_np, classes_np, H, W,\n",
    "    up2_px=SAMPLE_UP_PX, step_px=2, exclude_classes=(RAIL_ID,), danger_only=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Follow the path used in viz:\n",
    "      1) straight line JAKE_POINT -> tri_pos,\n",
    "      2) then continue from tri_pos along the angled probe ray (theta_deg) for up to `up2_px`.\n",
    "    Return (dist_px_from_jake, (x_hit, y_hit), class_id) for the first mask hit\n",
    "    (skipping rails or restricted to DANGER_RED if danger_only=True). If none, return (None, None, None).\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return (None, None, None)\n",
    "\n",
    "    # choose class indices to test\n",
    "    if danger_only:\n",
    "        test_idxs = [i for i,c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    else:\n",
    "        test_idxs = [i for i,c in enumerate(classes_np) if int(c) not in exclude_classes]\n",
    "    if not test_idxs:\n",
    "        return (None, None, None)\n",
    "\n",
    "    # scale factors from frame to mask grid\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    def _hit_at(xs, ys):\n",
    "        mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "        my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "        for i in test_idxs:\n",
    "            if masks_np[i][my, mx] > 0.5:\n",
    "                return int(classes_np[i])\n",
    "        return None\n",
    "\n",
    "    # ---- segment 1: JAKE_POINT -> triangle apex\n",
    "    x0, y0 = map(int, jake_point)\n",
    "    x1, y1 = map(int, tri_pos)\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "    x1 = _clampi(x1, 0, W-1); y1 = _clampi(y1, 0, H-1)\n",
    "\n",
    "    dx = x1 - x0; dy = y1 - y0\n",
    "    seg1_len = max(1e-6, math.hypot(dx, dy))\n",
    "    n1 = max(1, int(seg1_len // max(1, step_px)))\n",
    "    for k in range(1, n1 + 1):\n",
    "        t = min(1.0, (k * step_px) / seg1_len)\n",
    "        xs = _clampi(int(round(x0 + dx * t)), 0, W-1)\n",
    "        ys = _clampi(int(round(y0 + dy * t)), 0, H-1)\n",
    "        cls_hit = _hit_at(xs, ys)\n",
    "        if cls_hit is not None:\n",
    "            dist = math.hypot(xs - x0, ys - y0)  # Euclidean from Jake\n",
    "            return (float(dist), (int(xs), int(ys)), int(cls_hit))\n",
    "\n",
    "    # ---- segment 2: continue from triangle along angled probe (same as classify rays)\n",
    "    dxr, dyr = TRIG_TABLE.get(theta_deg, (0.0, -1.0))  # default straight up\n",
    "    n2 = max(1, int(up2_px // max(1, step_px)))\n",
    "    for k in range(1, n2 + 1):\n",
    "        t = k * step_px\n",
    "        xs = _clampi(int(round(x1 + dxr * t)), 0, W-1)\n",
    "        ys = _clampi(int(round(y1 + dyr * t)), 0, H-1)\n",
    "        cls_hit = _hit_at(xs, ys)\n",
    "        if cls_hit is not None:\n",
    "            dist = seg1_len + math.hypot(xs - x1, ys - y1)  # piecewise length from Jake\n",
    "            return (float(dist), (int(xs), int(ys)), int(cls_hit))\n",
    "\n",
    "    return (None, None, None)\n",
    "\n",
    "\n",
    "def first_mask_hit_along_segment(jake_point, tri_pos, masks_np, classes_np,\n",
    "                                 H, W, exclude_classes=(RAIL_ID,), step_px=1):\n",
    "    \"\"\"\n",
    "    Walk the straight segment from JAKE_POINT -> Jake's triangle apex.\n",
    "    Return (distance_px, (x_hit, y_hit), class_id) for the first mask hit,\n",
    "    skipping any classes in `exclude_classes`. If none, return (None, None, None).\n",
    "    \"\"\"\n",
    "    if masks_np is None or masks_np.size == 0 or classes_np is None or len(tri_pos) != 2:\n",
    "        return (None, None, None)\n",
    "\n",
    "    x0, y0 = map(int, jake_point)\n",
    "    x1, y1 = map(int, tri_pos)\n",
    "    # clamp\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "    x1 = _clampi(x1, 0, W-1); y1 = _clampi(y1, 0, H-1)\n",
    "\n",
    "    dx = x1 - x0\n",
    "    dy = y1 - y0\n",
    "    seg_len = math.hypot(dx, dy)\n",
    "    if seg_len < 1e-6:\n",
    "        return (None, None, None)\n",
    "\n",
    "    # map-to-mask scale factors\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    # prebuild indices of classes we actually test (skip excluded, e.g., RAIL_ID)\n",
    "    test_idxs = [i for i, c in enumerate(classes_np) if int(c) not in exclude_classes]\n",
    "    if not test_idxs:\n",
    "        return (None, None, None)\n",
    "\n",
    "    # step along the line; start at step 1 so we don't immediately \"hit\" Jake's pixel\n",
    "    n_steps = max(1, int(seg_len // max(1, step_px)))\n",
    "    for k in range(1, n_steps + 1):\n",
    "        t = (k * step_px) / seg_len\n",
    "        if t > 1.0: t = 1.0\n",
    "        xs = _clampi(int(round(x0 + dx * t)), 0, W-1)\n",
    "        ys = _clampi(int(round(y0 + dy * t)), 0, H-1)\n",
    "\n",
    "        mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "        my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "        for i in test_idxs:\n",
    "            # masks_np is float in [0,1]; >0.5 treated as hit (consistent with rest of code)\n",
    "            if masks_np[i][my, mx] > 0.5:\n",
    "                # distance in pixels along the segment to this sample\n",
    "                dist_px = math.hypot(xs - x0, ys - y0)\n",
    "                return (float(dist_px), (int(xs), int(ys)), int(classes_np[i]))\n",
    "\n",
    "    return (None, None, None)\n",
    "\n",
    "\n",
    "\n",
    "# --- tunnel wall color gate (HSV) ---\n",
    "LOWBARRIER1_ID   = 4\n",
    "ORANGETRAIN_ID   = 6\n",
    "WALL_STRIP_PX    = 10           # vertical strip height checked just above the barrier\n",
    "WALL_MATCH_FRAC  = 0.95         # % of “wall” pixels required to relabel\n",
    "WALL_ORANGE_LO = np.array([5,  80,  60], dtype=np.uint8)   # H,S,V (lo)\n",
    "WALL_ORANGE_HI = np.array([35, 255, 255], dtype=np.uint8)  # H,S,V (hi)\n",
    "\n",
    "\n",
    "def promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np,\n",
    "                                 strip_px=WALL_STRIP_PX, frac_thresh=WALL_MATCH_FRAC):\n",
    "    \"\"\"\n",
    "    If a LOWBARRIER1 has an orange 'tunnel wall' strip right behind it,\n",
    "    relabel that instance to ORANGETRAIN (treated as RED).\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return classes_np\n",
    "\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    hsv = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)\n",
    "    wall_u8 = cv2.inRange(hsv, WALL_ORANGE_LO, WALL_ORANGE_HI)  # 0/255\n",
    "\n",
    "    # iterate only over LOWBARRIER1 instances\n",
    "    for i, cls in enumerate(classes_np):\n",
    "        if int(cls) != LOWBARRIER1_ID:\n",
    "            continue\n",
    "\n",
    "        m = masks_np[i]\n",
    "        # upsample to frame size if needed\n",
    "        if m.shape != (H, W):\n",
    "            m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        else:\n",
    "            m_full = m.astype(bool, copy=False)\n",
    "\n",
    "        ys, xs = np.where(m_full)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "\n",
    "        x0, x1 = xs.min(), xs.max()\n",
    "        y0, _  = ys.min(), ys.max()\n",
    "\n",
    "        # check a strip immediately above the barrier (toward smaller y)\n",
    "        yb0 = max(0, y0 - strip_px)\n",
    "        yb1 = y0\n",
    "        if yb1 <= yb0:\n",
    "            continue\n",
    "\n",
    "        strip = wall_u8[yb0:yb1, x0:x1+1]\n",
    "        if strip.size == 0:\n",
    "            continue\n",
    "\n",
    "        frac = float(cv2.countNonZero(strip)) / strip.size\n",
    "        if frac >= frac_thresh:\n",
    "            classes_np[i] = ORANGETRAIN_ID  # promote to a RED class\n",
    "\n",
    "    return classes_np\n",
    "\n",
    "\n",
    "# extra classes/sets\n",
    "WARN_FOR_MOVE = {2, 3, 4, 5, 8}      # yellow set that should try to sidestep if a green exists\n",
    "JUMP_SET      = {3, 5, 10}           # Jump, LowBarrier2, Sidewalk\n",
    "DUCK_SET      = {2, 4}               # HighBarrier1, LowBarrier1\n",
    "\n",
    "# action keys (change if your emulator uses different binds)\n",
    "JUMP_KEY = \"up\"\n",
    "DUCK_KEY = \"down\"\n",
    "\n",
    "# --- \"white-ish\" lane probe (5x5 box counts) ---\n",
    "# tune these if your Jake sprite/board highlight isn't pure white\n",
    "WHITE_MIN = np.array([220, 220, 220], dtype=np.uint8)  # BGR lower bound\n",
    "WHITE_MAX = np.array([255, 255, 255], dtype=np.uint8)  # BGR upper bound\n",
    "BOX_RAD   = 2  # 5x5 => radius 2\n",
    "\n",
    "def _count_white_around(img_bgr, pt, box_rad=BOX_RAD):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    x, y = pt\n",
    "    x0 = max(0, x - box_rad); x1 = min(W, x + box_rad + 1)\n",
    "    y0 = max(0, y - box_rad); y1 = min(H, y + box_rad + 1)\n",
    "    roi = img_bgr[y0:y1, x0:x1]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "    mask = cv2.inRange(roi, WHITE_MIN, WHITE_MAX)\n",
    "    return int(cv2.countNonZero(mask))\n",
    "\n",
    "def _detect_lane_by_whiteness(img_bgr):\n",
    "    # returns lane index 0/1/2 chosen by the largest white count;\n",
    "    # if all zero, returns None to keep previous lane\n",
    "    counts = [\n",
    "        _count_white_around(img_bgr, LANE_LEFT),\n",
    "        _count_white_around(img_bgr, LANE_MID),\n",
    "        _count_white_around(img_bgr, LANE_RIGHT),\n",
    "    ]\n",
    "    best_idx = int(np.argmax(counts))\n",
    "    return best_idx if counts[best_idx] > 0 else None\n",
    "\n",
    "\n",
    "# action cooldown so we don't spam jump/duck\n",
    "try:\n",
    "    last_action_ts\n",
    "except NameError:\n",
    "    last_action_ts = 0.0\n",
    "ACTION_COOLDOWN_S = 0.0\n",
    "\n",
    "# distance threshold (pixels) from Jake to triangle apex for action decisions\n",
    "ACTION_DIST_PX = 30\n",
    "\n",
    "def _is_warn(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in WARN_FOR_MOVE)\n",
    "\n",
    "def _schedule(fn, *args, **kwargs):\n",
    "    Thread(target=fn, args=args, kwargs=kwargs, daemon=True).start()\n",
    "\n",
    "MIN_GREEN_AHEAD_PX = 400\n",
    "def _filter_green_far(cands, jake_band_y: int, min_ahead_px: int = MIN_GREEN_AHEAD_PX):\n",
    "    \"\"\"Keep only green triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:  # keep if ≥ 400 px ahead\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "def first_red_hit_y(pos, masks_np, classes_np, H, W, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first RED pixel straight above `pos`, or None.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    red_idx = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    if not red_idx: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "def first_hit_y(pos, masks_np, classes_np, H, W, class_set, band_px=6, step_px=5, max_up=SAMPLE_UP_PX):\n",
    "    \"\"\"Return the screen y of the first pixel (straight up) whose class ∈ class_set.\"\"\"\n",
    "    if masks_np is None or masks_np.size == 0: return None\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    idxs = [i for i, c in enumerate(classes_np) if int(c) in class_set]\n",
    "    if not idxs: return None\n",
    "\n",
    "    x0, y0 = int(pos[0]), int(pos[1])\n",
    "    x0 = _clampi(x0, 0, W-1); y0 = _clampi(y0, 0, H-1)\n",
    "\n",
    "    for t in range(step_px, max_up + 1, step_px):\n",
    "        y = _clampi(y0 - t, 0, H-1)\n",
    "        for dx in range(-band_px, band_px + 1):\n",
    "            x = _clampi(x0 + dx, 0, W-1)\n",
    "            mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "            for i in idxs:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    return y\n",
    "    return None\n",
    "\n",
    "\n",
    "# Only step from RED into a YELLOW lane if its triangle is far enough ahead\n",
    "MIN_YELLOW_AHEAD_PX = 400\n",
    "def _filter_yellow_far(cands, jake_band_y: int, min_ahead_px: int = MIN_YELLOW_AHEAD_PX):\n",
    "    \"\"\"Keep only yellow triangles that are at least `min_ahead_px` above Jake's y band.\"\"\"\n",
    "    out = []\n",
    "    for c in cands:\n",
    "        _, yt = c[\"pos\"]\n",
    "        if (jake_band_y - yt) >= min_ahead_px:\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _try_duck():\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "    global last_action_ts\n",
    "    now = time.perf_counter()\n",
    "    if now - last_action_ts >= ACTION_COOLDOWN_S:\n",
    "        last_action_ts = now\n",
    "        _schedule(pyautogui.press, DUCK_KEY)\n",
    "try:\n",
    "    last_move_ts\n",
    "except NameError:\n",
    "    last_move_ts = 0.0\n",
    "\n",
    "MOVE_COOLDOWN_S = 0.10  # 100 ms\n",
    "\n",
    "def _is_danger(cls_id: int | None) -> bool:\n",
    "    return (cls_id is not None) and (int(cls_id) in DANGER_RED)\n",
    "\n",
    "def _is_safe(cls_id: int | None) -> bool:\n",
    "    return not _is_danger(cls_id)\n",
    "\n",
    "def _filter_by_lane(cands, jx: int, lane_idx: int):\n",
    "    \"\"\"Prune triangles based on current lane:\n",
    "       - lane 0 (left): drop triangles with x < jx\n",
    "       - lane 2 (right): drop triangles with x > jx\n",
    "       - lane 1 (mid): keep all\n",
    "    \"\"\"\n",
    "    if lane_idx == 0:\n",
    "        return [c for c in cands if c[\"pos\"][0] >= jx]\n",
    "    if lane_idx == 2:\n",
    "        return [c for c in cands if c[\"pos\"][0] <= jx]\n",
    "    return cands\n",
    "\n",
    "def _pick_best_safe_triangle(cands, jx: int):\n",
    "    \"\"\"Prefer triangles with hit_class == None; otherwise any non-danger.\n",
    "       Break ties by smallest |x - jx|.\n",
    "    \"\"\"\n",
    "    if not cands:\n",
    "        return None\n",
    "    none_hits  = [c for c in cands if c[\"hit_class\"] is None]\n",
    "    safe_hits  = [c for c in cands if c[\"hit_class\"] is not None and _is_safe(c[\"hit_class\"])]\n",
    "    pool = none_hits if none_hits else safe_hits\n",
    "    if not pool:\n",
    "        return None\n",
    "    # exclude triangles exactly aligned with Jake in x (no direction)\n",
    "    pool = [c for c in pool if c[\"pos\"][0] != jx] or pool\n",
    "    return min(pool, key=lambda c: abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "def _issue_move_towards_x(jx: int, tx: int):\n",
    "    global lane, last_move_ts, _synth_block_until\n",
    "    if not MOVEMENT_ENABLED:\n",
    "        return\n",
    "\n",
    "    now = time.perf_counter()\n",
    "    if now - last_move_ts < MOVE_COOLDOWN_S:\n",
    "        return\n",
    "\n",
    "    if tx < jx and lane > MIN_LANE:\n",
    "        pause_inference()  # 360ms freeze to avoid mid-lane frames\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('left')\n",
    "        lane = max(MIN_LANE, lane - 1)\n",
    "        print(f\"[AI MOVE] left -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "\n",
    "    elif tx > jx and lane < MAX_LANE:\n",
    "        pause_inference()  # 360ms freeze to avoid mid-lane frames\n",
    "        _synth_block_until = time.monotonic() + SYNTHETIC_SUPPRESS_S\n",
    "        pyautogui.press('right')\n",
    "        lane = min(MAX_LANE, lane + 1)\n",
    "        print(f\"[AI MOVE] right -> Lane {lane}\")\n",
    "        last_move_ts = now\n",
    "\n",
    "    else:\n",
    "        print('WE ARE COOKED')\n",
    "\n",
    "#============================================================================================================================================\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Lane/keyboard state\n",
    "# =======================\n",
    "lane = 1\n",
    "MIN_LANE = 0\n",
    "MAX_LANE = 2\n",
    "running = True\n",
    "\n",
    "# ===== Debounce / cooldown =====\n",
    "COOLDOWN_MS = 20\n",
    "_last_press_ts = 0.0  # monotonic seconds\n",
    "\n",
    "def on_press(key):\n",
    "    global lane, running, _last_press_ts, _synth_block_until\n",
    "    now = time.monotonic()\n",
    "\n",
    "    # swallow AI-generated lane key events during the suppression window\n",
    "    if key in (keyboard.Key.left, keyboard.Key.right) and now < _synth_block_until:\n",
    "        return\n",
    "\n",
    "    if key != keyboard.Key.esc and (now - _last_press_ts) * 1000.0 < COOLDOWN_MS:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if key == keyboard.Key.left:\n",
    "            lane = max(MIN_LANE, lane - 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Left into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.right:\n",
    "            lane = min(MAX_LANE, lane + 1)\n",
    "            _last_press_ts = now\n",
    "            print(f\"Moved Right into → Lane {lane}\")\n",
    "\n",
    "        elif key == keyboard.Key.esc:\n",
    "            running = False\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# Class buckets for probe classification\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "def _fmt_px(v):\n",
    "    return f\"{v:.1f}px\" if v is not None else \"n/a\"\n",
    "\n",
    "# =======================\n",
    "# Parsec to front + click Start (non-blocking failures)\n",
    "# =======================\n",
    "try:\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell application \"Parsec\" to activate'], check=False)\n",
    "    time.sleep(0.4)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pyautogui.click(start_click)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # must be above Jake\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "# --------- walk-the-ray classifier (first-hit wins) ----------\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], [], [], []  # colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays, hit_class_ids, hit_distances_px = [], [], [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_colour = COLOR_GREEN\n",
    "        hit_cls = None\n",
    "        hit_dist_px = None\n",
    "\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            # RED first (so if red exists at a point, we record red distance)\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_RED\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then YELLOW\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_YELLOW\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "            # then BOOTS\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = COLOR_PINK\n",
    "                    hit_cls = int(classes_np[i])\n",
    "                    hit_dist_px = float(t)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found: break\n",
    "\n",
    "        x1 = _clampi(int(round(x0 + dx1 * sample_px)), 0, W-1)\n",
    "        y1 = _clampi(int(round(y0 + dy1 * sample_px)), 0, H-1)\n",
    "\n",
    "        colours.append(hit_colour)\n",
    "        rays.append(((int(x0), int(y0)), (x1, y1), float(theta)))\n",
    "        hit_class_ids.append(hit_cls)\n",
    "        hit_distances_px.append(hit_dist_px)\n",
    "\n",
    "    return colours, rays, hit_class_ids, hit_distances_px\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    \"\"\"\n",
    "    Returns (…)\n",
    "      tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "      masks_np, classes_np, rail_mask, green_mask,\n",
    "      tri_positions, tri_colours, tri_rays,\n",
    "      best_idx, best_deg, x_ref,\n",
    "      tri_hit_classes, tri_summary\n",
    "    \"\"\"\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return (None, 0, 0, 0.0, 0.0, None, None, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    classes_np = promote_lowbarrier_when_wall(frame_bgr, masks_np, classes_np)\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return (None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None,\n",
    "                [], [], [], None, None, None, [], [])\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Jake triangle by bearing\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "\n",
    "    MIN_AHEAD_FROM_JAKE_PX = 120  # tune (e.g., 80–160)\n",
    "    tri_positions = [p for p in tri_positions if (yj - p[1]) >= MIN_AHEAD_FROM_JAKE_PX]\n",
    "\n",
    "    # Filter triangles by absolute angle from vertical (≤ 45°) and at least 6px above Jake\n",
    "    ANGLE_MAX_DEG = 45.0\n",
    "    MIN_DY_ABOVE  = 100\n",
    "\n",
    "    def _angle_ok(p):\n",
    "        xt, yt = p\n",
    "        dy = yt - yj\n",
    "        if dy >= -MIN_DY_ABOVE:     # must be above Jake\n",
    "            return False\n",
    "        deg = signed_degrees_from_vertical(xt - xj, dy)\n",
    "        return abs(deg) <= ANGLE_MAX_DEG\n",
    "\n",
    "    tri_positions = [p for p in tri_positions if _angle_ok(p)]\n",
    "\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    if lane_name == \"mid\" and (best_idx is not None) and (0 <= best_idx < len(tri_positions)):\n",
    "        x_ref = tri_positions[best_idx][0]\n",
    "    else:\n",
    "        x_ref = xj\n",
    "\n",
    "    tri_colours, tri_rays, tri_hit_classes, tri_hit_dists = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "\n",
    "    if tri_positions and any(ty >= (H) for _, ty in tri_positions):\n",
    "    # compute rail_grad/edge_dist and run the loop\n",
    "\n",
    "        # --- edge-danger override: triangles too close to rail edges in bottom half ---\n",
    "        EDGE_PAD_PX = 50\n",
    "\n",
    "        # distance-to-rail-edge map (in pixels)\n",
    "        rail_grad = cv2.morphologyEx(rail_mask.astype(np.uint8), cv2.MORPH_GRADIENT,\n",
    "                                    cv2.getStructuringElement(cv2.MORPH_RECT, (3,3)))\n",
    "        # distanceTransform gives distance to the nearest 0; make edges=0, elsewhere=255\n",
    "        edge_bg = (rail_grad == 0).astype(np.uint8) * 255\n",
    "        edge_dist = cv2.distanceTransform(edge_bg, cv2.DIST_L2, 5)\n",
    "\n",
    "        # mark triangles as danger if they're within EDGE_PAD_PX of an edge\n",
    "        # AND they sit in the bottom half of the screen (y >= H//2)\n",
    "        for i, (tx, ty) in enumerate(tri_positions):\n",
    "            if ty >= (H // 2) and edge_dist[int(ty), int(tx)] <= EDGE_PAD_PX:\n",
    "                tri_colours[i]      = COLOR_RED          # show as red in the overlay\n",
    "                tri_hit_classes[i]  = 1                  # any class in DANGER_RED; 1=GREYTRAIN works\n",
    "                tri_hit_dists[i]    = 0.0                # optional: treat as immediate\n",
    "\n",
    "\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    # Minimal movement-friendly summary (pos, hit_class id/label, is_jake)\n",
    "    tri_summary = []\n",
    "    for i, (x, y) in enumerate(tri_positions):\n",
    "        cid = tri_hit_classes[i] if i < len(tri_hit_classes) else None\n",
    "        hdist = tri_hit_dists[i] if i < len(tri_hit_dists) else None\n",
    "        tri_summary.append({\n",
    "            \"pos\": (int(x), int(y)),\n",
    "            \"hit_class\": None if cid is None else int(cid),\n",
    "            \"hit_label\": None if cid is None else LABELS.get(int(cid), f\"C{int(cid)}\"),\n",
    "            \"hit_dist_px\": None if hdist is None else float(hdist),\n",
    "            \"is_jake\": (i == best_idx)\n",
    "        })\n",
    "\n",
    "\n",
    "    #PATHING LOGIC HERE# =================================================================================================================================================================\n",
    "    # ===== PATHING / ACTION LOGIC =================================================\n",
    "    jake_tri = next((t for t in tri_summary if t.get(\"is_jake\")), None)\n",
    "    if jake_tri:\n",
    "        jx, jy = jake_tri[\"pos\"]\n",
    "        jake_hit = jake_tri[\"hit_class\"]\n",
    "\n",
    "        # For movement logging: distance to the obstacle ahead of Jake\n",
    "\n",
    "        y_hit_log = first_red_hit_y(jake_tri[\"pos\"], masks_np, classes_np, H, W, band_px=6, step_px=5)\n",
    "        obstacle_dist_px = (jy - y_hit_log) if y_hit_log is not None else None\n",
    "\n",
    "        # \"Yellow in Jake's lane\" == Jake's own triangle has a WARN_YELLOW class.\n",
    "        jake_cls = jake_tri.get(\"hit_class\", None)\n",
    "        if (jake_cls is not None) and (int(jake_cls) in WARN_YELLOW) and (int(jake_cls) in IMPACT_CLASSES):\n",
    "            # theta actually used for Jake’s ray (matches overlay)\n",
    "            theta_deg = float(tri_rays[best_idx][2]) if (best_idx is not None and 0 <= best_idx < len(tri_rays)) else 0.0\n",
    "            allowed_set = JUMP_SET if int(jake_cls) in JUMP_SET else DUCK_SET\n",
    "\n",
    "            dist_px, _, _ = first_mask_hit_starburst_then_ray_for_set(\n",
    "                jake_point=JAKE_POINT,\n",
    "                tri_pos=jake_tri[\"pos\"],\n",
    "                theta_deg=theta_deg,\n",
    "                masks_np=masks_np, classes_np=classes_np, H=H, W=W,\n",
    "                allowed_classes=allowed_set,\n",
    "                up2_px=SAMPLE_UP_PX, step_px=2\n",
    "            )\n",
    "\n",
    "            # ---- token: only lane + class ----\n",
    "            new_token = (lane, int(jake_cls))\n",
    "\n",
    "            global IMPACT_TOKEN\n",
    "            # Only arm if no timer for this token yet\n",
    "            if IMPACT_TOKEN is None:\n",
    "                if dist_px is not None and (IMPACT_MIN_PX < dist_px < IMPACT_MAX_PX):\n",
    "                    _arm_impact_timer(float(dist_px), int(jake_cls))\n",
    "                    IMPACT_TOKEN = new_token\n",
    "                    print(f\"[TIMER] lock token {IMPACT_TOKEN}\")\n",
    "                # else: don’t arm; wait for next frame when it enters the window\n",
    "\n",
    "            else:\n",
    "                if IMPACT_TOKEN == new_token:\n",
    "                    # If the previous timer already fired (no longer alive), allow immediate re-arm\n",
    "                    if not (IMPACT_TIMER and getattr(IMPACT_TIMER, \"is_alive\", lambda: False)()):\n",
    "                        _arm_impact_timer(float(dist_px), int(jake_cls))\n",
    "                        IMPACT_TOKEN = new_token\n",
    "                    # else: keep the existing live timer\n",
    "\n",
    "                    # Same situation → do nothing (no cancel, no re-arm), even if dist jitters/out of window\n",
    "                    pass\n",
    "                else:\n",
    "                    # Situation changed (lane or class) → cancel old and arm once for new (if in window)\n",
    "                    _cancel_impact_timer(\"token change\")\n",
    "                    if dist_px is not None and (IMPACT_MIN_PX < dist_px < IMPACT_MAX_PX):\n",
    "                        _arm_impact_timer(float(dist_px), int(jake_cls))\n",
    "                        IMPACT_TOKEN = new_token\n",
    "                        print(f\"[TIMER] lock token {IMPACT_TOKEN} (replaced)\")\n",
    "                    else:\n",
    "                        IMPACT_TOKEN = None  # no valid new timer yet\n",
    "        else:\n",
    "            # Jake’s triangle not yellow/impact anymore → cancel & unlock\n",
    "            if IMPACT_TOKEN is not None:\n",
    "                _cancel_impact_timer(\"no longer impact in Jake lane\")\n",
    "                IMPACT_TOKEN = None\n",
    "\n",
    "\n",
    "        # --- 2) Lateral pathing decisions (policy: GREEN first) --------------------\n",
    "        # Build reusable candidate pools (excluding Jake's current triangle)\n",
    "        greens  = [t for t in tri_summary if t[\"hit_class\"] is None]\n",
    "        yellows = [t for t in tri_summary if (t[\"hit_class\"] is not None and int(t[\"hit_class\"]) in WARN_FOR_MOVE)]\n",
    "        reds    = [t for t in tri_summary if (t[\"hit_class\"] is not None and int(t[\"hit_class\"]) in DANGER_RED)]\n",
    "\n",
    "        # Lane-based pruning\n",
    "        greens  = _filter_by_lane(greens,  jx, lane)\n",
    "        yellows = _filter_by_lane(yellows, jx, lane)\n",
    "        reds    = _filter_by_lane(reds,    jx, lane)\n",
    "\n",
    "        # Only consider yellow if it's far enough ahead of the Jake band (e.g., 400px)\n",
    "        jake_band_y   = jake_point[1]  # 1340 with your lane points\n",
    "        yellows_far   = _filter_yellow_far(yellows, jake_band_y)  # uses MIN_YELLOW_AHEAD_PX\n",
    "        greens_far  = _filter_green_far(greens, jake_band_y)\n",
    "\n",
    "\n",
    "        def _nearest_x(cands):\n",
    "            return min(cands, key=lambda c: abs(c[\"pos\"][0] - jx)) if cands else None\n",
    "\n",
    "        # Score for \"least-bad red\": prefer the ray that hits red furthest away.\n",
    "        # If 'hit_dist_px' isn't present in tri_summary, fall back to apex distance.\n",
    "        jake_band_y = jake_point[1]\n",
    "\n",
    "        def _red_score(c):\n",
    "            y_hit = first_red_hit_y(c[\"pos\"], masks_np, classes_np, H, W, band_px=6, step_px=5)\n",
    "            if y_hit is None:\n",
    "                return (float('inf'), -abs(c[\"pos\"][0] - jx))  # no red in range = strictly better\n",
    "            ahead_px = jake_band_y - y_hit  # larger = farther ahead\n",
    "            return (ahead_px, -abs(c[\"pos\"][0] - jx))\n",
    "\n",
    "\n",
    "        # If Jake is already GREEN, stay put.\n",
    "        if jake_hit is None:\n",
    "            pass\n",
    "\n",
    "        # RED ahead: GREEN -> (far) YELLOW -> least-bad RED (all-red fallback)\n",
    "        elif _is_danger(jake_hit):\n",
    "            tgt = _nearest_x(greens)\n",
    "            if tgt is not None:\n",
    "                if MOVEMENT_ENABLED:\n",
    "                    print(f\"[MOVE] RED ahead → GREEN: obstacle={LABELS.get(int(jake_hit), str(jake_hit))}, dist={_fmt_px(obstacle_dist_px)}; target_x={tgt['pos'][0]}\")\n",
    "                _issue_move_towards_x(jx, tgt[\"pos\"][0])\n",
    "            else:\n",
    "                tgt = _nearest_x(yellows_far)   # only yellows ≥ threshold above the band\n",
    "                if tgt is not None:\n",
    "                    if MOVEMENT_ENABLED:\n",
    "                        ahead_px = jake_band_y - tgt[\"pos\"][1]\n",
    "                        print(f\"[MOVE] RED ahead → YELLOW (far): obstacle={LABELS.get(int(jake_hit), str(jake_hit))}, dist={_fmt_px(obstacle_dist_px)}; yellow_ahead={int(ahead_px)}px (≥{MIN_YELLOW_AHEAD_PX})\")\n",
    "                    _issue_move_towards_x(jx, tgt[\"pos\"][0])\n",
    "                else:\n",
    "                    if reds:\n",
    "                        # When choosing best_red:\n",
    "                        best_red = max(reds, key=_red_score)\n",
    "                        tx = best_red[\"pos\"][0]\n",
    "                        if tx != jx:                      # avoid needless move if staying is best\n",
    "                            _issue_move_towards_x(jx, tx)\n",
    "\n",
    "                    # else: boxed in → no lateral move this frame\n",
    "\n",
    "        # YELLOW ahead: try GREEN; if none, rely on countermeasures (jump/duck)\n",
    "        elif _is_warn(jake_hit):\n",
    "            tgt = _nearest_x(greens_far)  # only consider far-enough greens\n",
    "            if tgt is not None:\n",
    "                _issue_move_towards_x(jx, tgt[\"pos\"][0])\n",
    "    # else: no safe far green → hold lane; jump/duck handled above\n",
    "\n",
    "            # else: no green → hold lane; jumps/ducks already handled above\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "#END\n",
    "# ============================================================================\n",
    "\n",
    "    return (tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms,\n",
    "            masks_np, classes_np, rail_mask, green,\n",
    "            tri_positions, tri_colours, tri_rays,\n",
    "            best_idx, best_deg, x_ref,\n",
    "            tri_hit_classes, tri_summary)\n",
    "\n",
    "# =======================\n",
    "# Viz helpers\n",
    "# =======================\n",
    "def _colour_for_point(x, y, masks_np, classes_np, H, W):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0: return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "    my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5: cls_here = int(c); break\n",
    "    if cls_here in DANGER_RED:   return COLOR_RED\n",
    "    if cls_here in WARN_YELLOW:  return COLOR_YELLOW\n",
    "    if cls_here in BOOTS_PINK:   return COLOR_PINK\n",
    "    return COLOR_GREEN\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, COLOR_BLACK, 1, cv2.LINE_AA)\n",
    "\n",
    "def triangle_pts(x, y, size=TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    return np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask,\n",
    "                    tri_positions, tri_colours, tri_rays, best_idx, best_deg, x_ref, jake_point):\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # tiny scout lines (viz only)\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                out[yy, x] = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "\n",
    "    # starburst to Jake\n",
    "    xj, yj = jake_point\n",
    "    for idx, (xt, yt) in enumerate(tri_positions):\n",
    "        xt = _clampi(int(xt), 0, W-1); yt = _clampi(int(yt), 0, H-1)\n",
    "        deg_signed = signed_degrees_from_vertical(xt - xj, yt - yj)\n",
    "        cv2.line(out, (xj, yj), (xt, yt),\n",
    "                 COLOR_CYAN if idx == best_idx else COLOR_WHITE, 2, cv2.LINE_AA)\n",
    "        mx = (xj + xt) // 2; my = (yj + yt) // 2\n",
    "\n",
    "    # curved sampling rays (viz)\n",
    "    for (p0, p1, theta) in tri_rays:\n",
    "        cv2.line(out, p0, p1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        mx = (p0[0] + p1[0]) // 2; my = (p0[1] + p1[1]) // 2\n",
    "\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, int(x), int(y), colour=col)\n",
    "\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    if best_idx is not None and 0 <= best_idx < len(tri_positions):\n",
    "        xt, yt = tri_positions[best_idx]\n",
    "\n",
    "        # theta used for that triangle in classify_triangles_at_sample_curved\n",
    "        theta_deg = tri_rays[best_idx][2] if best_idx < len(tri_rays) else 0.0\n",
    "\n",
    "        dist_px, hit_xy, hit_cls = first_mask_hit_starburst_then_ray(\n",
    "            jake_point=jake_point,\n",
    "            tri_pos=(int(xt), int(yt)),\n",
    "            theta_deg=float(theta_deg),\n",
    "            masks_np=masks_np, classes_np=classes_np, H=H, W=W,\n",
    "            up2_px=SAMPLE_UP_PX, step_px=2,\n",
    "            exclude_classes=(RAIL_ID,),   # skip rails\n",
    "            danger_only=False             # set True to only consider DANGER_RED\n",
    "        )\n",
    "\n",
    "        # draw starburst segment (cyan + thicker)\n",
    "        xj, yj = jake_point\n",
    "        cv2.line(out, (xj, yj), (int(xt), int(yt)), COLOR_CYAN, 3, cv2.LINE_AA)\n",
    "\n",
    "        # draw the angled continuation for viz (cyan + thicker)\n",
    "        dxr, dyr = TRIG_TABLE.get(float(theta_deg), (0.0, -1.0))\n",
    "        xe = _clampi(int(round(xt + dxr * SAMPLE_UP_PX)), 0, W-1)\n",
    "        ye = _clampi(int(round(yt + dyr * SAMPLE_UP_PX)), 0, H-1)\n",
    "        cv2.line(out, (int(xt), int(yt)), (xe, ye), COLOR_CYAN, 3, cv2.LINE_AA)\n",
    "\n",
    "        # OPTIONAL: cyan outline around the best triangle so it pops\n",
    "        cv2.polylines(out, [triangle_pts(int(xt), int(yt)).reshape(-1,1,2)], True, COLOR_CYAN, 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        if hit_xy is not None:\n",
    "            cv2.circle(out, hit_xy, 6, (0, 0, 0), -1, cv2.LINE_AA)\n",
    "            cv2.circle(out, hit_xy, 4, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "        dist_text = \"∞\" if dist_px is None else f\"{dist_px:.1f}px\"\n",
    "        if hit_cls is not None:\n",
    "            dist_text += f\" → {LABELS.get(hit_cls, str(hit_cls))}\"\n",
    "        midx = (xj + int(xt)) // 2\n",
    "        midy = (yj + int(yt)) // 2 - 10\n",
    "        cv2.putText(out, f\"Jake→tri (ray) first-hit: {dist_text}\",\n",
    "                    (max(5, midx - 160), max(24, midy)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, f\"Jake→tri (ray) first-hit: {dist_text}\",\n",
    "                    (max(5, midx - 160), max(24, midy)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # TIME KEEPING\n",
    "\n",
    "        elapsed_ms = (time.perf_counter() - start_time) * 1000.0\n",
    "        time_str = f\"{elapsed_ms:.3f} ms\"\n",
    "\n",
    "        # position in bottom-right corner\n",
    "        (text_w, text_h), _ = cv2.getTextSize(time_str, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "        x_pos = out.shape[1] - text_w - 10  # 10px from right edge\n",
    "        y_pos = out.shape[0] - 10           # 10px from bottom edge\n",
    "\n",
    "        # draw text\n",
    "        cv2.putText(out, time_str, (x_pos, y_pos),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, time_str, (x_pos, y_pos),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # -------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    # top-left JAKE_POINT state\n",
    "    cv2.putText(out, f\"JAKE_POINT: {lane_name.upper()}\",\n",
    "                (10, 24), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Live loop\n",
    "# =======================   \n",
    "\n",
    "listener = keyboard.Listener(on_press=on_press)\n",
    "listener.start()\n",
    "\n",
    "sct = mss()\n",
    "frame_idx = 0\n",
    "\n",
    "from mss import mss\n",
    "\n",
    "if advertisement:\n",
    "    CHECK_X, CHECK_Y = 1030, 900\n",
    "else:\n",
    "    CHECK_X, CHECK_Y = 870, 895\n",
    "\n",
    "#===========================================Resource consuption monitoring===========================================\n",
    "\n",
    "import psutil\n",
    "import os\n",
    "import subprocess, threading, re\n",
    "import subprocess\n",
    "import threading\n",
    "import re\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "def print_system_usage():\n",
    "    cpu_percent = psutil.cpu_percent(interval=None)\n",
    "    mem_info = process.memory_info()\n",
    "    rss_mb = mem_info.rss / (1024 ** 2)  # Resident memory in MB\n",
    "    print(f\"[SYS] CPU: {cpu_percent:.1f}%  |  RAM: {rss_mb:.1f} MB\")\n",
    "\n",
    "    import subprocess, threading, re\n",
    "\n",
    "def stream_mps_gpu_stats():\n",
    "    # requires sudo; run your script with:  sudo python your_script.py\n",
    "    cmd = [\"powermetrics\", \"--samplers\", \"gpu_power\", \"-i\", \"200\"]\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "    busy_re = re.compile(r\"GPU Busy\\s*=\\s*(\\d+)%\")\n",
    "    power_re = re.compile(r\"GPU Power\\s*=\\s*([\\d\\.]+)\\s*W\")\n",
    "    for line in p.stdout:\n",
    "        m1 = busy_re.search(line); m2 = power_re.search(line)\n",
    "        if m1 or m2:\n",
    "            busy = m1.group(1) if m1 else \"?\"\n",
    "            power = m2.group(1) if m2 else \"?\"\n",
    "            print(f\"[GPU] Busy {busy}% | Power {power} W\")\n",
    "\n",
    "# call once before your while-loop:\n",
    "threading.Thread(target=stream_mps_gpu_stats, daemon=True).start()\n",
    "\n",
    "#=====================================================================================================================\n",
    "\n",
    "# =======================\n",
    "\n",
    "save_frames = False\n",
    "power_metrics = True\n",
    "\n",
    "# =======================\n",
    "\n",
    "while running:\n",
    "    frame_start_time = time.perf_counter()\n",
    "\n",
    "    _now = time.monotonic()\n",
    "    if _now < PAUSE_UNTIL:\n",
    "        time.sleep(PAUSE_UNTIL - _now)\n",
    "        continue\n",
    "\n",
    "    frame_idx += 1\n",
    "    print('/n')\n",
    "    print(f'===================================== Operating on frame {frame_idx} =====================================')\n",
    "\n",
    "    # --- Screen grab ---\n",
    "    t0_grab = time.perf_counter()\n",
    "    left, top, width, height = snap_coords\n",
    "    raw = sct.grab({\"left\": left, \"top\": top, \"width\": width, \"height\": height})\n",
    "    frame_bgr = np.array(raw)[:, :, :3]  # BGRA -> BGR\n",
    "    grab_ms = (time.perf_counter() - t0_grab) * 1000.0\n",
    "\n",
    "    # --- ABSOLUTE SCREEN pixel check ---\n",
    "    t0_check = time.perf_counter()\n",
    "    arr = np.array(sct.grab({\"left\": CHECK_X, \"top\": CHECK_Y, \"width\": 1, \"height\": 1}))\n",
    "    b, g, r, a = arr[0, 0]\n",
    "    TOL = 20\n",
    "    target = (61, 156, 93)\n",
    "\n",
    "    pixel_check_ms = (time.perf_counter() - t0_check) * 1000.0\n",
    "\n",
    "    # --- Lane detection ---\n",
    "    t0_lane = time.perf_counter()\n",
    "    _detected = _detect_lane_by_whiteness(frame_bgr)\n",
    "    if _detected is not None:\n",
    "        lane = _detected  # 0/1/2\n",
    "    JAKE_POINT = LANE_POINTS[lane]\n",
    "    lane_ms = (time.perf_counter() - t0_lane) * 1000.0\n",
    "\n",
    "    # --- Inference ---\n",
    "    t0_inf = time.perf_counter()\n",
    "    res_list = model.predict(\n",
    "        [frame_bgr], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "    )\n",
    "    infer_ms = (time.perf_counter() - t0_inf) * 1000.0\n",
    "    yres = res_list[0]\n",
    "\n",
    "    # --- Postproc ---\n",
    "    t0_post = time.perf_counter()\n",
    "    (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "     masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours,\n",
    "     tri_rays, best_idx, best_deg, x_ref,\n",
    "     tri_hit_classes, tri_summary) = process_frame_post(frame_bgr, yres, JAKE_POINT)\n",
    "    postproc_ms = (time.perf_counter() - t0_post) * 1000.0\n",
    "\n",
    "    total_proc_ms = grab_ms + pixel_check_ms + lane_ms + infer_ms + postproc_ms\n",
    "\n",
    "    if save_frames:\n",
    "        elapsed_no_post = time.perf_counter() - frame_start_time\n",
    "        print(f\"Frame {frame_idx} WITHOUT POSTPROC WAS: {elapsed_no_post * 1000:.2f} ms\")\n",
    "\n",
    "    if save_frames:\n",
    "        t0_overlay = time.perf_counter()\n",
    "        overlay = render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask,\n",
    "                                  tri_positions, tri_colours, tri_rays, best_idx, best_deg, x_ref, JAKE_POINT)\n",
    "        out_path = out_dir / f\"live_overlay_{frame_idx:05d}.jpg\"\n",
    "        cv2.imwrite(str(out_path), overlay)\n",
    "        overlay_ms = (time.perf_counter() - t0_overlay) * 1000.0\n",
    "    else:\n",
    "        overlay_ms = 0.0\n",
    "\n",
    "    total_elapsed_ms = (time.perf_counter() - frame_start_time) * 1000.0\n",
    "\n",
    "    if power_metrics:\n",
    "        print_system_usage()\n",
    "\n",
    "\n",
    "    # --- Timing summary ---\n",
    "    print(\n",
    "        f\"[TIMINGS] Grab={grab_ms:.2f} ms | PixelChk={pixel_check_ms:.2f} ms | \"\n",
    "        f\"LaneDet={lane_ms:.2f} ms | Inference={infer_ms:.2f} ms | \"\n",
    "        f\"Postproc={postproc_ms:.2f} ms | Overlay={overlay_ms:.2f} ms | \"\n",
    "        f\"TOTAL={total_elapsed_ms:.2f} ms\"\n",
    "    )\n",
    "\n",
    "# Cleanup\n",
    "listener.join()\n",
    "print(\"Script halted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751073b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1559998765.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msudo powermetrics --samplers gpu_power -i 200\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sudo powermetrics --samplers gpu_power -i 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1bc7bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing... (press Esc to quit)\n",
      "[FastGrabber] ~529.6 FPS   (region 1010x1812)\n",
      "[FastGrabber] ~555.1 FPS   (region 1010x1812)\n",
      "[FastGrabber] ~567.5 FPS   (region 1010x1812)\n",
      "[FastGrabber] ~570.5 FPS   (region 1010x1812)\n",
      "Stopped.\n"
     ]
    }
   ],
   "source": [
    "# fast_capture.py\n",
    "# High-FPS, low-latency screenshot capture (capture-only).\n",
    "# - Crops at source (mss region) to avoid post-crop cost\n",
    "# - Two-slot ring buffer (always read the freshest frame)\n",
    "# - Zero-copy NumPy view over mss bytes (BGRA) to minimize overhead\n",
    "# - Esc to quit (demo mode)\n",
    "#\n",
    "# Usage (as module):\n",
    "#   grabber = FastGrabber(left=100, top=100, width=640, height=360)\n",
    "#   ts, frame_bgra = grabber.latest()   # Non-blocking; returns None until first frame\n",
    "#   ...\n",
    "#   grabber.stop()\n",
    "#\n",
    "# Run file directly to see a minimal FPS print demo (no UI).\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    import mss  # pip install mss\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please `pip install mss` first\") from e\n",
    "\n",
    "\n",
    "class FastGrabber:\n",
    "    \"\"\"\n",
    "    Fast screen grabber that continuously captures a cropped region and exposes the latest frame.\n",
    "\n",
    "    Frame format: BGRA uint8, shape = (H, W, 4) as a zero-copy NumPy view over mss bytes.\n",
    "    NOTE: The returned array is READ-ONLY (backed by an immutable bytes buffer). Copy only if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, left: int, top: int, width: int, height: int, maxlen: int = 2, throttle_hz: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        :param left, top, width, height: capture region (pixels) — crop AT SOURCE for speed\n",
    "        :param maxlen: ring buffer length (2 recommended)\n",
    "        :param throttle_hz: optional soft cap on capture rate; None for 'as fast as possible'\n",
    "        \"\"\"\n",
    "        self.region = {\"left\": int(left), \"top\": int(top), \"width\": int(width), \"height\": int(height)}\n",
    "        self._sct = mss.mss()\n",
    "        self._buf = deque(maxlen=maxlen)  # (ts, np.ndarray BGRA view)\n",
    "        self._running = threading.Event()\n",
    "        self._running.set()\n",
    "        self._throttle_dt = (1.0 / throttle_hz) if throttle_hz else 0.0\n",
    "\n",
    "        self._thr = threading.Thread(target=self._loop, name=\"FastGrabber\", daemon=True)\n",
    "        self._thr.start()\n",
    "\n",
    "    def _grab_once(self) -> Tuple[float, np.ndarray]:\n",
    "        ts = time.perf_counter()\n",
    "        shot = self._sct.grab(self.region)  # Cropped capture at source\n",
    "        # Zero-copy view over raw bytes (BGRA)\n",
    "        arr = np.frombuffer(shot.raw, dtype=np.uint8)\n",
    "        arr = arr.reshape((shot.height, shot.width, 4))\n",
    "        return ts, arr  # BGRA view (read-only)\n",
    "\n",
    "    def _loop(self):\n",
    "        next_deadline = 0.0\n",
    "        while self._running.is_set():\n",
    "            ts, frame = self._grab_once()\n",
    "            self._buf.append((ts, frame))\n",
    "            if self._throttle_dt > 0.0:\n",
    "                next_deadline += self._throttle_dt\n",
    "                sleep_s = max(0.0, next_deadline - time.perf_counter())\n",
    "                if sleep_s:\n",
    "                    time.sleep(sleep_s)\n",
    "\n",
    "    def latest(self) -> Optional[Tuple[float, np.ndarray]]:\n",
    "        \"\"\"Return the most recent (ts, frame_bgra) or None if not yet available. Non-blocking.\"\"\"\n",
    "        return self._buf[-1] if self._buf else None\n",
    "\n",
    "    def stop(self):\n",
    "        self._running.clear()\n",
    "        if self._thr.is_alive():\n",
    "            self._thr.join(timeout=1.0)\n",
    "        try:\n",
    "            self._sct.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ---------- Minimal demo (no display) ----------\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "\n",
    "    # Example region (edit to your game area)\n",
    "    LEFT, TOP, WIDTH, HEIGHT = 0, 0, 1010, 1812\n",
    "\n",
    "\n",
    "    grabber = FastGrabber(LEFT, TOP, WIDTH, HEIGHT, throttle_hz=None)  # as fast as possible\n",
    "\n",
    "    print(\"Capturing... (press Esc to quit)\")\n",
    "    # Simple Esc listener without extra deps\n",
    "    try:\n",
    "        import termios, tty, select\n",
    "        def kbhit():\n",
    "            dr, _, _ = select.select([sys.stdin], [], [], 0)\n",
    "            return bool(dr)\n",
    "        old = termios.tcgetattr(sys.stdin)\n",
    "        tty.setcbreak(sys.stdin.fileno())\n",
    "        esc_pressed = False\n",
    "    except Exception:\n",
    "        # Fallback: Ctrl+C to quit on platforms without termios (e.g., Windows)\n",
    "        old = None\n",
    "        esc_pressed = False\n",
    "\n",
    "    frames = 0\n",
    "    t0 = time.perf_counter()\n",
    "    last_print = t0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            item = grabber.latest()\n",
    "            if item is not None:\n",
    "                frames += 1\n",
    "            now = time.perf_counter()\n",
    "            if now - last_print >= 1.0:\n",
    "                fps = frames / (now - t0)\n",
    "                print(f\"[FastGrabber] ~{fps:5.1f} FPS   (region {WIDTH}x{HEIGHT})\")\n",
    "                last_print = now\n",
    "\n",
    "            # Esc to exit (POSIX)\n",
    "            if old is not None and kbhit():\n",
    "                ch = sys.stdin.read(1)\n",
    "                if ch == '\\x1b':  # ESC\n",
    "                    esc_pressed = True\n",
    "            if esc_pressed:\n",
    "                break\n",
    "\n",
    "            # tiny yield to keep the loop responsive without throttling capture thread\n",
    "            time.sleep(0.001)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if old is not None:\n",
    "            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old)\n",
    "        grabber.stop()\n",
    "        print(\"Stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee85ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing... (press Esc to quit)\n",
      "[FastGrabber] CAP   18.9 fps | TURNAROUND  median  47.11 ms  p95  77.43 ms  max  79.17 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   21.9 fps | TURNAROUND  median  44.00 ms  p95  48.08 ms  max  49.48 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   22.8 fps | TURNAROUND  median  43.08 ms  p95  51.73 ms  max  76.01 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   23.9 fps | TURNAROUND  median  42.68 ms  p95  45.88 ms  max  47.73 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   22.0 fps | TURNAROUND  median  43.79 ms  p95  53.80 ms  max  69.35 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   23.0 fps | TURNAROUND  median  42.67 ms  p95  46.67 ms  max  59.20 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   21.0 fps | TURNAROUND  median  42.16 ms  p95 105.07 ms  max 114.14 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   20.9 fps | TURNAROUND  median  42.31 ms  p95  72.46 ms  max  78.84 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   23.0 fps | TURNAROUND  median  43.21 ms  p95  50.51 ms  max  69.42 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   22.8 fps | TURNAROUND  median  42.14 ms  p95  48.85 ms  max  53.67 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   22.8 fps | TURNAROUND  median  42.20 ms  p95  47.88 ms  max  82.67 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   27.0 fps | TURNAROUND  median  37.93 ms  p95  45.30 ms  max  50.30 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   23.0 fps | TURNAROUND  median  43.09 ms  p95  52.00 ms  max  57.37 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   25.0 fps | TURNAROUND  median  40.17 ms  p95  46.32 ms  max  50.03 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   22.0 fps | TURNAROUND  median  43.69 ms  p95  51.84 ms  max  55.61 ms (region 1010x1812)\n",
      "[FastGrabber] CAP   24.0 fps | TURNAROUND  median  41.36 ms  p95  47.69 ms  max  52.84 ms (region 1010x1812)\n",
      "Stopped.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# fast_capture.py\n",
    "# High-FPS, low-latency screenshot capture (capture-only) with real capture FPS\n",
    "# and turnaround (age) stats.\n",
    "#\n",
    "# - Crops at source (mss region)\n",
    "# - Two-slot ring buffer (always read freshest frame; drops stale ones)\n",
    "# - Zero-copy NumPy view over mss bytes (BGRA)\n",
    "# - Prints true CAPTURE FPS and TURNAROUND median/p95/max once per second\n",
    "# - Esc to quit (POSIX & Windows), or Ctrl+C\n",
    "#\n",
    "# Usage as module:\n",
    "#   grabber = FastGrabber(left=100, top=100, width=640, height=360)\n",
    "#   item = grabber.latest_with_age()  # -> (ts, frame_bgra, age_ms) or None\n",
    "#   ...\n",
    "#   grabber.stop()\n",
    "\n",
    "import time\n",
    "import threading\n",
    "import statistics\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    import mss  # pip install mss\n",
    "except Exception as e:\n",
    "    raise SystemExit(\"Please `pip install mss` first\") from e\n",
    "\n",
    "\n",
    "class FastGrabber:\n",
    "    \"\"\"\n",
    "    Fast screen grabber that continuously captures a cropped region and exposes the latest frame.\n",
    "\n",
    "    Frame format: BGRA uint8, shape = (H, W, 4) as a zero-copy NumPy view over mss bytes.\n",
    "    NOTE: The returned array is READ-ONLY (backed by an immutable bytes buffer). Copy only if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        left: int,\n",
    "        top: int,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        maxlen: int = 2,\n",
    "        throttle_hz: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param left, top, width, height: capture region (pixels) — crop AT SOURCE for speed\n",
    "        :param maxlen: ring buffer length (2 recommended)\n",
    "        :param throttle_hz: optional soft cap on capture rate; None = as fast as possible\n",
    "        \"\"\"\n",
    "        self.region = {\"left\": int(left), \"top\": int(top), \"width\": int(width), \"height\": int(height)}\n",
    "        self._sct = mss.mss()\n",
    "        self._buf = deque(maxlen=maxlen)  # (ts, np.ndarray BGRA view)\n",
    "        self._running = threading.Event()\n",
    "        self._running.set()\n",
    "        self._throttle_dt = (1.0 / throttle_hz) if throttle_hz else 0.0\n",
    "\n",
    "        # stats\n",
    "        self._cap_count = 0                # total captured frames\n",
    "        self._t0 = time.perf_counter()     # start time for stats\n",
    "\n",
    "        self._thr = threading.Thread(target=self._loop, name=\"FastGrabber\", daemon=True)\n",
    "        self._thr.start()\n",
    "\n",
    "    def _grab_once(self) -> Tuple[float, np.ndarray]:\n",
    "        ts = time.perf_counter()\n",
    "        shot = self._sct.grab(self.region)  # Cropped capture at source\n",
    "        # Zero-copy view over raw bytes (BGRA)\n",
    "        arr = np.frombuffer(shot.raw, dtype=np.uint8).reshape((shot.height, shot.width, 4))\n",
    "        return ts, arr  # BGRA view (read-only)\n",
    "\n",
    "    def _loop(self):\n",
    "        next_deadline = 0.0\n",
    "        while self._running.is_set():\n",
    "            ts, frame = self._grab_once()\n",
    "            self._buf.append((ts, frame))\n",
    "            self._cap_count += 1\n",
    "            if self._throttle_dt > 0.0:\n",
    "                next_deadline += self._throttle_dt\n",
    "                sleep_s = max(0.0, next_deadline - time.perf_counter())\n",
    "                if sleep_s:\n",
    "                    time.sleep(sleep_s)\n",
    "\n",
    "    def latest(self) -> Optional[Tuple[float, np.ndarray]]:\n",
    "        \"\"\"Return the most recent (ts, frame_bgra) or None if not yet available. Non-blocking.\"\"\"\n",
    "        return self._buf[-1] if self._buf else None\n",
    "\n",
    "    def latest_with_age(self) -> Optional[Tuple[float, np.ndarray, float]]:\n",
    "        \"\"\"Return the most recent (ts, frame_bgra, age_ms) or None if not yet available.\"\"\"\n",
    "        item = self.latest()\n",
    "        if not item:\n",
    "            return None\n",
    "        ts, frame = item\n",
    "        age_ms = (time.perf_counter() - ts) * 1000.0\n",
    "        return ts, frame, age_ms\n",
    "\n",
    "    def capture_stats(self) -> Tuple[int, float, float]:\n",
    "        \"\"\"Return (total_captures, elapsed_s, avg_fps_since_start).\"\"\"\n",
    "        elapsed = max(1e-9, time.perf_counter() - self._t0)\n",
    "        return self._cap_count, elapsed, self._cap_count / elapsed\n",
    "\n",
    "    def stop(self):\n",
    "        self._running.clear()\n",
    "        if self._thr.is_alive():\n",
    "            self._thr.join(timeout=1.0)\n",
    "        try:\n",
    "            self._sct.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ---------- Minimal demo ----------\n",
    "def _posix_esc_support():\n",
    "    \"\"\"Return (kbhit, readch, cleanup) functions for POSIX, or (None, None, None) on failure.\"\"\"\n",
    "    try:\n",
    "        import sys, termios, tty, select\n",
    "        def kbhit():\n",
    "            dr, _, _ = select.select([sys.stdin], [], [], 0)\n",
    "            return bool(dr)\n",
    "        def readch():\n",
    "            return sys.stdin.read(1)\n",
    "        old = termios.tcgetattr(sys.stdin)\n",
    "        tty.setcbreak(sys.stdin.fileno())\n",
    "        def cleanup():\n",
    "            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old)\n",
    "        return kbhit, readch, cleanup\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def _windows_esc_support():\n",
    "    \"\"\"Return (kbhit, readch, cleanup) functions for Windows, or (None, None, None) on failure.\"\"\"\n",
    "    try:\n",
    "        import msvcrt\n",
    "        def kbhit():\n",
    "            return msvcrt.kbhit()\n",
    "        def readch():\n",
    "            return msvcrt.getch().decode(errors='ignore')\n",
    "        def cleanup():\n",
    "            return\n",
    "        return kbhit, readch, cleanup\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example region (edit to your game area)\n",
    "    LEFT, TOP, WIDTH, HEIGHT = 0, 0, 1010, 1812\n",
    "\n",
    "    grabber = FastGrabber(LEFT, TOP, WIDTH, HEIGHT, throttle_hz=None)  # as fast as possible\n",
    "    print(\"Capturing... (press Esc to quit)\")\n",
    "\n",
    "    # Cross-platform Esc support\n",
    "    kbhit, readch, cleanup = _posix_esc_support()\n",
    "    if kbhit is None:\n",
    "        kbhit, readch, cleanup = _windows_esc_support()\n",
    "    esc_pressed = False\n",
    "\n",
    "    # For stats\n",
    "    last_seen_ts = None\n",
    "    ages_ms: list[float] = []\n",
    "    last_tick = time.perf_counter()\n",
    "    last_cap_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            info = grabber.latest_with_age()\n",
    "            if info:\n",
    "                ts, frame_bgra, age_ms = info\n",
    "                if ts != last_seen_ts:\n",
    "                    last_seen_ts = ts\n",
    "                    ages_ms.append(age_ms)\n",
    "\n",
    "            now = time.perf_counter()\n",
    "            if now - last_tick >= 1.0:\n",
    "                # True capture FPS from producer thread\n",
    "                total, _, _ = grabber.capture_stats()\n",
    "                cap_fps_inst = (total - last_cap_count) / (now - last_tick)\n",
    "                last_cap_count = total\n",
    "\n",
    "                if ages_ms:\n",
    "                    ages_sorted = sorted(ages_ms)\n",
    "                    med = statistics.median(ages_sorted)\n",
    "                    p95 = ages_sorted[int(0.95 * (len(ages_sorted) - 1))]\n",
    "                    worst = ages_sorted[-1]\n",
    "                else:\n",
    "                    med = p95 = worst = float('nan')\n",
    "\n",
    "                print(\n",
    "                    f\"[FastGrabber] CAP {cap_fps_inst:6.1f} fps | \"\n",
    "                    f\"TURNAROUND  median {med:6.2f} ms  p95 {p95:6.2f} ms  max {worst:6.2f} ms \"\n",
    "                    f\"(region {WIDTH}x{HEIGHT})\"\n",
    "                )\n",
    "\n",
    "                ages_ms.clear()\n",
    "                last_tick = now\n",
    "\n",
    "            # Esc to exit\n",
    "            if kbhit and kbhit():\n",
    "                ch = readch()\n",
    "                if ch == '\\x1b':  # ESC\n",
    "                    esc_pressed = True\n",
    "            if esc_pressed:\n",
    "                break\n",
    "\n",
    "            # tiny yield to keep loop responsive\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if cleanup:\n",
    "            cleanup()\n",
    "        grabber.stop()\n",
    "        print(\"Stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1bc03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing via ffmpeg... (press Esc to quit)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "[FfmpegGrabber] CAP    0.0 fps | TURNAROUND median    nan ms  p95    nan ms  max    nan ms (region 1010x1812, fmt=nv12)\n",
      "Stopped.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# ffmpeg_capture.py\n",
    "# High-FPS capture of a large ROI via ffmpeg/avfoundation → rawvideo pipe.\n",
    "# Same public API style as your FastGrabber: latest_with_age(), capture_stats().\n",
    "#\n",
    "# Why faster? AVFoundation's screen pipeline is optimized & can output NV12 (1.5 B/px)\n",
    "# which cuts bandwidth vs Quartz BGRA (4 B/px). We crop at source, and stream frames.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "import statistics\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2  # pip install opencv-python\n",
    "\n",
    "class FfmpegGrabber:\n",
    "    \"\"\"\n",
    "    Spawn ffmpeg to capture a screen region and stream frames via stdout as rawvideo.\n",
    "    Works on macOS with -f avfoundation. Use BGRA (no convert) or NV12 (smaller bandwidth).\n",
    "\n",
    "    latest_with_age() -> (ts, frame, age_ms)\n",
    "      - if pix_fmt='bgra' and return_bgr=True: returns BGR uint8 (H,W,3)\n",
    "      - if pix_fmt='bgra' and return_bgr=False: returns BGRA uint8 (H,W,4) view\n",
    "      - if pix_fmt='nv12' and return_bgr=True: returns BGR converted from NV12\n",
    "      - if pix_fmt='nv12' and return_bgr=False: returns the NV12 buffer (H*3//2, W) uint8\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        left: int,\n",
    "        top: int,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        framerate: int = 120,\n",
    "        pix_fmt: str = \"nv12\",          # 'nv12' (fast) or 'bgra' (simple)\n",
    "        input_device: str = \"1:none\",   # <<< CHANGE THIS for your screen (see notes below)\n",
    "        return_bgr: bool = True,        # convert to BGR in Python (cost ~1–2 ms @ 1080p NV12)\n",
    "        ring_len: int = 2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_device examples (macOS):\n",
    "          - List devices:  ffmpeg -f avfoundation -list_devices true -i \"\"\n",
    "          - Primary display is often \"1:none\" or \"2:none\", or \"Capture screen 0\"\n",
    "          - You can also try: input_device='Capture screen 0'\n",
    "        \"\"\"\n",
    "        self.left, self.top, self.width, self.height = map(int, (left, top, width, height))\n",
    "        self.framerate = int(framerate)\n",
    "        self.pix_fmt = pix_fmt.lower()\n",
    "        assert self.pix_fmt in (\"bgra\", \"nv12\")\n",
    "        self.input_device = input_device\n",
    "        self.return_bgr = return_bgr\n",
    "\n",
    "        # bytes per frame\n",
    "        if self.pix_fmt == \"bgra\":\n",
    "            self.bytes_per_frame = self.width * self.height * 4\n",
    "        else:  # NV12: 1.5 bytes per pixel\n",
    "            self.bytes_per_frame = self.width * self.height * 3 // 2\n",
    "\n",
    "        self._buf = deque(maxlen=ring_len)   # (ts, frame_obj)\n",
    "        self._running = threading.Event()\n",
    "        self._running.set()\n",
    "        self._cap_count = 0\n",
    "        self._t0 = time.perf_counter()\n",
    "\n",
    "        self.proc = self._start_ffmpeg()\n",
    "        self._thr = threading.Thread(target=self._reader, name=\"FfmpegGrabber\", daemon=True)\n",
    "        self._thr.start()\n",
    "\n",
    "    def _start_ffmpeg(self) -> subprocess.Popen:\n",
    "        # Build ffmpeg command\n",
    "        # -f avfoundation: macOS screen capture\n",
    "        # -framerate: desired capture fps\n",
    "        # -i \"<device>\": see __init__ docstring for finding the right string\n",
    "        # -vf crop=WxH:x:y crops at source\n",
    "        # -pix_fmt: 'bgra' or 'nv12' (NV12 drastically reduces bandwidth)\n",
    "        # -f rawvideo - : write raw frames to stdout\n",
    "        vf = f\"crop={self.width}:{self.height}:{self.left}:{self.top}\"\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "            \"-f\", \"avfoundation\",\n",
    "            \"-framerate\", str(self.framerate),\n",
    "            \"-i\", self.input_device,\n",
    "            \"-vf\", vf,\n",
    "            \"-pix_fmt\", self.pix_fmt,\n",
    "            \"-an\", \"-sn\",\n",
    "            \"-f\", \"rawvideo\",\n",
    "            \"-\"\n",
    "        ]\n",
    "        # If your ffmpeg expects a different device string style, try:\n",
    "        #   self.input_device = \"Capture screen 0\"\n",
    "        # or use the numeric index you see in -list_devices\n",
    "\n",
    "        return subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            bufsize=0  # unbuffered\n",
    "        )\n",
    "\n",
    "    def _read_exact(self, n: int) -> bytes:\n",
    "        \"\"\"Read exactly n bytes from ffmpeg stdout.\"\"\"\n",
    "        data = bytearray(n)\n",
    "        view = memoryview(data)\n",
    "        read = 0\n",
    "        while read < n and self._running.is_set():\n",
    "            chunk = self.proc.stdout.read(n - read)\n",
    "            if not chunk:\n",
    "                break\n",
    "            view[read:read + len(chunk)] = chunk\n",
    "            read += len(chunk)\n",
    "        if read != n:\n",
    "            return b\"\"\n",
    "        return bytes(data)\n",
    "\n",
    "    def _reader(self):\n",
    "        while self._running.is_set():\n",
    "            ts = time.perf_counter()\n",
    "            raw = self._read_exact(self.bytes_per_frame)\n",
    "            if not raw:\n",
    "                # Try to detect process death\n",
    "                if self.proc.poll() is not None:\n",
    "                    break\n",
    "                # Otherwise, continue; might be a transient read issue\n",
    "                continue\n",
    "\n",
    "            # Interpret the raw frame depending on pix_fmt\n",
    "            if self.pix_fmt == \"bgra\":\n",
    "                frame = np.frombuffer(raw, dtype=np.uint8).reshape(self.height, self.width, 4)\n",
    "                if self.return_bgr:\n",
    "                    # Drop alpha; this is just a view, copy if you'll mutate\n",
    "                    frame_out = frame[..., :3]\n",
    "                else:\n",
    "                    frame_out = frame  # BGRA view\n",
    "            else:\n",
    "                # NV12: pack as (H*3/2, W) then cvtColor\n",
    "                yuv = np.frombuffer(raw, dtype=np.uint8).reshape(self.height * 3 // 2, self.width)\n",
    "                if self.return_bgr:\n",
    "                    frame_out = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_NV12)\n",
    "                else:\n",
    "                    frame_out = yuv  # NV12 buffer (H*3/2, W)\n",
    "\n",
    "            self._buf.append((ts, frame_out))\n",
    "            self._cap_count += 1\n",
    "\n",
    "        self._running.clear()\n",
    "\n",
    "    def latest(self) -> Optional[Tuple[float, np.ndarray]]:\n",
    "        return self._buf[-1] if self._buf else None\n",
    "\n",
    "    def latest_with_age(self) -> Optional[Tuple[float, np.ndarray, float]]:\n",
    "        item = self.latest()\n",
    "        if not item:\n",
    "            return None\n",
    "        ts, frame = item\n",
    "        age_ms = (time.perf_counter() - ts) * 1000.0\n",
    "        return ts, frame, age_ms\n",
    "\n",
    "    def capture_stats(self):\n",
    "        elapsed = max(1e-9, time.perf_counter() - self._t0)\n",
    "        return self._cap_count, elapsed, self._cap_count / elapsed\n",
    "\n",
    "    def stop(self):\n",
    "        self._running.clear()\n",
    "        try:\n",
    "            if self.proc and self.proc.poll() is None:\n",
    "                self.proc.terminate()\n",
    "                try:\n",
    "                    self.proc.wait(timeout=1.0)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    self.proc.kill()\n",
    "        finally:\n",
    "            try:\n",
    "                if self.proc and self.proc.stdout:\n",
    "                    self.proc.stdout.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "# ---------- Minimal demo (prints CAP fps + TURNAROUND stats) ----------\n",
    "def _posix_esc_support():\n",
    "    try:\n",
    "        import termios, tty, select\n",
    "        def kbhit():\n",
    "            dr, _, _ = select.select([sys.stdin], [], [], 0)\n",
    "            return bool(dr)\n",
    "        def readch():\n",
    "            return sys.stdin.read(1)\n",
    "        old = termios.tcgetattr(sys.stdin)\n",
    "        tty.setcbreak(sys.stdin.fileno())\n",
    "        def cleanup():\n",
    "            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old)\n",
    "        return kbhit, readch, cleanup\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "def _windows_esc_support():\n",
    "    try:\n",
    "        import msvcrt\n",
    "        def kbhit():\n",
    "            return msvcrt.kbhit()\n",
    "        def readch():\n",
    "            return msvcrt.getch().decode(errors='ignore')\n",
    "        def cleanup():\n",
    "            return\n",
    "        return kbhit, readch, cleanup\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === Set your capture region (keep your full size) ===\n",
    "    LEFT, TOP, WIDTH, HEIGHT = 0, 0, 1010, 1812\n",
    "\n",
    "    # 1) Find your screen device:\n",
    "    #    ffmpeg -f avfoundation -list_devices true -i \"\"\n",
    "    #    Use the \"Capture screen X\" entry or numeric index like \"1:none\"\n",
    "    INPUT_DEVICE = \"1:none\"   # <— change this for your machine\n",
    "\n",
    "    # 2) Choose pixel format: 'nv12' (faster) or 'bgra' (simple)\n",
    "    PIX_FMT = \"nv12\"\n",
    "    RETURN_BGR = True\n",
    "\n",
    "    grab = FfmpegGrabber(\n",
    "        LEFT, TOP, WIDTH, HEIGHT,\n",
    "        framerate=120,\n",
    "        pix_fmt=PIX_FMT,\n",
    "        input_device=INPUT_DEVICE,\n",
    "        return_bgr=RETURN_BGR,\n",
    "        ring_len=2\n",
    "    )\n",
    "    print(\"Capturing via ffmpeg... (press Esc to quit)\")\n",
    "\n",
    "    # Cross-platform ESC\n",
    "    kbhit, readch, cleanup = _posix_esc_support()\n",
    "    if kbhit is None:\n",
    "        kbhit, readch, cleanup = _windows_esc_support()\n",
    "    esc = False\n",
    "\n",
    "    last_seen_ts = None\n",
    "    ages_ms = []\n",
    "    last_tick = time.perf_counter()\n",
    "    last_cap_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            info = grab.latest_with_age()\n",
    "            if info:\n",
    "                ts, frame, age_ms = info\n",
    "                if ts != last_seen_ts:\n",
    "                    last_seen_ts = ts\n",
    "                    ages_ms.append(age_ms)\n",
    "\n",
    "            now = time.perf_counter()\n",
    "            if now - last_tick >= 1.0:\n",
    "                total, _, _ = grab.capture_stats()\n",
    "                cap_fps_inst = (total - last_cap_count) / (now - last_tick)\n",
    "                last_cap_count = total\n",
    "\n",
    "                if ages_ms:\n",
    "                    ages_sorted = sorted(ages_ms)\n",
    "                    med = statistics.median(ages_sorted)\n",
    "                    p95 = ages_sorted[int(0.95 * (len(ages_sorted) - 1))]\n",
    "                    worst = ages_sorted[-1]\n",
    "                else:\n",
    "                    med = p95 = worst = float('nan')\n",
    "\n",
    "                print(f\"[FfmpegGrabber] CAP {cap_fps_inst:6.1f} fps | \"\n",
    "                      f\"TURNAROUND median {med:6.2f} ms  p95 {p95:6.2f} ms  max {worst:6.2f} ms \"\n",
    "                      f\"(region {WIDTH}x{HEIGHT}, fmt={PIX_FMT})\")\n",
    "\n",
    "                ages_ms.clear()\n",
    "                last_tick = now\n",
    "\n",
    "            if kbhit and kbhit():\n",
    "                ch = readch()\n",
    "                if ch == '\\x1b':\n",
    "                    esc = True\n",
    "            if esc:\n",
    "                break\n",
    "\n",
    "            time.sleep(0.001)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if cleanup:\n",
    "            cleanup()\n",
    "        grab.stop()\n",
    "        print(\"Stopped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb03cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--list-devices] [--device DEVICE] [-x X]\n",
      "                             [-y Y] [-W W] [-H H] [-r FPS]\n",
      "                             [--pix-fmt {nv12,bgra}] [--return-bgr] [--show]\n",
      "                             [--ffmpeg FFMPEG]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/Users/marcus/Library/Jupyter/runtime/kernel-v3f2b5e4280663f99227882b893a119c4f4175d9f2.json could match --fps, --ffmpeg\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# avfoundation_nv12_capture.py\n",
    "# High-FPS, low-latency screen region capture on macOS using ffmpeg/avfoundation → NV12 rawvideo.\n",
    "# Prints true CAPTURE FPS (producer) and TURNAROUND latency (age when consumed).\n",
    "#\n",
    "# Usage examples:\n",
    "#   python avfoundation_nv12_capture.py --list-devices\n",
    "#   python avfoundation_nv12_capture.py --device \"1:none\" -x 0 -y 0 -W 1010 -H 1812 -r 120\n",
    "#   python avfoundation_nv12_capture.py --device \"Capture screen 0\" -x 0 -y 0 -W 1010 -H 1812 --show\n",
    "#\n",
    "# Notes:\n",
    "# - To find your device string:  ffmpeg -f avfoundation -list_devices true -i \"\"\n",
    "# - Default pixel format is NV12 (1.5 B/px). You can switch to BGRA (4 B/px) with --pix-fmt bgra.\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "import statistics\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cv2  # only needed if --show or --return-bgr\n",
    "except Exception:\n",
    "    cv2 = None\n",
    "\n",
    "\n",
    "class FfmpegGrabber:\n",
    "    \"\"\"\n",
    "    Spawn ffmpeg to capture a screen region and stream frames via stdout as rawvideo.\n",
    "\n",
    "    latest_with_age() -> (ts, frame, age_ms)\n",
    "      - If pix_fmt='nv12' and return_bgr=True: frame is BGR uint8 (H,W,3)\n",
    "      - If pix_fmt='nv12' and return_bgr=False: frame is NV12 buffer (H*3//2, W)\n",
    "      - If pix_fmt='bgra' and return_bgr=True: frame is BGR (drops alpha)\n",
    "      - If pix_fmt='bgra' and return_bgr=False: frame is BGRA (H,W,4)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        left: int,\n",
    "        top: int,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        framerate: int = 120,\n",
    "        pix_fmt: str = \"nv12\",             # 'nv12' (fast) or 'bgra' (simple)\n",
    "        input_device: str = \"1:none\",      # e.g. \"1:none\" or \"Capture screen 0\"\n",
    "        return_bgr: bool = False,          # convert to BGR in Python (cost ~1–2 ms @ ~2MP for NV12)\n",
    "        ring_len: int = 2,\n",
    "        ffmpeg_path: str = \"ffmpeg\",\n",
    "        loglevel: str = \"error\",\n",
    "    ):\n",
    "        self.left, self.top, self.width, self.height = map(int, (left, top, width, height))\n",
    "        self.framerate = int(framerate)\n",
    "        self.pix_fmt = pix_fmt.lower()\n",
    "        assert self.pix_fmt in (\"nv12\", \"bgra\")\n",
    "        self.input_device = input_device\n",
    "        self.return_bgr = return_bgr\n",
    "        self.ffmpeg_path = ffmpeg_path\n",
    "        self.loglevel = loglevel\n",
    "\n",
    "        if self.return_bgr and cv2 is None:\n",
    "            raise RuntimeError(\"--return-bgr or --show requires opencv-python (cv2)\")\n",
    "\n",
    "        # bytes per frame\n",
    "        if self.pix_fmt == \"bgra\":\n",
    "            self.bytes_per_frame = self.width * self.height * 4\n",
    "        else:  # NV12: 1.5 bytes per pixel\n",
    "            self.bytes_per_frame = self.width * self.height * 3 // 2\n",
    "\n",
    "        self._buf = deque(maxlen=ring_len)   # (ts, frame_obj)\n",
    "        self._running = threading.Event()\n",
    "        self._running.set()\n",
    "        self._cap_count = 0\n",
    "        self._t0 = time.perf_counter()\n",
    "\n",
    "        self.proc = self._start_ffmpeg()\n",
    "        self._thr = threading.Thread(target=self._reader, name=\"FfmpegGrabber\", daemon=True)\n",
    "        self._thr.start()\n",
    "\n",
    "    def _start_ffmpeg(self) -> subprocess.Popen:\n",
    "        vf = f\"crop={self.width}:{self.height}:{self.left}:{self.top}\"\n",
    "        cmd = [\n",
    "            self.ffmpeg_path,\n",
    "            \"-hide_banner\",\n",
    "            \"-loglevel\", self.loglevel,\n",
    "            \"-f\", \"avfoundation\",\n",
    "            \"-framerate\", str(self.framerate),\n",
    "            \"-i\", self.input_device,\n",
    "            \"-vf\", vf,\n",
    "            \"-pix_fmt\", self.pix_fmt,\n",
    "            \"-an\", \"-sn\",\n",
    "            \"-f\", \"rawvideo\",\n",
    "            \"-\"\n",
    "        ]\n",
    "        try:\n",
    "            proc = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                bufsize=0  # unbuffered\n",
    "            )\n",
    "        except FileNotFoundError as e:\n",
    "            raise SystemExit(\"ffmpeg executable not found. Install with `brew install ffmpeg`.\") from e\n",
    "        return proc\n",
    "\n",
    "    def _read_exact(self, n: int) -> bytes:\n",
    "        \"\"\"Read exactly n bytes from ffmpeg stdout.\"\"\"\n",
    "        out = bytearray(n)\n",
    "        mv = memoryview(out)\n",
    "        got = 0\n",
    "        stdout = self.proc.stdout\n",
    "        while got < n and self._running.is_set():\n",
    "            chunk = stdout.read(n - got)\n",
    "            if not chunk:\n",
    "                break\n",
    "            mv[got:got+len(chunk)] = chunk\n",
    "            got += len(chunk)\n",
    "        if got != n:\n",
    "            return b\"\"\n",
    "        return bytes(out)\n",
    "\n",
    "    def _reader(self):\n",
    "        stderr_reader = threading.Thread(target=self._drain_stderr, daemon=True)\n",
    "        stderr_reader.start()\n",
    "        while self._running.is_set():\n",
    "            ts = time.perf_counter()\n",
    "            raw = self._read_exact(self.bytes_per_frame)\n",
    "            if not raw:\n",
    "                if self.proc.poll() is not None:\n",
    "                    # process ended\n",
    "                    break\n",
    "                # transient short read; continue\n",
    "                continue\n",
    "\n",
    "            if self.pix_fmt == \"bgra\":\n",
    "                frame_bgra = np.frombuffer(raw, dtype=np.uint8).reshape(self.height, self.width, 4)\n",
    "                if self.return_bgr:\n",
    "                    frame_out = frame_bgra[..., :3]  # drop alpha (view)\n",
    "                else:\n",
    "                    frame_out = frame_bgra\n",
    "            else:\n",
    "                # NV12\n",
    "                yuv = np.frombuffer(raw, dtype=np.uint8).reshape(self.height * 3 // 2, self.width)\n",
    "                if self.return_bgr:\n",
    "                    frame_out = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_NV12)\n",
    "                else:\n",
    "                    frame_out = yuv\n",
    "\n",
    "            self._buf.append((ts, frame_out))\n",
    "            self._cap_count += 1\n",
    "\n",
    "        self._running.clear()\n",
    "\n",
    "    def _drain_stderr(self):\n",
    "        # Helpful for capturing permission or device errors\n",
    "        if not self.proc or not self.proc.stderr:\n",
    "            return\n",
    "        for line in self.proc.stderr:\n",
    "            try:\n",
    "                sys.stderr.write(line.decode(errors=\"ignore\"))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    def latest(self) -> Optional[Tuple[float, np.ndarray]]:\n",
    "        return self._buf[-1] if self._buf else None\n",
    "\n",
    "    def latest_with_age(self) -> Optional[Tuple[float, np.ndarray, float]]:\n",
    "        item = self.latest()\n",
    "        if not item:\n",
    "            return None\n",
    "        ts, frame = item\n",
    "        age_ms = (time.perf_counter() - ts) * 1000.0\n",
    "        return ts, frame, age_ms\n",
    "\n",
    "    def capture_stats(self):\n",
    "        elapsed = max(1e-9, time.perf_counter() - self._t0)\n",
    "        return self._cap_count, elapsed, self._cap_count / elapsed\n",
    "\n",
    "    def stop(self):\n",
    "        self._running.clear()\n",
    "        try:\n",
    "            if self.proc and self.proc.poll() is None:\n",
    "                self.proc.terminate()\n",
    "                try:\n",
    "                    self.proc.wait(timeout=1.0)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    self.proc.kill()\n",
    "        finally:\n",
    "            try:\n",
    "                if self.proc and self.proc.stdout:\n",
    "                    self.proc.stdout.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                if self.proc and self.proc.stderr:\n",
    "                    self.proc.stderr.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "def list_devices(ffmpeg_path: str = \"ffmpeg\"):\n",
    "    print(\"Listing AVFoundation devices...\\n\", flush=True)\n",
    "    try:\n",
    "        # This command always exits non-zero; we just want its stderr\n",
    "        proc = subprocess.Popen(\n",
    "            [ffmpeg_path, \"-f\", \"avfoundation\", \"-list_devices\", \"true\", \"-i\", \"\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "        )\n",
    "        _, err = proc.communicate(timeout=5)\n",
    "        sys.stdout.write(err.decode(errors=\"ignore\"))\n",
    "    except FileNotFoundError:\n",
    "        print(\"ffmpeg not found. Install with `brew install ffmpeg`.\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"ffmpeg list devices timed out.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"AVFoundation NV12 region capture via ffmpeg (macOS).\")\n",
    "    ap.add_argument(\"--list-devices\", action=\"store_true\", help=\"List AVFoundation devices and exit.\")\n",
    "    ap.add_argument(\"--device\", type=str, default=\"1:none\", help='Input device, e.g. \"1:none\" or \"Capture screen 0\".')\n",
    "    ap.add_argument(\"-x\", type=int, default=0, help=\"Left (pixels)\")\n",
    "    ap.add_argument(\"-y\", type=int, default=0, help=\"Top (pixels)\")\n",
    "    ap.add_argument(\"-W\", type=int, default=1010, help=\"Width (pixels)\")\n",
    "    ap.add_argument(\"-H\", type=int, default=1812, help=\"Height (pixels)\")\n",
    "    ap.add_argument(\"-r\", \"--fps\", type=int, default=120, help=\"Target capture frame rate\")\n",
    "    ap.add_argument(\"--pix-fmt\", choices=[\"nv12\", \"bgra\"], default=\"nv12\", help=\"Pixel format to stream.\")\n",
    "    ap.add_argument(\"--return-bgr\", action=\"store_true\", help=\"Convert to BGR in Python (NV12→BGR or drop A).\")\n",
    "    ap.add_argument(\"--show\", action=\"store_true\", help=\"Preview window (implies --return-bgr).\")\n",
    "    ap.add_argument(\"--ffmpeg\", type=str, default=\"ffmpeg\", help=\"Path to ffmpeg binary.\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    if args.list_devices:\n",
    "        list_devices(args.ffmpeg)\n",
    "        return\n",
    "\n",
    "    if args.show:\n",
    "        args.return_bgr = True\n",
    "        if cv2 is None:\n",
    "            raise SystemExit(\"--show requires opencv-python (pip install opencv-python)\")\n",
    "\n",
    "    grab = FfmpegGrabber(\n",
    "        left=args.x, top=args.y, width=args.W, height=args.H,\n",
    "        framerate=args.fps, pix_fmt=args.pix_fmt, input_device=args.device,\n",
    "        return_bgr=args.return_bgr, ring_len=2, ffmpeg_path=args.ffmpeg,\n",
    "    )\n",
    "\n",
    "    print(f\"Capturing via ffmpeg/avfoundation (fmt={args.pix_fmt}, \"\n",
    "          f\"device={args.device})...  Press Ctrl+C to quit.\\n\")\n",
    "\n",
    "    last_seen_ts = None\n",
    "    ages_ms = []\n",
    "    last_tick = time.perf_counter()\n",
    "    last_cap_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            info = grab.latest_with_age()\n",
    "            if info:\n",
    "                ts, frame, age_ms = info\n",
    "                if ts != last_seen_ts:\n",
    "                    last_seen_ts = ts\n",
    "                    ages_ms.append(age_ms)\n",
    "\n",
    "                    if args.show:\n",
    "                        cv2.imshow(\"Preview (BGR)\", frame)\n",
    "                        # ~120 Hz UI cap\n",
    "                        if cv2.waitKey(1) == 27:  # Esc\n",
    "                            break\n",
    "\n",
    "            now = time.perf_counter()\n",
    "            if now - last_tick >= 1.0:\n",
    "                total, _, _ = grab.capture_stats()\n",
    "                cap_fps_inst = (total - last_cap_count) / (now - last_tick)\n",
    "                last_cap_count = total\n",
    "\n",
    "                if ages_ms:\n",
    "                    ages_sorted = sorted(ages_ms)\n",
    "                    med = statistics.median(ages_sorted)\n",
    "                    p95 = ages_sorted[int(0.95 * (len(ages_sorted) - 1))]\n",
    "                    worst = ages_sorted[-1]\n",
    "                else:\n",
    "                    med = p95 = worst = float('nan')\n",
    "\n",
    "                print(f\"[AVF] CAP {cap_fps_inst:6.1f} fps | \"\n",
    "                      f\"TURNAROUND median {med:6.2f} ms  p95 {p95:6.2f} ms  max {worst:6.2f} ms \"\n",
    "                      f\"(region {args.W}x{args.H}, fmt={args.pix_fmt})\")\n",
    "\n",
    "                ages_ms.clear()\n",
    "                last_tick = now\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        grab.stop()\n",
    "        if args.show and cv2 is not None:\n",
    "            try:\n",
    "                cv2.destroyAllWindows()\n",
    "            except Exception:\n",
    "                pass\n",
    "        print(\"Stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01665ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 38.70979161001742 ms  p95: 47.56199987605214 ms\n"
     ]
    }
   ],
   "source": [
    "import time, statistics, mss\n",
    "left, top, width, height = 0, 0, 1010, 1812\n",
    "times = []\n",
    "with mss.mss() as sct:\n",
    "    for _ in range(10): sct.grab({\"left\":left,\"top\":top,\"width\":width,\"height\":height})  # warmup\n",
    "    for _ in range(120):\n",
    "        t0 = time.perf_counter()\n",
    "        _ = sct.grab({\"left\":left,\"top\":top,\"width\":width,\"height\":height})\n",
    "        times.append((time.perf_counter()-t0)*1000)\n",
    "print(\"median:\", statistics.median(times), \"ms  p95:\", sorted(times)[int(0.95*(len(times)-1))], \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ee7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--list-devices] [--device DEVICE] [-x X]\n",
      "                             [-y Y] [-W W] [-H H] [-r FPS]\n",
      "                             [--pix-fmt {bgr0,nv12}] [--return-bgr]\n",
      "ipykernel_launcher.py: error: argument -r/--fps: invalid int value: '/Users/marcus/Library/Jupyter/runtime/kernel-v3f2b5e4280663f99227882b893a119c4f4175d9f2.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# fast_capture_bgr0.py\n",
    "# High-FPS, low-latency screen region capture on macOS using ffmpeg/avfoundation.\n",
    "# Optimized for the screen’s native pixel format (bgr0) to avoid costly color conversions.\n",
    "# Prints true CAPTURE FPS (producer rate) and TURNAROUND (age when consumed) once per second.\n",
    "#\n",
    "# Requires: macOS + ffmpeg (`brew install ffmpeg`)\n",
    "#\n",
    "# Example:\n",
    "#   python fast_capture_bgr0.py --device \"Capture screen 0\" -x 0 -y 0 -W 1010 -H 1812 -r 120\n",
    "#   # If the name form fails, try a numeric form:\n",
    "#   python fast_capture_bgr0.py --device \"1:none\" -x 0 -y 0 -W 1010 -H 1812 -r 120\n",
    "#\n",
    "# Notes:\n",
    "# - We request bgr0 (native for screen capture) to avoid colorspace conversion overhead.\n",
    "# - We disable buffering and pacing: -fflags nobuffer -flags low_delay -vsync 0.\n",
    "# - AVFoundation can’t crop at source; ffmpeg applies -vf crop after capture (still fast enough here).\n",
    "# - If you truly need 3-channel BGR, we drop A in Python via a view (no copy).\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import subprocess\n",
    "import statistics\n",
    "from collections import deque\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def list_avfoundation_devices(ffmpeg_path: str = \"ffmpeg\"):\n",
    "    \"\"\"Print AVFoundation devices (stderr) and return the raw listing text.\"\"\"\n",
    "    try:\n",
    "        p = subprocess.run(\n",
    "            [ffmpeg_path, \"-f\", \"avfoundation\", \"-list_devices\", \"true\", \"-i\", \"\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            check=False,\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        raise SystemExit(\"ffmpeg not found. Install with `brew install ffmpeg`.\")\n",
    "    text = p.stderr.decode(errors=\"ignore\")\n",
    "    # Print a cleaned list\n",
    "    print(\"\\n=== AVFoundation devices ===\")\n",
    "    for line in text.splitlines():\n",
    "        if \"AVFoundation video devices\" in line or \"AVFoundation audio devices\" in line or \"] [\" in line:\n",
    "            print(line)\n",
    "    print(\"============================\\n\")\n",
    "    return text\n",
    "\n",
    "\n",
    "class AVFGrabber:\n",
    "    \"\"\"\n",
    "    AVFoundation screen grabber via ffmpeg, streaming rawvideo frames.\n",
    "\n",
    "    latest_with_age() -> (ts, frame, age_ms)\n",
    "      - If pix_fmt='bgr0' and return_bgr=False: frame is BGR0 (H,W,4) view\n",
    "      - If pix_fmt='bgr0' and return_bgr=True:  frame is BGR  (H,W,3) view (alpha dropped)\n",
    "      - If pix_fmt='nv12' and return_bgr=False: frame is NV12 buffer (H*3//2, W)\n",
    "      - If pix_fmt='nv12' and return_bgr=True:  frame is BGR (converted; needs opencv-python)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        left: int,\n",
    "        top: int,\n",
    "        width: int,\n",
    "        height: int,\n",
    "        framerate: int = 120,\n",
    "        device: str = \"Capture screen 0\",\n",
    "        pix_fmt: str = \"bgr0\",            # 'bgr0' recommended for speed (native); 'nv12' optional\n",
    "        return_bgr: bool = False,         # drop alpha (bgr0→bgr) or convert (nv12→bgr)\n",
    "        ring_len: int = 2,\n",
    "        ffmpeg_path: str = \"ffmpeg\",\n",
    "        loglevel: str = \"error\",\n",
    "    ):\n",
    "        self.left, self.top, self.width, self.height = map(int, (left, top, width, height))\n",
    "        self.fps = int(framerate)\n",
    "        self.device = device\n",
    "        self.pix_fmt = pix_fmt.lower()\n",
    "        assert self.pix_fmt in (\"bgr0\", \"nv12\"), \"pix_fmt must be 'bgr0' or 'nv12'\"\n",
    "        self.return_bgr = return_bgr\n",
    "        self.ffmpeg = ffmpeg_path\n",
    "        self.loglevel = loglevel\n",
    "\n",
    "        if self.pix_fmt == \"bgr0\":\n",
    "            self._bytes_per_frame = self.width * self.height * 4\n",
    "        else:\n",
    "            self._bytes_per_frame = self.width * self.height * 3 // 2  # NV12\n",
    "\n",
    "        if self.pix_fmt == \"nv12\" and self.return_bgr:\n",
    "            try:\n",
    "                import cv2  # noqa: F401\n",
    "            except Exception:\n",
    "                raise SystemExit(\"nv12→bgr conversion requires `pip install opencv-python`.\")\n",
    "\n",
    "        self._buf = deque(maxlen=ring_len)  # (ts, frame)\n",
    "        self._running = threading.Event()\n",
    "        self._running.set()\n",
    "        self._cap_count = 0\n",
    "        self._t0 = time.perf_counter()\n",
    "\n",
    "        self.proc = self._start_ffmpeg()\n",
    "        self._thr = threading.Thread(target=self._reader, name=\"AVFGrabber\", daemon=True)\n",
    "        self._thr.start()\n",
    "\n",
    "        # Drain stderr so ffmpeg can't block\n",
    "        self._stderr_thr = threading.Thread(target=self._drain_stderr, daemon=True)\n",
    "        self._stderr_thr.start()\n",
    "\n",
    "    def _start_ffmpeg(self) -> subprocess.Popen:\n",
    "        vf = f\"crop={self.width}:{self.height}:{self.left}:{self.top}\"\n",
    "        cmd = [\n",
    "            self.ffmpeg,\n",
    "            \"-hide_banner\", \"-loglevel\", self.loglevel,\n",
    "            \"-fflags\", \"nobuffer\",\n",
    "            \"-flags\", \"low_delay\",\n",
    "            \"-f\", \"avfoundation\",\n",
    "            \"-framerate\", str(self.fps),\n",
    "            \"-i\", self.device,\n",
    "            \"-vf\", vf,\n",
    "            \"-pix_fmt\", self.pix_fmt,    # request native bgr0 for screen capture\n",
    "            \"-vsync\", \"0\",               # do not repace/duplicate frames\n",
    "            \"-an\", \"-sn\",\n",
    "            \"-f\", \"rawvideo\", \"-\"\n",
    "        ]\n",
    "        try:\n",
    "            return subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, bufsize=0)\n",
    "        except FileNotFoundError:\n",
    "            raise SystemExit(\"ffmpeg not found. Install with `brew install ffmpeg`.\")\n",
    "\n",
    "    def _read_exact(self, n: int) -> bytes:\n",
    "        out = bytearray(n)\n",
    "        mv = memoryview(out)\n",
    "        got = 0\n",
    "        r = self.proc.stdout\n",
    "        while got < n and self._running.is_set():\n",
    "            chunk = r.read(n - got)\n",
    "            if not chunk:\n",
    "                break\n",
    "            mv[got:got + len(chunk)] = chunk\n",
    "            got += len(chunk)\n",
    "        return bytes(out) if got == n else b\"\"\n",
    "\n",
    "    def _reader(self):\n",
    "        if self.pix_fmt == \"nv12\" and self.return_bgr:\n",
    "            import cv2  # local import only when needed\n",
    "\n",
    "        while self._running.is_set():\n",
    "            ts = time.perf_counter()\n",
    "            raw = self._read_exact(self._bytes_per_frame)\n",
    "            if not raw:\n",
    "                if self.proc.poll() is not None:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            if self.pix_fmt == \"bgr0\":\n",
    "                bgr0 = np.frombuffer(raw, np.uint8).reshape(self.height, self.width, 4)\n",
    "                frame = bgr0[..., :3] if self.return_bgr else bgr0  # drop alpha via view if requested\n",
    "            else:\n",
    "                # NV12 buffer shape (H*3/2, W)\n",
    "                yuv = np.frombuffer(raw, np.uint8).reshape(self.height * 3 // 2, self.width)\n",
    "                if self.return_bgr:\n",
    "                    import cv2\n",
    "                    frame = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_NV12)\n",
    "                else:\n",
    "                    frame = yuv\n",
    "\n",
    "            self._buf.append((ts, frame))\n",
    "            self._cap_count += 1\n",
    "\n",
    "        self._running.clear()\n",
    "\n",
    "    def _drain_stderr(self):\n",
    "        if not self.proc or not self.proc.stderr:\n",
    "            return\n",
    "        for line in self.proc.stderr:\n",
    "            # Uncomment to see ffmpeg messages:\n",
    "            # sys.stderr.write(line.decode(errors=\"ignore\"))\n",
    "            pass\n",
    "\n",
    "    # ---- Public API (matches your previous FastGrabber) ----\n",
    "    def latest(self) -> Optional[Tuple[float, np.ndarray]]:\n",
    "        return self._buf[-1] if self._buf else None\n",
    "\n",
    "    def latest_with_age(self) -> Optional[Tuple[float, np.ndarray, float]]:\n",
    "        item = self.latest()\n",
    "        if not item:\n",
    "            return None\n",
    "        ts, frame = item\n",
    "        age_ms = (time.perf_counter() - ts) * 1000.0\n",
    "        return ts, frame, age_ms\n",
    "\n",
    "    def capture_stats(self):\n",
    "        elapsed = max(1e-9, time.perf_counter() - self._t0)\n",
    "        return self._cap_count, elapsed, self._cap_count / elapsed\n",
    "\n",
    "    def stop(self):\n",
    "        self._running.clear()\n",
    "        try:\n",
    "            if self.proc and self.proc.poll() is None:\n",
    "                self.proc.terminate()\n",
    "                try:\n",
    "                    self.proc.wait(timeout=1.0)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    self.proc.kill()\n",
    "        finally:\n",
    "            for s in (\"stdout\", \"stderr\"):\n",
    "                try:\n",
    "                    getattr(self.proc, s).close()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Fast screen region capture via AVFoundation (bgr0).\")\n",
    "    ap.add_argument(\"--list-devices\", action=\"store_true\", help=\"List AVFoundation devices and exit.\")\n",
    "    ap.add_argument(\"--device\", type=str, default=\"Capture screen 0\",\n",
    "                    help='AVFoundation input (e.g., \"Capture screen 0\" or \"1:none\").')\n",
    "    ap.add_argument(\"-x\", type=int, default=0, help=\"Left\")\n",
    "    ap.add_argument(\"-y\", type=int, default=0, help=\"Top\")\n",
    "    ap.add_argument(\"-W\", type=int, default=1010, help=\"Width\")\n",
    "    ap.add_argument(\"-H\", type=int, default=1812, help=\"Height\")\n",
    "    ap.add_argument(\"-r\", \"--fps\", type=int, default=120, help=\"Requested capture FPS\")\n",
    "    ap.add_argument(\"--pix-fmt\", choices=[\"bgr0\", \"nv12\"], default=\"bgr0\", help=\"Pixel format.\")\n",
    "    ap.add_argument(\"--return-bgr\", action=\"store_true\",\n",
    "                    help=\"Return 3-channel BGR (drops alpha for bgr0, converts for nv12).\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    if args.list_devices:\n",
    "        list_avfoundation_devices()\n",
    "        sys.exit(0)\n",
    "\n",
    "    grab = AVFGrabber(\n",
    "        left=args.x, top=args.y, width=args.W, height=args.H,\n",
    "        framerate=args.fps, device=args.device,\n",
    "        pix_fmt=args.pix_fmt, return_bgr=args.return_bgr,\n",
    "        ring_len=2, ffmpeg_path=\"ffmpeg\", loglevel=\"error\"\n",
    "    )\n",
    "\n",
    "    print(f\"Capturing via AVFoundation (device={args.device}, fmt={args.pix_fmt}) — Ctrl+C to stop\")\n",
    "    last_seen_ts = None\n",
    "    ages_ms = []\n",
    "    last_tick = time.perf_counter()\n",
    "    last_cap_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            info = grab.latest_with_age()\n",
    "            if info:\n",
    "                ts, frame, age_ms = info\n",
    "                if ts != last_seen_ts:\n",
    "                    last_seen_ts = ts\n",
    "                    ages_ms.append(age_ms)\n",
    "\n",
    "            now = time.perf_counter()\n",
    "            if now - last_tick >= 1.0:\n",
    "                total, _, _ = grab.capture_stats()\n",
    "                cap_fps_inst = (total - last_cap_count) / (now - last_tick)\n",
    "                last_cap_count = total\n",
    "\n",
    "                if ages_ms:\n",
    "                    ages_sorted = sorted(ages_ms)\n",
    "                    med = statistics.median(ages_sorted)\n",
    "                    p95 = ages_sorted[int(0.95 * (len(ages_sorted) - 1))]\n",
    "                    worst = ages_sorted[-1]\n",
    "                    ages_ms.clear()\n",
    "                else:\n",
    "                    med = p95 = worst = float('nan')\n",
    "\n",
    "                print(f\"[AVF bgr0] CAP {cap_fps_inst:6.1f} fps | \"\n",
    "                      f\"TURNAROUND median {med:6.2f} ms  p95 {p95:6.2f} ms  max {worst:6.2f} ms \"\n",
    "                      f\"(region {args.W}x{args.H})\")\n",
    "                last_tick = now\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        grab.stop()\n",
    "        print(\"Stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d77d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
