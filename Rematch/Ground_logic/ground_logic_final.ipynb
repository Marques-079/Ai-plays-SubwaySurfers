{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5fa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Live inference testing -> No overlays, no saves -> Live state tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Live capture + ultra-fast single-image pipeline (no batching)\n",
    "# ESC to stop. Captures a cropped region, processes each frame immediately, prints per-frame timings.\n",
    "\n",
    "import os, time, math, subprocess\n",
    "import cv2, numpy as np\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "# Lane state\n",
    "lane = 1\n",
    "MIN_LANE = 0\n",
    "MAX_LANE = 2\n",
    "running = True\n",
    "\n",
    "def on_press(key):\n",
    "    \"\"\"Single handler: arrow keys change lanes; ESC stops.\"\"\"\n",
    "    global lane, running\n",
    "    try:\n",
    "        if key == keyboard.Key.left:\n",
    "            lane = max(MIN_LANE, lane - 1)\n",
    "            print(f\"Moved Left → Lane {lane}\")\n",
    "        elif key == keyboard.Key.right:\n",
    "            lane = min(MAX_LANE, lane + 1)\n",
    "            print(f\"Moved Right → Lane {lane}\")\n",
    "        elif key == keyboard.Key.esc:\n",
    "            print(\"ESC pressed — exiting\")\n",
    "            running = False\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# =======================\n",
    "# Capture / UI bootstrap\n",
    "# =======================\n",
    "# Start the keyboard listener once\n",
    "listener = keyboard.Listener(on_press=on_press)\n",
    "listener.start()\n",
    "\n",
    "# Parsec to front (macOS)\n",
    "try:\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell application \"Parsec\" to activate'], check=False)\n",
    "    time.sleep(0.4)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Choose crop + click based on ad layout\n",
    "advertisement = True\n",
    "if advertisement:\n",
    "    snap_coords = (644, 77, (1149-644), (981-75))  # (left, top, width, height)\n",
    "    start_click = (1030, 900)\n",
    "else:\n",
    "    snap_coords = (483, 75, (988-483), (981-75))\n",
    "    start_click = (870, 895)\n",
    "\n",
    "# Click \"Start\"\n",
    "try:\n",
    "    pyautogui.click(start_click)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Initialize capture\n",
    "sct = mss()\n",
    "\n",
    "# =======================\n",
    "# Model / Pipeline config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter for \"green rails\"\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle params\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "\n",
    "# Sampling ray\n",
    "SAMPLE_UP_PX        = 180\n",
    "RAY_STEP_PX         = 20  # probe step\n",
    "\n",
    "# Jake lane points + bearing targets\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)  # index by lane (0/1/2)\n",
    "\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "# Bend degrees\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0  # N1\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0  # N2\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0  # N3\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0  # N4\n",
    "\n",
    "# =======================\n",
    "# System / backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try:\n",
    "    cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (singleton, warmed)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed tables\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r, g, b)[::-1] for (r, g, b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "MORPH_OPEN_SE   = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "# =======================\n",
    "# Pipeline helpers\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "    comp = combined.astype(np.uint8)\n",
    "\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "    dark = cv2.morphologyEx(dark, cv2.MORPH_OPEN, MORPH_OPEN_SE, iterations=1)\n",
    "\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # must be above Jake\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) unit ray (up = -y)\n",
    "    return table\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours = []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_colour = None\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = 3; break\n",
    "            if hit_colour is not None: break\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = 2; break\n",
    "            if hit_colour is not None: break\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5:\n",
    "                    hit_colour = 1; break\n",
    "            if hit_colour is not None: break\n",
    "\n",
    "        if hit_colour == 3: colours.append((0,0,255))\n",
    "        elif hit_colour == 2: colours.append((0,255,255))\n",
    "        elif hit_colour == 1: colours.append((203,192,255))\n",
    "        else: colours.append((0,255,0))\n",
    "    return colours\n",
    "\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return 0, 0, 0.0, 0.0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, _ = purple_triangles(score, H)\n",
    "\n",
    "    # choose Jake triangle and set x_ref\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, _, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "    x_ref = tri_positions[best_idx][0] if (lane_name == \"mid\" and 0 <= best_idx < len(tri_positions)) else xj\n",
    "\n",
    "    # run probe classification (not used further here, but triggers same work)\n",
    "    _ = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    return len(tri_positions), mask_count, to_cpu_ms, post_ms\n",
    "\n",
    "def process_image_bgr(img_bgr, name, jake_point):\n",
    "    \"\"\"Process one BGR frame already in memory and print timing line.\"\"\"\n",
    "    if img_bgr is None:\n",
    "        return\n",
    "    predict = model.predict  # local binding\n",
    "\n",
    "    # In live mode there's no disk read; keep field for consistency\n",
    "    read_ms = 0.0\n",
    "\n",
    "    t0_inf = time.perf_counter()\n",
    "    yres_list = predict(\n",
    "        [img_bgr], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "    )\n",
    "    infer_ms = (time.perf_counter() - t0_inf) * 1000.0\n",
    "\n",
    "    yres = yres_list[0]\n",
    "    tri_count, mask_count, to_cpu_ms, post_ms = process_frame_post(img_bgr, yres, jake_point)\n",
    "    proc_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "    print(f\"[live] {name}  \"\n",
    "          f\"read {read_ms:.1f} | infer {infer_ms:.1f} | \"\n",
    "          f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "          f\"masks {mask_count} | triangles {tri_count} \"\n",
    "          f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "# =======================\n",
    "# Live loop\n",
    "# =======================\n",
    "\n",
    "# Output folder for saved frames\n",
    "out_dir = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"live_run\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "prev_ts = time.time()\n",
    "frame_idx = 0\n",
    "\n",
    "while running:\n",
    "    # Grab screen region\n",
    "    left, top, width, height = snap_coords\n",
    "    raw = sct.grab({\"left\": left, \"top\": top, \"width\": width, \"height\": height})\n",
    "    frame_bgr = np.array(raw)[:, :, :3]  # BGRA -> BGR\n",
    "\n",
    "    # Determine JAKE_POINT for this frame from current lane (0/1/2)\n",
    "    jake_point = LANE_POINTS[lane]\n",
    "\n",
    "    # Process immediately (no batching, no saving)\n",
    "    frame_idx += 1\n",
    "    process_image_bgr(frame_bgr, name=f\"frame_{frame_idx:05d}\", jake_point=jake_point)\n",
    "\n",
    "    # Save a copy with JAKE_POINT text at top-left (does not affect inference)\n",
    "    annotated = frame_bgr.copy()\n",
    "    jp_name = lane_name_from_point(jake_point).upper()\n",
    "    cv2.putText(annotated, f\"JAKE_POINT: {jp_name}\",\n",
    "                (10, 24), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    out_path = out_dir / f\"live_{frame_idx:05d}.jpg\"\n",
    "    cv2.imwrite(str(out_path), annotated)\n",
    "\n",
    "    # (Optional) inter-frame delta print — comment out if noisy\n",
    "    now = time.time()\n",
    "    # print(f\"Δ between frames: {now - prev_ts:.3f}s\")\n",
    "    prev_ts = now\n",
    "\n",
    "# Cleanup\n",
    "listener.join()\n",
    "print(\"Script halted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27ea1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overlay saves and movement logic implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc034d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[live 00001] infer 700.4 | to_cpu 1.3 | post 169.2 | masks 1 | triangles 1 => proc 870.9 ms\n",
      "[live 00002] infer 184.1 | to_cpu 197.3 | post 139.2 | masks 5 | triangles 1 => proc 520.6 ms\n",
      "[live 00003] infer 149.7 | to_cpu 1.0 | post 146.2 | masks 6 | triangles 1 => proc 297.0 ms\n",
      "[live 00004] infer 84.5 | to_cpu 1.1 | post 144.9 | masks 5 | triangles 1 => proc 230.5 ms\n",
      "Moved Right → Lane 2\n",
      "[live 00005] infer 143.6 | to_cpu 0.8 | post 157.1 | masks 4 | triangles 3 => proc 301.6 ms\n",
      "[live 00006] infer 78.1 | to_cpu 1.0 | post 148.7 | masks 5 | triangles 2 => proc 227.9 ms\n",
      "[live 00007] infer 75.2 | to_cpu 1.0 | post 148.8 | masks 4 | triangles 2 => proc 225.0 ms\n",
      "[live 00008] infer 43.7 | to_cpu 1.0 | post 144.2 | masks 4 | triangles 2 => proc 188.9 ms\n",
      "[live 00009] infer 183.2 | to_cpu 0.9 | post 145.8 | masks 3 | triangles 2 => proc 329.9 ms\n",
      "[live 00010] infer 43.5 | to_cpu 0.9 | post 114.1 | masks 4 | triangles 1 => proc 158.5 ms\n",
      "[live 00011] infer 42.9 | to_cpu 1.7 | post 108.8 | masks 4 | triangles 1 => proc 153.4 ms\n",
      "[live 00012] infer 78.7 | to_cpu 0.9 | post 101.1 | masks 4 | triangles 1 => proc 180.7 ms\n",
      "[live 00013] infer 78.8 | to_cpu 1.0 | post 93.6 | masks 5 | triangles 1 => proc 173.4 ms\n",
      "[live 00014] infer 74.9 | to_cpu 0.8 | post 57.2 | masks 3 | triangles 1 => proc 132.9 ms\n",
      "[live 00015] infer 78.5 | to_cpu 1.0 | post 28.8 | masks 5 | triangles 0 => proc 108.3 ms\n",
      "[live 00016] infer 79.8 | to_cpu 1.1 | post 57.0 | masks 6 | triangles 1 => proc 137.9 ms\n",
      "[live 00017] infer 42.7 | to_cpu 1.0 | post 54.9 | masks 5 | triangles 1 => proc 98.6 ms\n",
      "[live 00018] infer 41.9 | to_cpu 1.1 | post 133.3 | masks 6 | triangles 1 => proc 176.3 ms\n",
      "[live 00019] infer 80.9 | to_cpu 1.0 | post 114.8 | masks 4 | triangles 2 => proc 196.7 ms\n",
      "[live 00020] infer 42.2 | to_cpu 0.8 | post 150.9 | masks 3 | triangles 2 => proc 194.0 ms\n",
      "[live 00021] infer 82.3 | to_cpu 0.8 | post 114.5 | masks 3 | triangles 1 => proc 197.5 ms\n",
      "[live 00022] infer 78.3 | to_cpu 0.9 | post 111.6 | masks 4 | triangles 1 => proc 190.8 ms\n",
      "[live 00023] infer 42.8 | to_cpu 0.9 | post 145.6 | masks 4 | triangles 2 => proc 189.4 ms\n",
      "[live 00024] infer 81.0 | to_cpu 1.1 | post 124.1 | masks 6 | triangles 1 => proc 206.2 ms\n",
      "[live 00025] infer 43.0 | to_cpu 0.9 | post 152.1 | masks 3 | triangles 2 => proc 196.1 ms\n",
      "[live 00026] infer 50.2 | to_cpu 1.6 | post 153.3 | masks 4 | triangles 1 => proc 205.2 ms\n",
      "Moved Left → Lane 1\n",
      "[live 00027] infer 76.7 | to_cpu 1.0 | post 124.9 | masks 5 | triangles 1 => proc 202.6 ms\n",
      "[live 00028] infer 43.8 | to_cpu 1.0 | post 149.7 | masks 4 | triangles 2 => proc 194.5 ms\n",
      "[live 00029] infer 78.8 | to_cpu 1.0 | post 132.9 | masks 5 | triangles 2 => proc 212.7 ms\n",
      "[live 00030] infer 48.1 | to_cpu 1.1 | post 107.3 | masks 5 | triangles 1 => proc 156.5 ms\n",
      "[live 00031] infer 42.7 | to_cpu 1.0 | post 71.5 | masks 4 | triangles 1 => proc 115.2 ms\n",
      "[live 00032] infer 88.3 | to_cpu 1.0 | post 50.5 | masks 6 | triangles 1 => proc 139.9 ms\n",
      "[live 00033] infer 165.2 | to_cpu 1.2 | post 144.2 | masks 7 | triangles 1 => proc 310.7 ms\n",
      "Moved Left → Lane 0\n",
      "[live 00034] infer 45.5 | to_cpu 1.0 | post 148.4 | masks 5 | triangles 2 => proc 195.0 ms\n",
      "[live 00035] infer 47.0 | to_cpu 1.0 | post 144.0 | masks 3 | triangles 2 => proc 191.9 ms\n",
      "[live 00036] infer 43.4 | to_cpu 0.9 | post 144.9 | masks 3 | triangles 2 => proc 189.2 ms\n",
      "[live 00037] infer 83.9 | to_cpu 0.9 | post 119.5 | masks 4 | triangles 2 => proc 204.3 ms\n",
      "[live 00038] infer 47.9 | to_cpu 1.0 | post 98.3 | masks 4 | triangles 1 => proc 147.2 ms\n",
      "[live 00039] infer 47.4 | to_cpu 0.9 | post 59.6 | masks 3 | triangles 1 => proc 108.0 ms\n",
      "[live 00040] infer 51.4 | to_cpu 2.1 | post 58.7 | masks 4 | triangles 2 => proc 112.3 ms\n",
      "[live 00041] infer 160.9 | to_cpu 1.0 | post 156.6 | masks 2 | triangles 2 => proc 318.5 ms\n",
      "[live 00042] infer 84.9 | to_cpu 0.9 | post 159.7 | masks 3 | triangles 2 => proc 245.4 ms\n",
      "[live 00043] infer 48.7 | to_cpu 0.8 | post 147.0 | masks 3 | triangles 2 => proc 196.5 ms\n",
      "[live 00044] infer 76.0 | to_cpu 0.7 | post 158.7 | masks 3 | triangles 2 => proc 235.5 ms\n",
      "[live 00045] infer 83.9 | to_cpu 0.8 | post 139.5 | masks 3 | triangles 2 => proc 224.3 ms\n",
      "[live 00046] infer 90.5 | to_cpu 0.6 | post 77.2 | masks 1 | triangles 1 => proc 168.4 ms\n",
      "[live 00047] infer 82.9 | to_cpu 0.8 | post 0.0 | masks 1 | triangles 0 => proc 83.8 ms\n",
      "[live 00048] infer 50.5 | to_cpu 0.8 | post 0.0 | masks 1 | triangles 0 => proc 51.3 ms\n",
      "[live 00049] infer 33.8 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.8 ms\n",
      "[live 00050] infer 38.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 38.6 ms\n",
      "[live 00051] infer 34.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.2 ms\n",
      "[live 00052] infer 34.9 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.9 ms\n",
      "[live 00053] infer 33.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.5 ms\n",
      "[live 00054] infer 34.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.1 ms\n",
      "[live 00055] infer 32.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 32.7 ms\n",
      "[live 00056] infer 35.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 35.7 ms\n",
      "[live 00057] infer 34.3 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.3 ms\n",
      "[live 00058] infer 85.6 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 86.3 ms\n",
      "[live 00059] infer 44.6 | to_cpu 1.8 | post 0.0 | masks 1 | triangles 0 => proc 46.4 ms\n",
      "[live 00060] infer 33.8 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.8 ms\n",
      "[live 00061] infer 37.0 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 37.0 ms\n",
      "[live 00062] infer 35.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 35.6 ms\n",
      "[live 00063] infer 44.5 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 45.2 ms\n",
      "[live 00064] infer 44.0 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 44.7 ms\n",
      "[live 00065] infer 35.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 35.7 ms\n",
      "[live 00066] infer 32.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 32.2 ms\n",
      "[live 00067] infer 35.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 35.6 ms\n",
      "[live 00068] infer 44.5 | to_cpu 0.8 | post 0.0 | masks 1 | triangles 0 => proc 45.3 ms\n",
      "[live 00069] infer 42.7 | to_cpu 0.6 | post 0.0 | masks 1 | triangles 0 => proc 43.4 ms\n",
      "[live 00070] infer 33.9 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.9 ms\n",
      "[live 00071] infer 33.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.5 ms\n",
      "[live 00072] infer 34.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.7 ms\n",
      "[live 00073] infer 43.0 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 43.7 ms\n",
      "[live 00074] infer 44.8 | to_cpu 0.6 | post 0.0 | masks 1 | triangles 0 => proc 45.4 ms\n",
      "[live 00075] infer 44.3 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 44.9 ms\n",
      "[live 00076] infer 44.4 | to_cpu 0.8 | post 0.0 | masks 1 | triangles 0 => proc 45.2 ms\n",
      "[live 00077] infer 33.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.2 ms\n",
      "[live 00078] infer 34.0 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.0 ms\n",
      "[live 00079] infer 31.9 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 31.9 ms\n",
      "[live 00080] infer 43.6 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 44.2 ms\n",
      "[live 00081] infer 42.9 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 43.6 ms\n",
      "[live 00082] infer 43.2 | to_cpu 0.6 | post 0.0 | masks 1 | triangles 0 => proc 43.9 ms\n",
      "[live 00083] infer 44.1 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 44.7 ms\n",
      "[live 00084] infer 44.2 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 44.9 ms\n",
      "[live 00085] infer 49.3 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 50.0 ms\n",
      "[live 00086] infer 93.2 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 93.9 ms\n",
      "[live 00087] infer 45.1 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 45.8 ms\n",
      "[live 00088] infer 32.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 32.1 ms\n",
      "[live 00089] infer 32.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 32.2 ms\n",
      "[live 00090] infer 33.8 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.8 ms\n",
      "[live 00091] infer 45.9 | to_cpu 1.1 | post 0.0 | masks 1 | triangles 0 => proc 47.0 ms\n",
      "[live 00092] infer 46.7 | to_cpu 0.6 | post 0.0 | masks 1 | triangles 0 => proc 47.3 ms\n",
      "[live 00093] infer 46.6 | to_cpu 0.8 | post 0.0 | masks 1 | triangles 0 => proc 47.3 ms\n",
      "[live 00094] infer 46.3 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 47.0 ms\n",
      "[live 00095] infer 34.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.7 ms\n",
      "[live 00096] infer 34.3 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 34.3 ms\n",
      "[live 00097] infer 33.3 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.3 ms\n",
      "[live 00098] infer 44.6 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 45.3 ms\n",
      "[live 00099] infer 46.0 | to_cpu 0.7 | post 0.0 | masks 1 | triangles 0 => proc 46.7 ms\n",
      "[live 00100] infer 33.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.2 ms\n",
      "[live 00101] infer 33.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 33.6 ms\n",
      "[live 00102] infer 36.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 36.6 ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 531\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    530\u001b[39m t0_inf = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m res_list = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe_bgr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msegment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIOU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_DET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    534\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m infer_ms = (time.perf_counter() - t0_inf) * \u001b[32m1000.0\u001b[39m\n\u001b[32m    536\u001b[39m yres = res_list[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/engine/model.py:555\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/engine/predictor.py:227\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/engine/predictor.py:326\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     im = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/engine/predictor.py:162\u001b[39m, in \u001b[36mBasePredictor.preprocess\u001b[39m\u001b[34m(self, im)\u001b[39m\n\u001b[32m    160\u001b[39m not_tensor = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(im, torch.Tensor)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_tensor:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     im = np.stack(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m im.shape[-\u001b[32m1\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    164\u001b[39m         im = im[..., ::-\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# BGR to RGB\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/engine/predictor.py:202\u001b[39m, in \u001b[36mBasePredictor.pre_transform\u001b[39m\u001b[34m(self, im)\u001b[39m\n\u001b[32m    194\u001b[39m same_shapes = \u001b[38;5;28mlen\u001b[39m({x.shape \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m im}) == \u001b[32m1\u001b[39m\n\u001b[32m    195\u001b[39m letterbox = LetterBox(\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgsz,\n\u001b[32m    197\u001b[39m     auto=same_shapes\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m     stride=\u001b[38;5;28mself\u001b[39m.model.stride,\n\u001b[32m    201\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mletterbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m im]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Ai-plays-SubwaySurfers/.venv/lib/python3.13/site-packages/ultralytics/data/augment.py:1708\u001b[39m, in \u001b[36mLetterBox.__call__\u001b[39m\u001b[34m(self, labels, image)\u001b[39m\n\u001b[32m   1705\u001b[39m     dh /= \u001b[32m2\u001b[39m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shape[::-\u001b[32m1\u001b[39m] != new_unpad:  \u001b[38;5;66;03m# resize\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1708\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_unpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mINTER_LINEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1709\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1710\u001b[39m         img = img[..., \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Live overlays + lane-aware curved sampling (optimized postproc)\n",
    "# • Parsec focus + auto click\n",
    "# • mss live capture of a crop region\n",
    "# • Arrow keys switch lane (0/1/2) -> JAKE_POINT updates per frame\n",
    "# • Full overlay rendering + per-frame save\n",
    "# • Prints compact timing per frame\n",
    "\n",
    "import os, time, math, subprocess, glob\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from mss import mss\n",
    "import pyautogui\n",
    "from pynput import keyboard\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "\n",
    "# SAVE HERE\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_live_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Crop + click (set by ad layout)\n",
    "advertisement = True\n",
    "if advertisement:\n",
    "    snap_coords = (644, 77, (1149-644), (981-75))  # (left, top, width, height)\n",
    "    start_click = (1030, 900)\n",
    "else:\n",
    "    snap_coords = (483, 75, (988-483), (981-75))\n",
    "    start_click = (870, 895)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Sampling ray length\n",
    "SAMPLE_UP_PX        = 180\n",
    "RAY_STEP_PX         = 20   # walk the ray every 20 px\n",
    "\n",
    "# ===== Bend degrees (tune here) =====\n",
    "BEND_LEFT_STATE_RIGHT_DEG  = -20.0  # N1\n",
    "BEND_MID_STATE_RIGHT_DEG   = -20.0  # N2\n",
    "BEND_MID_STATE_LEFT_DEG    = +20.0  # N3\n",
    "BEND_RIGHT_STATE_LEFT_DEG  = +20.0  # N4\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "COLOR_CYAN   = (255, 255, 0)\n",
    "COLOR_BLACK  = (0, 0, 0)\n",
    "\n",
    "# =======================\n",
    "# Jake lane points + dynamic JAKE_POINT\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "LANE_POINTS = (LANE_LEFT, LANE_MID, LANE_RIGHT)  # index by lane (0,1,2)\n",
    "JAKE_POINT  = LANE_MID  # will be overwritten each frame from 'lane'\n",
    "\n",
    "LANE_TARGET_DEG = {\"left\": -10.7, \"mid\": +1.5, \"right\": +15.0}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    return \"mid\"\n",
    "\n",
    "# =======================\n",
    "# Lane/keyboard state\n",
    "# =======================\n",
    "lane = 1\n",
    "MIN_LANE = 0\n",
    "MAX_LANE = 2\n",
    "running = True\n",
    "\n",
    "def on_press(key):\n",
    "    global lane, running\n",
    "    try:\n",
    "        if key == keyboard.Key.left:\n",
    "            lane = max(MIN_LANE, lane - 1)\n",
    "            print(f\"Moved Left → Lane {lane}\")\n",
    "        elif key == keyboard.Key.right:\n",
    "            lane = min(MAX_LANE, lane + 1)\n",
    "            print(f\"Moved Right → Lane {lane}\")\n",
    "        elif key == keyboard.Key.esc:\n",
    "            print(\"ESC pressed — exiting\")\n",
    "            running = False\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# Class buckets for probe classification\n",
    "DANGER_RED   = {1, 6, 7, 11}\n",
    "WARN_YELLOW  = {2, 3, 4, 5, 8}\n",
    "BOOTS_PINK   = {0}\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# ====== tiny helpers ======\n",
    "def _clampi(v, lo, hi):\n",
    "    return lo if v < lo else (hi if v > hi else v)\n",
    "\n",
    "# =======================\n",
    "# Parsec to front + click Start (non-blocking failures)\n",
    "# =======================\n",
    "try:\n",
    "    subprocess.run([\"osascript\", \"-e\", 'tell application \"Parsec\" to activate'], check=False)\n",
    "    time.sleep(0.4)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pyautogui.click(start_click)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Fast rails green finder\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = rail_mask.shape\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    rail_u8 = rail_mask.view(dtype=np.uint8) * 255\n",
    "    x, y, w, h = cv2.boundingRect(rail_u8)\n",
    "    img_roi  = img_bgr[y:y+h, x:x+w]\n",
    "    mask_roi = rail_u8[y:y+h, x:x+w]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = (diff * diff).sum(-1)\n",
    "    colour_hit = (dist2 <= TOL2).any(-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi.astype(bool))\n",
    "\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1: return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs    = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep  = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep: good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y:y+h, x:x+w] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8, copy=False)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8, copy=False)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)), iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0: return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1: return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((x_mid, int(y_top)))\n",
    "\n",
    "    if not tris: return [], None\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    if dx == 0 and dy == 0: return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # must be above Jake\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(xt - jx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# ===== Lane-aware curved sampling (precompute sin/cos) =====\n",
    "def _precompute_trig():\n",
    "    angles = sorted(set([0.0,\n",
    "        BEND_LEFT_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_RIGHT_DEG,\n",
    "        BEND_MID_STATE_LEFT_DEG,\n",
    "        BEND_RIGHT_STATE_LEFT_DEG\n",
    "    ]))\n",
    "    table = {}\n",
    "    for a in angles:\n",
    "        r = math.radians(a)\n",
    "        table[a] = (math.sin(r), -math.cos(r))  # (dx, dy) for unit ray (up = -y)\n",
    "    return table\n",
    "TRIG_TABLE = _precompute_trig()\n",
    "\n",
    "def pick_bend_angle(jake_point, xt, x_ref, idx, best_idx):\n",
    "    if idx == best_idx:\n",
    "        return 0.0\n",
    "    if jake_point == LANE_LEFT:\n",
    "        return BEND_LEFT_STATE_RIGHT_DEG if xt > x_ref else 0.0\n",
    "    if jake_point == LANE_RIGHT:\n",
    "        return BEND_RIGHT_STATE_LEFT_DEG if xt < x_ref else 0.0\n",
    "    if xt > x_ref: return BEND_MID_STATE_RIGHT_DEG\n",
    "    if xt < x_ref: return BEND_MID_STATE_LEFT_DEG\n",
    "    return 0.0\n",
    "\n",
    "# --------- walk-the-ray classifier (first-hit wins) ----------\n",
    "def classify_triangles_at_sample_curved(\n",
    "    tri_positions, masks_np, classes_np, H, W,\n",
    "    jake_point, x_ref, best_idx, sample_px=SAMPLE_UP_PX, step_px=RAY_STEP_PX\n",
    "):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return [], []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1))\n",
    "    sy = (mh - 1) / max(1, (H - 1))\n",
    "\n",
    "    red_idx    = [i for i, c in enumerate(classes_np) if int(c) in DANGER_RED]\n",
    "    yellow_idx = [i for i, c in enumerate(classes_np) if int(c) in WARN_YELLOW]\n",
    "    boots_idx  = [i for i, c in enumerate(classes_np) if int(c) in BOOTS_PINK]\n",
    "\n",
    "    colours, rays = [], []\n",
    "    max_k = max(1, sample_px // max(1, step_px))\n",
    "\n",
    "    for idx, (x0, y0) in enumerate(tri_positions):\n",
    "        theta = pick_bend_angle(jake_point, x0, x_ref, idx, best_idx)\n",
    "        dx1, dy1 = TRIG_TABLE[theta]\n",
    "\n",
    "        hit_colour = COLOR_GREEN\n",
    "        found = False\n",
    "        for k in range(1, max_k + 1):\n",
    "            t  = k * step_px\n",
    "            xs = _clampi(int(round(x0 + dx1 * t)), 0, W-1)\n",
    "            ys = _clampi(int(round(y0 + dy1 * t)), 0, H-1)\n",
    "            mx = _clampi(int(round(xs * sx)), 0, mw-1)\n",
    "            my = _clampi(int(round(ys * sy)), 0, mh-1)\n",
    "\n",
    "            for i in red_idx:\n",
    "                if masks_np[i][my, mx] > 0.5: hit_colour = COLOR_RED; found = True; break\n",
    "            if found: break\n",
    "            for i in yellow_idx:\n",
    "                if masks_np[i][my, mx] > 0.5: hit_colour = COLOR_YELLOW; found = True; break\n",
    "            if found: break\n",
    "            for i in boots_idx:\n",
    "                if masks_np[i][my, mx] > 0.5: hit_colour = COLOR_PINK; found = True; break\n",
    "            if found: break\n",
    "\n",
    "        x1 = _clampi(int(round(x0 + dx1 * sample_px)), 0, W-1)\n",
    "        y1 = _clampi(int(round(y0 + dy1 * sample_px)), 0, H-1)\n",
    "\n",
    "        colours.append(hit_colour)\n",
    "        rays.append(((int(x0), int(y0)), (x1, y1), float(theta)))\n",
    "\n",
    "    return colours, rays\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# =======================\n",
    "# Frame post-processing\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res, jake_point):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], [], [], None, None, None\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.detach().cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.detach().cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    to_cpu_ms = (time.perf_counter() - t0) * 1000.0\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], [], [], None, None, None\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], [], [], None, None, None\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool, copy=False)\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8, copy=False)\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool, copy=False)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # Jake triangle by bearing\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    xj, yj = jake_point\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # x_ref for bending\n",
    "    if lane_name == \"mid\" and (best_idx is not None) and (0 <= best_idx < len(tri_positions)):\n",
    "        x_ref = tri_positions[best_idx][0]\n",
    "    else:\n",
    "        x_ref = xj\n",
    "\n",
    "    tri_colours, tri_rays = classify_triangles_at_sample_curved(\n",
    "        tri_positions, masks_np, classes_np, H, W, jake_point, x_ref, best_idx,\n",
    "        SAMPLE_UP_PX, RAY_STEP_PX\n",
    "    )\n",
    "    post_ms = (time.perf_counter() - t1) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours, tri_rays, best_idx, best_deg, x_ref\n",
    "\n",
    "# =======================\n",
    "# Viz helpers\n",
    "# =======================\n",
    "def _colour_for_point(x, y, masks_np, classes_np, H, W):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0: return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (W - 1)); sy = (mh - 1) / max(1, (H - 1))\n",
    "    mx = _clampi(int(round(x * sx)), 0, mw-1)\n",
    "    my = _clampi(int(round(y * sy)), 0, mh-1)\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5: cls_here = int(c); break\n",
    "    if cls_here in DANGER_RED:   return COLOR_RED\n",
    "    if cls_here in WARN_YELLOW:  return COLOR_YELLOW\n",
    "    if cls_here in BOOTS_PINK:   return COLOR_PINK\n",
    "    return COLOR_GREEN\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, COLOR_BLACK, 1, cv2.LINE_AA)\n",
    "\n",
    "def triangle_pts(x, y, size=TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    return np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask,\n",
    "                    tri_positions, tri_colours, tri_rays, best_idx, best_deg, x_ref, jake_point):\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # tiny scout lines (viz only)\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                out[yy, x] = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "\n",
    "    # starburst to Jake\n",
    "    xj, yj = jake_point\n",
    "    for idx, (xt, yt) in enumerate(tri_positions):\n",
    "        xt = _clampi(int(xt), 0, W-1); yt = _clampi(int(yt), 0, H-1)\n",
    "        deg_signed = signed_degrees_from_vertical(xt - xj, yt - yj)\n",
    "        cv2.line(out, (xj, yj), (xt, yt),\n",
    "                 COLOR_CYAN if idx == best_idx else COLOR_WHITE, 2, cv2.LINE_AA)\n",
    "        mx = (xj + xt) // 2; my = (yj + yt) // 2\n",
    "        txt = f\"{deg_signed:.1f}°\"\n",
    "        cv2.putText(out, txt, (mx, my), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, txt, (mx, my), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # curved sampling rays (viz)\n",
    "    for (p0, p1, theta) in tri_rays:\n",
    "        cv2.line(out, p0, p1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        mx = (p0[0] + p1[0]) // 2; my = (p0[1] + p1[1]) // 2\n",
    "        ttxt = f\"{theta:+.1f}°\"\n",
    "        cv2.putText(out, ttxt, (mx, my), cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, ttxt, (mx, my), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, int(x), int(y), colour=col)\n",
    "\n",
    "    lane_name = lane_name_from_point(jake_point)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "    if best_idx is not None and 0 <= best_idx < len(tri_positions):\n",
    "        xt, yt = tri_positions[best_idx]\n",
    "        pts = triangle_pts(int(xt), int(yt), size=TRI_SIZE_PX)\n",
    "        cv2.polylines(out, [pts.reshape(-1,1,2)], True, COLOR_CYAN, 3, cv2.LINE_AA)\n",
    "        tag = f\"JAKE_TRI ({lane_name}: target {target_deg:.1f}°)\"\n",
    "        cv2.putText(out, tag, (max(5, int(xt)-70), max(20, int(yt)-16)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, tag, (max(5, int(xt)-70), max(20, int(yt)-16)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # top-left JAKE_POINT state\n",
    "    cv2.putText(out, f\"JAKE_POINT: {lane_name.upper()}\",\n",
    "                (10, 24), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Live loop\n",
    "# =======================\n",
    "listener = keyboard.Listener(on_press=on_press)\n",
    "listener.start()\n",
    "\n",
    "sct = mss()\n",
    "frame_idx = 0\n",
    "\n",
    "while running:\n",
    "    # Screen grab\n",
    "    left, top, width, height = snap_coords\n",
    "    raw = sct.grab({\"left\": left, \"top\": top, \"width\": width, \"height\": height})\n",
    "    frame_bgr = np.array(raw)[:, :, :3]  # BGRA -> BGR\n",
    "\n",
    "    # Dynamic JAKE_POINT from current lane (O(1))\n",
    "    JAKE_POINT = LANE_POINTS[lane]\n",
    "\n",
    "    # Inference\n",
    "    t0_inf = time.perf_counter()\n",
    "    res_list = model.predict(\n",
    "        [frame_bgr], task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET, batch=1\n",
    "    )\n",
    "    infer_ms = (time.perf_counter() - t0_inf) * 1000.0\n",
    "    yres = res_list[0]\n",
    "\n",
    "    # Postproc\n",
    "    (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "     masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours,\n",
    "     tri_rays, best_idx, best_deg, x_ref) = process_frame_post(frame_bgr, yres, JAKE_POINT)\n",
    "\n",
    "    proc_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "    # Render + save\n",
    "    overlay = render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask,\n",
    "                              tri_positions, tri_colours, tri_rays, best_idx, best_deg, x_ref, JAKE_POINT)\n",
    "    frame_idx += 1\n",
    "    out_path = out_dir / f\"live_overlay_{frame_idx:05d}.jpg\"\n",
    "    cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "    # Print compact timing\n",
    "    print(f\"[live {frame_idx:05d}] \"\n",
    "          f\"infer {infer_ms:.1f} | to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "          f\"masks {mask_count} | triangles {tri_count} => proc {proc_ms:.1f} ms\")\n",
    "\n",
    "# Cleanup\n",
    "listener.join()\n",
    "print(\"Script halted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d570a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
