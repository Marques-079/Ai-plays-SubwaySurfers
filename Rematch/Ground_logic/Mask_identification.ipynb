{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Triangles plotting lines pxl up from endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now renders ALL masks + triangles coloured by the mask sampled N px above the tip\n",
    "# + Scout lines: per-pixel coloured line from tip to sample point (render-only)\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays2\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Triangle mask scan distance (N pixels above tip)\n",
    "SAMPLE_UP_PX        = 65\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)  # readable pink\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None   # None → all frames\n",
    "RENDER_FIRST_N      = 150     # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "SAFE_GREEN = {9, 10}          # rails or sidewalk or no mask -> green\n",
    "WARN_YELLOW = {2,3,4,5,8}   # barrier/jump/train/ramp -> yellow\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ---- Triangle classification by sampling masks N px above tip (no resizes) ----\n",
    "def classify_triangles_at_sample(tri_positions, masks_np, classes_np, frame_H, frame_W, sample_up=SAMPLE_UP_PX):\n",
    "    \"\"\"\n",
    "    For each triangle (x,y), sample (x, y - N) and determine which mask/class covers it.\n",
    "    If no mask there: GREEN. If class==0: PINK. If class in {2,3,4,5,6,8}: YELLOW.\n",
    "    If class in {9,10}: GREEN. Else: RED.\n",
    "    Uses scale mapping into masks grid; avoids resizing masks.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "\n",
    "    colours = []\n",
    "    for (x, y) in tri_positions:\n",
    "        ys = max(0, y - sample_up)\n",
    "        mx = int(round(x * sx))\n",
    "        my = int(round(ys * sy))\n",
    "        if mx < 0: mx = 0\n",
    "        elif mx >= mw: mx = mw - 1\n",
    "        if my < 0: my = 0\n",
    "        elif my >= mh: my = mh - 1\n",
    "\n",
    "        cls_here = None\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            if m[my, mx] > 0.5:  # mask hit\n",
    "                cls_here = int(c)\n",
    "                break\n",
    "\n",
    "        if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "            colours.append(COLOR_GREEN)\n",
    "        elif cls_here == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif cls_here in WARN_YELLOW:\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "\n",
    "    return colours\n",
    "\n",
    "# --- NEW (render-only): colour for any frame-point via masks (no resizes) ---\n",
    "def _colour_for_point(x, y, masks_np, classes_np, frame_H, frame_W):\n",
    "    \"\"\"\n",
    "    Determine display colour at frame point (x,y) using same mapping rules as classifier.\n",
    "    No mask or class in SAFE_GREEN -> GREEN; class==0 -> PINK; class in WARN_YELLOW -> YELLOW; else RED.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    # Precompute scales\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "    mx = int(round(x * sx))\n",
    "    my = int(round(y * sy))\n",
    "    if mx < 0: mx = 0\n",
    "    elif mx >= mw: mx = mw - 1\n",
    "    if my < 0: my = 0\n",
    "    elif my >= mh: my = mh - 1\n",
    "\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5:\n",
    "            cls_here = int(c)\n",
    "            break\n",
    "\n",
    "    if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "        return COLOR_GREEN\n",
    "    if cls_here == 0:\n",
    "        return COLOR_PINK\n",
    "    if cls_here in WARN_YELLOW:\n",
    "        return COLOR_YELLOW\n",
    "    return COLOR_RED\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # classify triangles by sampling masks above tip\n",
    "    tri_colours = classify_triangles_at_sample(tri_positions, masks_np, classes_np, H, W, SAMPLE_UP_PX)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, coloured triangles, and scout lines on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # --- Scout lines (render-only): per-pixel coloured vertical line up to sample point ---\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            # Draw 1px dots along path; color per mask under that pixel\n",
    "            # (Cheap: ≤ SAMPLE_UP_PX points per triangle)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                col = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "                # draw a 1px point\n",
    "                out[yy, x] = col  # direct assign faster than cv2.circle for 1px\n",
    "\n",
    "    # Draw triangles with per-triangle colours (after scout lines so tips are visible)\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da271eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNice—this fits cleanly into what you already compute from the heatmap (the dark connected components). I tweaked your pipeline so we:\\ntag each triangle with its component label during purple_triangles, look up which component contains the lane probe point (mocked “Jake lane” = 0), and\\n\\ndraw a pink outline around the triangle whose component matches that lane’s hot region.\\nThis adds essentially no overhead: we’re already building lbls and iterating labels; we just carry the label for each triangle and do a single pixel lookup.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Nice—this fits cleanly into what you already compute from the heatmap (the dark connected components). I tweaked your pipeline so we:\n",
    "tag each triangle with its component label during purple_triangles, look up which component contains the lane probe point (mocked “Jake lane” = 0), and\n",
    "\n",
    "draw a pink outline around the triangle whose component matches that lane’s hot region.\n",
    "This adds essentially no overhead: we’re already building lbls and iterating labels; we just carry the label for each triangle and do a single pixel lookup.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a1beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/144] frame_00000.png  read 43.7 | infer 101.9 | to_cpu 5.5 | post 53.8 | masks 2 | triangles 1 => proc 161.3 ms\n",
      "[2/144] frame_00001.png  read 37.1 | infer 42.8 | to_cpu 1.2 | post 75.1 | masks 3 | triangles 1 => proc 119.1 ms\n",
      "[3/144] frame_00002.png  read 36.0 | infer 45.8 | to_cpu 0.8 | post 95.8 | masks 3 | triangles 1 => proc 142.4 ms\n",
      "[4/144] frame_00003.png  read 39.4 | infer 51.2 | to_cpu 1.2 | post 104.9 | masks 2 | triangles 1 => proc 157.3 ms\n",
      "[5/144] frame_00004.png  read 61.8 | infer 87.9 | to_cpu 0.8 | post 169.5 | masks 5 | triangles 1 => proc 258.3 ms\n",
      "[6/144] frame_00005.png  read 37.4 | infer 43.4 | to_cpu 0.9 | post 166.9 | masks 5 | triangles 1 => proc 211.2 ms\n",
      "[7/144] frame_00006.png  read 40.9 | infer 55.0 | to_cpu 0.9 | post 160.1 | masks 6 | triangles 2 => proc 215.9 ms\n",
      "[8/144] frame_00007.png  read 39.7 | infer 37.7 | to_cpu 1.0 | post 311.2 | masks 4 | triangles 2 => proc 349.9 ms\n",
      "[9/144] frame_00008.png  read 37.1 | infer 60.4 | to_cpu 1.2 | post 179.6 | masks 5 | triangles 2 => proc 241.2 ms\n",
      "[10/144] frame_00009.png  read 38.3 | infer 36.6 | to_cpu 0.9 | post 168.0 | masks 4 | triangles 2 => proc 205.4 ms\n",
      "[11/144] frame_00010.png  read 38.7 | infer 37.5 | to_cpu 0.8 | post 169.7 | masks 4 | triangles 2 => proc 208.0 ms\n",
      "[12/144] frame_00011.png  read 36.7 | infer 43.5 | to_cpu 0.7 | post 170.1 | masks 3 | triangles 3 => proc 214.4 ms\n",
      "[13/144] frame_00012.png  read 40.6 | infer 54.4 | to_cpu 1.0 | post 178.6 | masks 4 | triangles 3 => proc 234.0 ms\n",
      "[14/144] frame_00013.png  read 39.8 | infer 43.7 | to_cpu 0.7 | post 228.8 | masks 4 | triangles 3 => proc 273.2 ms\n",
      "[15/144] frame_00014.png  read 40.3 | infer 42.7 | to_cpu 0.7 | post 169.9 | masks 4 | triangles 3 => proc 213.3 ms\n",
      "[16/144] frame_00015.png  read 41.0 | infer 39.7 | to_cpu 0.8 | post 180.4 | masks 4 | triangles 3 => proc 220.9 ms\n",
      "[17/144] frame_00016.png  read 38.6 | infer 38.8 | to_cpu 0.7 | post 163.0 | masks 4 | triangles 3 => proc 202.6 ms\n",
      "[18/144] frame_00017.png  read 38.2 | infer 41.5 | to_cpu 1.0 | post 146.3 | masks 5 | triangles 1 => proc 188.8 ms\n",
      "[19/144] frame_00018.png  read 41.1 | infer 41.2 | to_cpu 0.9 | post 178.6 | masks 5 | triangles 1 => proc 220.7 ms\n",
      "[20/144] frame_00019.png  read 41.4 | infer 43.4 | to_cpu 0.9 | post 155.6 | masks 6 | triangles 1 => proc 199.9 ms\n",
      "[21/144] frame_00020.png  read 40.7 | infer 34.4 | to_cpu 0.8 | post 147.7 | masks 5 | triangles 2 => proc 182.9 ms\n",
      "[22/144] frame_00021.png  read 37.5 | infer 40.8 | to_cpu 1.1 | post 152.7 | masks 5 | triangles 1 => proc 194.5 ms\n",
      "[23/144] frame_00022.png  read 40.6 | infer 34.9 | to_cpu 0.9 | post 196.4 | masks 4 | triangles 2 => proc 232.1 ms\n",
      "[24/144] frame_00023.png  read 38.0 | infer 34.0 | to_cpu 0.7 | post 137.5 | masks 5 | triangles 1 => proc 172.2 ms\n",
      "[25/144] frame_00024.png  read 39.0 | infer 35.4 | to_cpu 1.1 | post 140.2 | masks 5 | triangles 2 => proc 176.7 ms\n",
      "[26/144] frame_00025.png  read 36.4 | infer 34.5 | to_cpu 0.9 | post 132.2 | masks 4 | triangles 2 => proc 167.7 ms\n",
      "[27/144] frame_00026.png  read 36.8 | infer 41.8 | to_cpu 1.1 | post 125.0 | masks 6 | triangles 1 => proc 167.9 ms\n",
      "[28/144] frame_00027.png  read 38.2 | infer 53.3 | to_cpu 1.4 | post 149.1 | masks 6 | triangles 1 => proc 203.8 ms\n",
      "[29/144] frame_00028.png  read 39.9 | infer 42.3 | to_cpu 1.0 | post 136.3 | masks 6 | triangles 3 => proc 179.6 ms\n",
      "[30/144] frame_00029.png  read 37.3 | infer 34.4 | to_cpu 0.8 | post 103.1 | masks 4 | triangles 1 => proc 138.3 ms\n",
      "[31/144] frame_00030.png  read 39.4 | infer 40.6 | to_cpu 0.8 | post 125.2 | masks 4 | triangles 1 => proc 166.6 ms\n",
      "[32/144] frame_00031.png  read 38.0 | infer 36.3 | to_cpu 0.9 | post 121.5 | masks 5 | triangles 1 => proc 158.7 ms\n",
      "[33/144] frame_00032.png  read 40.8 | infer 40.2 | to_cpu 1.9 | post 147.3 | masks 5 | triangles 2 => proc 189.4 ms\n",
      "[34/144] frame_00033.png  read 96.2 | infer 42.0 | to_cpu 0.8 | post 166.4 | masks 5 | triangles 2 => proc 209.3 ms\n",
      "[35/144] frame_00034.png  read 38.6 | infer 40.7 | to_cpu 0.9 | post 148.4 | masks 5 | triangles 2 => proc 190.0 ms\n",
      "[36/144] frame_00035.png  read 38.1 | infer 48.7 | to_cpu 1.0 | post 155.1 | masks 7 | triangles 1 => proc 204.9 ms\n",
      "[37/144] frame_00036.png  read 47.7 | infer 43.9 | to_cpu 0.9 | post 147.3 | masks 6 | triangles 1 => proc 192.1 ms\n",
      "[38/144] frame_00037.png  read 37.9 | infer 52.6 | to_cpu 1.1 | post 149.6 | masks 9 | triangles 1 => proc 203.3 ms\n",
      "[39/144] frame_00038.png  read 41.5 | infer 49.9 | to_cpu 1.3 | post 149.9 | masks 9 | triangles 2 => proc 201.1 ms\n",
      "[40/144] frame_00039.png  read 42.2 | infer 40.1 | to_cpu 1.1 | post 77.0 | masks 7 | triangles 1 => proc 118.2 ms\n",
      "[41/144] frame_00040.png  read 36.8 | infer 39.8 | to_cpu 0.9 | post 164.8 | masks 5 | triangles 2 => proc 205.5 ms\n",
      "[42/144] frame_00041.png  read 39.4 | infer 41.8 | to_cpu 0.7 | post 156.1 | masks 4 | triangles 2 => proc 198.5 ms\n",
      "[43/144] frame_00042.png  read 36.4 | infer 41.7 | to_cpu 0.7 | post 159.2 | masks 3 | triangles 3 => proc 201.5 ms\n",
      "[44/144] frame_00043.png  read 39.0 | infer 42.2 | to_cpu 0.9 | post 162.2 | masks 3 | triangles 3 => proc 205.3 ms\n",
      "[45/144] frame_00044.png  read 39.1 | infer 34.6 | to_cpu 0.8 | post 162.2 | masks 3 | triangles 2 => proc 197.6 ms\n",
      "[46/144] frame_00045.png  read 35.3 | infer 33.8 | to_cpu 0.7 | post 143.0 | masks 3 | triangles 2 => proc 177.4 ms\n",
      "[47/144] frame_00046.png  read 33.2 | infer 36.7 | to_cpu 0.9 | post 154.4 | masks 3 | triangles 2 => proc 192.0 ms\n",
      "[48/144] frame_00047.png  read 35.5 | infer 40.7 | to_cpu 0.7 | post 141.1 | masks 2 | triangles 1 => proc 182.4 ms\n",
      "[49/144] frame_00048.png  read 32.6 | infer 64.7 | to_cpu 20.4 | post 122.0 | masks 2 | triangles 1 => proc 207.1 ms\n",
      "[50/144] frame_00049.png  read 44.6 | infer 51.1 | to_cpu 0.6 | post 103.3 | masks 1 | triangles 1 => proc 155.0 ms\n",
      "[51/144] frame_00050.png  read 31.0 | infer 50.6 | to_cpu 1.5 | post 107.3 | masks 1 | triangles 1 => proc 159.4 ms\n",
      "[52/144] frame_00051.png  read 34.7 | infer 34.3 | to_cpu 0.6 | post 99.5 | masks 1 | triangles 1 => proc 134.4 ms\n",
      "[53/144] frame_00052.png  read 33.4 | infer 41.9 | to_cpu 0.8 | post 99.4 | masks 2 | triangles 1 => proc 142.0 ms\n",
      "[54/144] frame_00053.png  read 42.3 | infer 286.3 | to_cpu 0.7 | post 168.5 | masks 2 | triangles 2 => proc 455.5 ms\n",
      "[55/144] frame_00054.png  read 36.0 | infer 44.9 | to_cpu 0.7 | post 153.8 | masks 2 | triangles 2 => proc 199.4 ms\n",
      "[56/144] frame_00055.png  read 39.0 | infer 43.9 | to_cpu 0.7 | post 165.2 | masks 2 | triangles 2 => proc 209.8 ms\n",
      "[57/144] frame_00056.png  read 37.4 | infer 42.0 | to_cpu 0.7 | post 264.4 | masks 2 | triangles 2 => proc 307.2 ms\n",
      "[58/144] frame_00057.png  read 46.4 | infer 39.0 | to_cpu 0.9 | post 163.7 | masks 3 | triangles 2 => proc 203.6 ms\n",
      "[59/144] frame_00058.png  read 36.4 | infer 39.6 | to_cpu 0.8 | post 162.0 | masks 3 | triangles 2 => proc 202.3 ms\n",
      "[60/144] frame_00059.png  read 36.8 | infer 46.3 | to_cpu 0.8 | post 151.3 | masks 3 | triangles 1 => proc 198.4 ms\n",
      "[61/144] frame_00060.png  read 38.7 | infer 44.4 | to_cpu 0.8 | post 140.6 | masks 3 | triangles 1 => proc 185.8 ms\n",
      "[62/144] frame_00061.png  read 39.6 | infer 40.4 | to_cpu 1.0 | post 120.2 | masks 5 | triangles 1 => proc 161.6 ms\n",
      "[63/144] frame_00062.png  read 42.8 | infer 35.9 | to_cpu 0.8 | post 117.4 | masks 4 | triangles 1 => proc 154.1 ms\n",
      "[64/144] frame_00063.png  read 37.7 | infer 39.8 | to_cpu 0.7 | post 123.2 | masks 4 | triangles 1 => proc 163.8 ms\n",
      "[65/144] frame_00064.png  read 37.1 | infer 33.2 | to_cpu 0.8 | post 128.3 | masks 4 | triangles 1 => proc 162.4 ms\n",
      "[66/144] frame_00065.png  read 38.7 | infer 41.2 | to_cpu 0.9 | post 122.4 | masks 4 | triangles 1 => proc 164.5 ms\n",
      "[67/144] frame_00066.png  read 40.9 | infer 42.8 | to_cpu 0.9 | post 116.3 | masks 4 | triangles 1 => proc 159.9 ms\n",
      "[68/144] frame_00067.png  read 44.8 | infer 42.4 | to_cpu 0.7 | post 105.7 | masks 4 | triangles 1 => proc 148.9 ms\n",
      "[69/144] frame_00068.png  read 37.3 | infer 46.0 | to_cpu 1.3 | post 118.7 | masks 5 | triangles 2 => proc 166.1 ms\n",
      "[70/144] frame_00069.png  read 38.3 | infer 39.8 | to_cpu 0.7 | post 118.8 | masks 4 | triangles 1 => proc 159.3 ms\n",
      "[71/144] frame_00070.png  read 90.5 | infer 49.5 | to_cpu 0.9 | post 227.9 | masks 5 | triangles 2 => proc 278.3 ms\n",
      "[72/144] frame_00071.png  read 40.8 | infer 45.4 | to_cpu 1.0 | post 129.6 | masks 7 | triangles 1 => proc 176.0 ms\n",
      "[73/144] frame_00072.png  read 42.0 | infer 41.9 | to_cpu 0.9 | post 149.8 | masks 6 | triangles 2 => proc 192.6 ms\n",
      "[74/144] frame_00073.png  read 37.4 | infer 38.1 | to_cpu 0.9 | post 161.3 | masks 5 | triangles 2 => proc 200.3 ms\n",
      "[75/144] frame_00074.png  read 41.2 | infer 58.8 | to_cpu 0.8 | post 214.7 | masks 4 | triangles 2 => proc 274.3 ms\n",
      "[76/144] frame_00075.png  read 49.7 | infer 38.9 | to_cpu 0.9 | post 192.0 | masks 5 | triangles 2 => proc 231.7 ms\n",
      "[77/144] frame_00076.png  read 38.8 | infer 48.6 | to_cpu 0.9 | post 154.1 | masks 5 | triangles 2 => proc 203.5 ms\n",
      "[78/144] frame_00077.png  read 37.2 | infer 39.3 | to_cpu 0.7 | post 186.5 | masks 5 | triangles 2 => proc 226.5 ms\n",
      "[79/144] frame_00078.png  read 39.5 | infer 49.3 | to_cpu 1.1 | post 172.4 | masks 4 | triangles 2 => proc 222.7 ms\n",
      "[80/144] frame_00079.png  read 39.8 | infer 52.2 | to_cpu 0.9 | post 188.9 | masks 4 | triangles 2 => proc 242.0 ms\n",
      "[81/144] frame_00080.png  read 50.9 | infer 86.3 | to_cpu 0.7 | post 272.9 | masks 3 | triangles 2 => proc 359.9 ms\n",
      "[82/144] frame_00081.png  read 36.6 | infer 43.6 | to_cpu 0.7 | post 106.3 | masks 3 | triangles 1 => proc 150.6 ms\n",
      "[83/144] frame_00082.png  read 51.0 | infer 106.8 | to_cpu 0.7 | post 99.4 | masks 4 | triangles 1 => proc 206.9 ms\n",
      "[84/144] frame_00083.png  read 40.9 | infer 37.9 | to_cpu 0.7 | post 70.7 | masks 3 | triangles 1 => proc 109.3 ms\n",
      "[85/144] frame_00084.png  read 33.1 | infer 47.9 | to_cpu 1.2 | post 31.0 | masks 5 | triangles 0 => proc 80.0 ms\n",
      "[86/144] frame_00085.png  read 97.4 | infer 44.5 | to_cpu 0.8 | post 124.4 | masks 4 | triangles 1 => proc 169.7 ms\n",
      "[87/144] frame_00086.png  read 40.2 | infer 35.5 | to_cpu 0.9 | post 129.9 | masks 5 | triangles 1 => proc 166.2 ms\n",
      "[88/144] frame_00087.png  read 36.6 | infer 44.4 | to_cpu 0.9 | post 153.5 | masks 5 | triangles 2 => proc 198.7 ms\n",
      "[89/144] frame_00088.png  read 39.7 | infer 35.3 | to_cpu 0.7 | post 148.6 | masks 5 | triangles 2 => proc 184.7 ms\n",
      "[90/144] frame_00089.png  read 37.6 | infer 47.5 | to_cpu 0.8 | post 183.4 | masks 5 | triangles 2 => proc 231.6 ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 487\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# Entry\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     _ = \u001b[43mrun_pipeline_with_prints_and_overlays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 436\u001b[39m, in \u001b[36mrun_pipeline_with_prints_and_overlays\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    434\u001b[39m idx_global = \u001b[32m0\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_paths \u001b[38;5;129;01min\u001b[39;00m chunked(paths, BATCH):\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     batch_paths, imgs_bgr, read_ms_list = \u001b[43mload_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     B = \u001b[38;5;28mlen\u001b[39m(imgs_bgr)\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m B == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 423\u001b[39m, in \u001b[36mrun_pipeline_with_prints_and_overlays.<locals>.load_batch\u001b[39m\u001b[34m(batch_paths)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=THREADS_IO) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    422\u001b[39m     fut2idx = {ex.submit(load_image_with_time, p): i \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_paths)}\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfut\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfut2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfut2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfut\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now renders ALL masks + triangles coloured by the mask sampled N px above the tip\n",
    "# + Scout lines: per-pixel coloured line from tip to sample point (render-only)\n",
    "# + NEW: starburst lines from each triangle tip to Jake's middle-lane point\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "import os, glob, sys, time, math\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "# SAVE HERE (changed to overlays3)\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays3\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Triangle mask scan distance (N pixels above tip)\n",
    "SAMPLE_UP_PX        = 65\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)  # readable pink\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None   # None → all frames\n",
    "RENDER_FIRST_N      = 150     # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# Jake lane points (hardcode middle for now)\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "JAKE_POINT  = LANE_RIGHT   # hardcoded to middle lane as requested\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "SAFE_GREEN = {9, 10}          # rails or sidewalk or no mask -> green\n",
    "WARN_YELLOW = {2,3,4,5,8}     # barrier/jump/ramp -> yellow\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ---- Triangle classification by sampling masks N px above tip (no resizes) ----\n",
    "def classify_triangles_at_sample(tri_positions, masks_np, classes_np, frame_H, frame_W, sample_up=SAMPLE_UP_PX):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "\n",
    "    colours = []\n",
    "    for (x, y) in tri_positions:\n",
    "        ys = max(0, y - sample_up)\n",
    "        mx = int(round(x * sx))\n",
    "        my = int(round(ys * sy))\n",
    "        if mx < 0: mx = 0\n",
    "        elif mx >= mw: mx = mw - 1\n",
    "        if my < 0: my = 0\n",
    "        elif my >= mh: my = mh - 1\n",
    "\n",
    "        cls_here = None\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            if m[my, mx] > 0.5:\n",
    "                cls_here = int(c)\n",
    "                break\n",
    "\n",
    "        if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "            colours.append(COLOR_GREEN)\n",
    "        elif cls_here == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif cls_here in WARN_YELLOW:\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "\n",
    "    return colours\n",
    "\n",
    "# --- colour for any frame-point via masks (no resizes) ---\n",
    "def _colour_for_point(x, y, masks_np, classes_np, frame_H, frame_W):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "    mx = int(round(x * sx))\n",
    "    my = int(round(y * sy))\n",
    "    if mx < 0: mx = 0\n",
    "    elif mx >= mw: mx = mw - 1\n",
    "    if my < 0: my = 0\n",
    "    elif my >= mh: my = mh - 1\n",
    "\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5:\n",
    "            cls_here = int(c)\n",
    "            break\n",
    "\n",
    "    if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "        return COLOR_GREEN\n",
    "    if cls_here == 0:\n",
    "        return COLOR_PINK\n",
    "    if cls_here in WARN_YELLOW:\n",
    "        return COLOR_YELLOW\n",
    "    return COLOR_RED\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # classify triangles by sampling masks above tip\n",
    "    tri_colours = classify_triangles_at_sample(tri_positions, masks_np, classes_np, H, W, SAMPLE_UP_PX)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, coloured triangles, scout lines,\n",
    "       and NEW: straight lines from each triangle to Jake's middle-lane point.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Scout lines (render-only): tiny, cheap\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                col = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "                out[yy, x] = col\n",
    "\n",
    "    # NEW: starburst lines from each triangle to Jake's middle-lane point\n",
    "    xj, yj = JAKE_POINT\n",
    "    for (xt, yt) in tri_positions:\n",
    "        # clamp target to frame bounds just in case\n",
    "        xt = max(0, min(W-1, int(xt)))\n",
    "        yt = max(0, min(H-1, int(yt)))\n",
    "\n",
    "        dx = xt - xj\n",
    "        dy = yt - yj\n",
    "\n",
    "        # Degrees FROM VERTICAL (0° = perfectly vertical line)\n",
    "        deg_from_vertical = 90.0 if dy == 0 else math.degrees(math.atan2(abs(dx), abs(dy)))\n",
    "\n",
    "        # Draw the line\n",
    "        cv2.line(out, (xj, yj), (xt, yt), COLOR_WHITE, 2, cv2.LINE_AA)\n",
    "\n",
    "        # Label near the midpoint of the line\n",
    "        mid_x = int((xj + xt) / 2)\n",
    "        mid_y = int((yj + yt) / 2)\n",
    "        label = f\"{deg_from_vertical:.1f}°\"\n",
    "\n",
    "        # outlined text for readability\n",
    "        cv2.putText(out, label, (mid_x, mid_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, label, (mid_x, mid_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Triangles (after lines so tips stay visible)\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "       \n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2168c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jakes triangle finder final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf2a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/144] frame_00000.png  read 38.0 | infer 97.0 | to_cpu 0.8 | post 63.5 | masks 2 | triangles 1 => proc 161.3 ms\n",
      "[2/144] frame_00001.png  read 37.0 | infer 38.9 | to_cpu 0.9 | post 91.6 | masks 3 | triangles 1 => proc 131.4 ms\n",
      "[3/144] frame_00002.png  read 36.0 | infer 42.3 | to_cpu 0.7 | post 147.6 | masks 3 | triangles 1 => proc 190.6 ms\n",
      "[4/144] frame_00003.png  read 82.6 | infer 43.9 | to_cpu 0.7 | post 102.4 | masks 2 | triangles 1 => proc 147.0 ms\n",
      "[5/144] frame_00004.png  read 52.6 | infer 45.5 | to_cpu 0.9 | post 165.1 | masks 5 | triangles 1 => proc 211.5 ms\n",
      "[6/144] frame_00005.png  read 41.3 | infer 40.0 | to_cpu 0.8 | post 156.1 | masks 5 | triangles 1 => proc 196.8 ms\n",
      "[7/144] frame_00006.png  read 43.9 | infer 323.7 | to_cpu 1.5 | post 172.1 | masks 6 | triangles 2 => proc 497.2 ms\n",
      "[8/144] frame_00007.png  read 37.3 | infer 44.7 | to_cpu 0.8 | post 179.9 | masks 4 | triangles 2 => proc 225.4 ms\n",
      "[9/144] frame_00008.png  read 41.4 | infer 57.3 | to_cpu 1.0 | post 171.1 | masks 5 | triangles 2 => proc 229.3 ms\n",
      "[10/144] frame_00009.png  read 141.1 | infer 33.1 | to_cpu 0.8 | post 168.8 | masks 4 | triangles 2 => proc 202.7 ms\n",
      "[11/144] frame_00010.png  read 38.3 | infer 33.1 | to_cpu 0.7 | post 158.1 | masks 4 | triangles 2 => proc 191.9 ms\n",
      "[12/144] frame_00011.png  read 37.4 | infer 50.4 | to_cpu 0.7 | post 157.9 | masks 3 | triangles 3 => proc 209.0 ms\n",
      "[13/144] frame_00012.png  read 36.2 | infer 39.3 | to_cpu 0.8 | post 163.4 | masks 4 | triangles 3 => proc 203.4 ms\n",
      "[14/144] frame_00013.png  read 39.4 | infer 39.8 | to_cpu 1.0 | post 163.5 | masks 4 | triangles 3 => proc 204.2 ms\n",
      "[15/144] frame_00014.png  read 37.1 | infer 40.0 | to_cpu 0.8 | post 168.6 | masks 4 | triangles 3 => proc 209.4 ms\n",
      "[16/144] frame_00015.png  read 39.3 | infer 42.4 | to_cpu 0.7 | post 195.3 | masks 4 | triangles 3 => proc 238.5 ms\n",
      "[17/144] frame_00016.png  read 36.1 | infer 63.4 | to_cpu 0.8 | post 159.4 | masks 4 | triangles 3 => proc 223.5 ms\n",
      "[18/144] frame_00017.png  read 35.7 | infer 37.2 | to_cpu 0.9 | post 169.0 | masks 5 | triangles 1 => proc 207.1 ms\n",
      "[19/144] frame_00018.png  read 37.1 | infer 42.0 | to_cpu 1.2 | post 141.1 | masks 5 | triangles 1 => proc 184.2 ms\n",
      "[20/144] frame_00019.png  read 40.9 | infer 325.9 | to_cpu 2.1 | post 160.9 | masks 6 | triangles 1 => proc 488.9 ms\n",
      "[21/144] frame_00020.png  read 40.2 | infer 79.5 | to_cpu 0.8 | post 183.5 | masks 5 | triangles 2 => proc 263.9 ms\n",
      "[22/144] frame_00021.png  read 44.1 | infer 37.8 | to_cpu 0.8 | post 151.6 | masks 5 | triangles 1 => proc 190.2 ms\n",
      "[23/144] frame_00022.png  read 38.1 | infer 35.4 | to_cpu 0.7 | post 158.7 | masks 4 | triangles 2 => proc 194.8 ms\n",
      "[24/144] frame_00023.png  read 39.5 | infer 34.0 | to_cpu 0.8 | post 143.7 | masks 5 | triangles 1 => proc 178.6 ms\n",
      "[25/144] frame_00024.png  read 36.8 | infer 31.1 | to_cpu 0.8 | post 141.4 | masks 5 | triangles 2 => proc 173.2 ms\n",
      "[26/144] frame_00025.png  read 37.4 | infer 34.5 | to_cpu 0.7 | post 144.3 | masks 4 | triangles 2 => proc 179.5 ms\n",
      "[27/144] frame_00026.png  read 36.9 | infer 199.5 | to_cpu 1.0 | post 176.2 | masks 6 | triangles 1 => proc 376.7 ms\n",
      "[28/144] frame_00027.png  read 40.2 | infer 54.7 | to_cpu 0.9 | post 133.2 | masks 6 | triangles 1 => proc 188.9 ms\n",
      "[29/144] frame_00028.png  read 36.7 | infer 51.4 | to_cpu 1.0 | post 146.7 | masks 6 | triangles 3 => proc 199.1 ms\n",
      "[30/144] frame_00029.png  read 40.4 | infer 43.4 | to_cpu 0.9 | post 117.9 | masks 4 | triangles 1 => proc 162.3 ms\n",
      "[31/144] frame_00030.png  read 40.5 | infer 42.9 | to_cpu 0.7 | post 129.0 | masks 4 | triangles 1 => proc 172.6 ms\n",
      "[32/144] frame_00031.png  read 39.7 | infer 49.3 | to_cpu 0.8 | post 120.2 | masks 5 | triangles 1 => proc 170.3 ms\n",
      "[33/144] frame_00032.png  read 39.6 | infer 38.6 | to_cpu 0.8 | post 171.6 | masks 5 | triangles 2 => proc 211.0 ms\n",
      "[34/144] frame_00033.png  read 39.7 | infer 40.5 | to_cpu 0.9 | post 159.1 | masks 5 | triangles 2 => proc 200.5 ms\n",
      "[35/144] frame_00034.png  read 36.3 | infer 45.5 | to_cpu 0.7 | post 147.8 | masks 5 | triangles 2 => proc 194.1 ms\n",
      "[36/144] frame_00035.png  read 37.6 | infer 82.7 | to_cpu 1.3 | post 166.5 | masks 7 | triangles 1 => proc 250.5 ms\n",
      "[37/144] frame_00036.png  read 36.2 | infer 44.5 | to_cpu 0.9 | post 143.6 | masks 6 | triangles 1 => proc 189.0 ms\n",
      "[38/144] frame_00037.png  read 40.3 | infer 40.8 | to_cpu 1.2 | post 154.7 | masks 9 | triangles 1 => proc 196.6 ms\n",
      "[39/144] frame_00038.png  read 37.6 | infer 39.8 | to_cpu 1.2 | post 149.5 | masks 9 | triangles 2 => proc 190.5 ms\n",
      "[40/144] frame_00039.png  read 39.6 | infer 41.3 | to_cpu 1.0 | post 80.6 | masks 7 | triangles 1 => proc 122.9 ms\n",
      "[41/144] frame_00040.png  read 37.6 | infer 42.3 | to_cpu 0.9 | post 162.3 | masks 5 | triangles 2 => proc 205.4 ms\n",
      "[42/144] frame_00041.png  read 39.1 | infer 31.9 | to_cpu 0.8 | post 151.5 | masks 4 | triangles 2 => proc 184.2 ms\n",
      "[43/144] frame_00042.png  read 40.8 | infer 44.7 | to_cpu 0.7 | post 158.9 | masks 3 | triangles 3 => proc 204.3 ms\n",
      "[44/144] frame_00043.png  read 36.0 | infer 40.4 | to_cpu 0.7 | post 160.0 | masks 3 | triangles 3 => proc 201.2 ms\n",
      "[45/144] frame_00044.png  read 37.0 | infer 31.6 | to_cpu 0.6 | post 147.8 | masks 3 | triangles 2 => proc 180.1 ms\n",
      "[46/144] frame_00045.png  read 36.6 | infer 33.3 | to_cpu 0.8 | post 149.9 | masks 3 | triangles 2 => proc 184.0 ms\n",
      "[47/144] frame_00046.png  read 33.3 | infer 31.6 | to_cpu 0.7 | post 165.3 | masks 3 | triangles 2 => proc 197.6 ms\n",
      "[48/144] frame_00047.png  read 32.0 | infer 42.1 | to_cpu 0.7 | post 138.7 | masks 2 | triangles 1 => proc 181.4 ms\n",
      "[49/144] frame_00048.png  read 34.5 | infer 48.1 | to_cpu 0.6 | post 106.0 | masks 2 | triangles 1 => proc 154.7 ms\n",
      "[50/144] frame_00049.png  read 30.2 | infer 38.4 | to_cpu 0.5 | post 100.8 | masks 1 | triangles 1 => proc 139.7 ms\n",
      "[51/144] frame_00050.png  read 30.5 | infer 39.1 | to_cpu 0.9 | post 99.5 | masks 1 | triangles 1 => proc 139.5 ms\n",
      "[52/144] frame_00051.png  read 30.4 | infer 39.8 | to_cpu 0.6 | post 224.4 | masks 1 | triangles 1 => proc 264.9 ms\n",
      "[53/144] frame_00052.png  read 35.7 | infer 44.7 | to_cpu 0.7 | post 103.6 | masks 2 | triangles 1 => proc 149.1 ms\n",
      "[54/144] frame_00053.png  read 35.6 | infer 39.6 | to_cpu 0.7 | post 139.4 | masks 2 | triangles 2 => proc 179.7 ms\n",
      "[55/144] frame_00054.png  read 37.4 | infer 39.0 | to_cpu 0.6 | post 146.3 | masks 2 | triangles 2 => proc 185.9 ms\n",
      "[56/144] frame_00055.png  read 38.8 | infer 42.1 | to_cpu 0.7 | post 162.9 | masks 2 | triangles 2 => proc 205.7 ms\n",
      "[57/144] frame_00056.png  read 36.6 | infer 36.2 | to_cpu 0.6 | post 149.5 | masks 2 | triangles 2 => proc 186.3 ms\n",
      "[58/144] frame_00057.png  read 39.7 | infer 36.1 | to_cpu 0.8 | post 150.2 | masks 3 | triangles 2 => proc 187.1 ms\n",
      "[59/144] frame_00058.png  read 38.3 | infer 41.1 | to_cpu 0.6 | post 156.2 | masks 3 | triangles 2 => proc 198.0 ms\n",
      "[60/144] frame_00059.png  read 38.2 | infer 41.1 | to_cpu 0.7 | post 143.0 | masks 3 | triangles 1 => proc 184.8 ms\n",
      "[61/144] frame_00060.png  read 36.5 | infer 40.6 | to_cpu 0.7 | post 127.0 | masks 3 | triangles 1 => proc 168.3 ms\n",
      "[62/144] frame_00061.png  read 39.9 | infer 40.8 | to_cpu 0.8 | post 123.6 | masks 5 | triangles 1 => proc 165.2 ms\n",
      "[63/144] frame_00062.png  read 37.2 | infer 30.5 | to_cpu 0.7 | post 115.8 | masks 4 | triangles 1 => proc 147.0 ms\n",
      "[64/144] frame_00063.png  read 40.2 | infer 44.8 | to_cpu 0.8 | post 117.0 | masks 4 | triangles 1 => proc 162.6 ms\n",
      "[65/144] frame_00064.png  read 37.5 | infer 35.9 | to_cpu 0.8 | post 112.4 | masks 4 | triangles 1 => proc 149.1 ms\n",
      "[66/144] frame_00065.png  read 39.7 | infer 40.5 | to_cpu 0.8 | post 112.7 | masks 4 | triangles 1 => proc 153.9 ms\n",
      "[67/144] frame_00066.png  read 37.0 | infer 38.9 | to_cpu 0.7 | post 110.4 | masks 4 | triangles 1 => proc 150.0 ms\n",
      "[68/144] frame_00067.png  read 40.3 | infer 41.3 | to_cpu 1.1 | post 106.4 | masks 4 | triangles 1 => proc 148.9 ms\n",
      "[69/144] frame_00068.png  read 40.0 | infer 45.9 | to_cpu 0.9 | post 118.4 | masks 5 | triangles 2 => proc 165.3 ms\n",
      "[70/144] frame_00069.png  read 38.0 | infer 37.2 | to_cpu 0.8 | post 114.5 | masks 4 | triangles 1 => proc 152.5 ms\n",
      "[71/144] frame_00070.png  read 36.1 | infer 31.4 | to_cpu 0.8 | post 149.0 | masks 5 | triangles 2 => proc 181.3 ms\n",
      "[72/144] frame_00071.png  read 39.5 | infer 267.1 | to_cpu 1.7 | post 140.8 | masks 7 | triangles 1 => proc 409.6 ms\n",
      "[73/144] frame_00072.png  read 37.1 | infer 52.5 | to_cpu 0.9 | post 136.2 | masks 6 | triangles 2 => proc 189.6 ms\n",
      "[74/144] frame_00073.png  read 39.8 | infer 32.1 | to_cpu 0.8 | post 172.2 | masks 5 | triangles 2 => proc 205.1 ms\n",
      "[75/144] frame_00074.png  read 37.2 | infer 43.2 | to_cpu 0.8 | post 160.9 | masks 4 | triangles 2 => proc 204.9 ms\n",
      "[76/144] frame_00075.png  read 39.3 | infer 34.7 | to_cpu 0.8 | post 168.1 | masks 5 | triangles 2 => proc 203.6 ms\n",
      "[77/144] frame_00076.png  read 36.6 | infer 36.6 | to_cpu 0.8 | post 157.3 | masks 5 | triangles 2 => proc 194.6 ms\n",
      "[78/144] frame_00077.png  read 38.6 | infer 37.4 | to_cpu 0.9 | post 151.8 | masks 5 | triangles 2 => proc 190.1 ms\n",
      "[79/144] frame_00078.png  read 36.5 | infer 48.6 | to_cpu 2.6 | post 150.5 | masks 4 | triangles 2 => proc 201.7 ms\n",
      "[80/144] frame_00079.png  read 42.4 | infer 47.5 | to_cpu 0.9 | post 142.0 | masks 4 | triangles 2 => proc 190.4 ms\n",
      "[81/144] frame_00080.png  read 36.1 | infer 37.5 | to_cpu 0.6 | post 134.0 | masks 3 | triangles 2 => proc 172.1 ms\n",
      "[82/144] frame_00081.png  read 39.3 | infer 41.8 | to_cpu 0.8 | post 95.2 | masks 3 | triangles 1 => proc 137.8 ms\n",
      "[83/144] frame_00082.png  read 38.4 | infer 41.1 | to_cpu 0.7 | post 90.7 | masks 4 | triangles 1 => proc 132.5 ms\n",
      "[84/144] frame_00083.png  read 38.5 | infer 30.0 | to_cpu 0.7 | post 64.7 | masks 3 | triangles 1 => proc 95.4 ms\n",
      "[85/144] frame_00084.png  read 34.2 | infer 51.1 | to_cpu 1.0 | post 42.2 | masks 5 | triangles 0 => proc 94.3 ms\n",
      "[86/144] frame_00085.png  read 39.6 | infer 31.7 | to_cpu 0.8 | post 110.0 | masks 4 | triangles 1 => proc 142.5 ms\n",
      "[87/144] frame_00086.png  read 39.9 | infer 36.7 | to_cpu 0.8 | post 113.4 | masks 5 | triangles 1 => proc 150.9 ms\n",
      "[88/144] frame_00087.png  read 39.1 | infer 40.3 | to_cpu 0.9 | post 144.8 | masks 5 | triangles 2 => proc 185.9 ms\n",
      "[89/144] frame_00088.png  read 37.0 | infer 38.2 | to_cpu 0.9 | post 155.6 | masks 5 | triangles 2 => proc 194.7 ms\n",
      "[90/144] frame_00089.png  read 40.4 | infer 36.5 | to_cpu 0.8 | post 133.0 | masks 5 | triangles 2 => proc 170.3 ms\n",
      "[91/144] frame_00090.png  read 37.1 | infer 38.3 | to_cpu 0.9 | post 119.1 | masks 5 | triangles 1 => proc 158.3 ms\n",
      "[92/144] frame_00091.png  read 40.5 | infer 31.1 | to_cpu 0.8 | post 105.0 | masks 5 | triangles 1 => proc 136.9 ms\n",
      "[93/144] frame_00092.png  read 36.8 | infer 38.8 | to_cpu 0.8 | post 82.8 | masks 5 | triangles 1 => proc 122.3 ms\n",
      "[94/144] frame_00093.png  read 34.2 | infer 138.4 | to_cpu 1.0 | post 31.0 | masks 6 | triangles 0 => proc 170.4 ms\n",
      "[95/144] frame_00094.png  read 37.4 | infer 53.4 | to_cpu 0.9 | post 155.0 | masks 7 | triangles 1 => proc 209.3 ms\n",
      "[96/144] frame_00095.png  read 40.8 | infer 42.7 | to_cpu 2.4 | post 141.3 | masks 5 | triangles 1 => proc 186.4 ms\n",
      "[97/144] frame_00096.png  read 48.1 | infer 33.3 | to_cpu 0.8 | post 142.5 | masks 5 | triangles 1 => proc 176.7 ms\n",
      "[98/144] frame_00097.png  read 38.6 | infer 35.6 | to_cpu 0.8 | post 147.6 | masks 4 | triangles 2 => proc 184.0 ms\n",
      "[99/144] frame_00098.png  read 45.6 | infer 39.4 | to_cpu 0.7 | post 158.1 | masks 4 | triangles 3 => proc 198.2 ms\n",
      "[100/144] frame_00099.png  read 36.9 | infer 33.3 | to_cpu 0.7 | post 143.3 | masks 4 | triangles 2 => proc 177.3 ms\n",
      "[101/144] frame_00100.png  read 36.7 | infer 36.2 | to_cpu 0.7 | post 133.7 | masks 4 | triangles 2 => proc 170.5 ms\n",
      "[102/144] frame_00101.png  read 38.1 | infer 31.7 | to_cpu 0.8 | post 123.6 | masks 5 | triangles 1 => proc 156.0 ms\n",
      "[103/144] frame_00102.png  read 41.3 | infer 71.0 | to_cpu 1.2 | post 124.4 | masks 6 | triangles 1 => proc 196.6 ms\n",
      "[104/144] frame_00103.png  read 40.2 | infer 34.7 | to_cpu 0.9 | post 125.0 | masks 8 | triangles 1 => proc 160.6 ms\n",
      "[105/144] frame_00104.png  read 36.1 | infer 37.2 | to_cpu 2.7 | post 86.4 | masks 5 | triangles 2 => proc 126.3 ms\n",
      "[106/144] frame_00105.png  read 39.2 | infer 31.3 | to_cpu 0.8 | post 122.4 | masks 5 | triangles 2 => proc 154.5 ms\n",
      "[107/144] frame_00106.png  read 40.1 | infer 35.4 | to_cpu 0.8 | post 121.7 | masks 4 | triangles 1 => proc 157.9 ms\n",
      "[108/144] frame_00107.png  read 38.3 | infer 49.9 | to_cpu 0.7 | post 160.5 | masks 3 | triangles 2 => proc 211.2 ms\n",
      "[109/144] frame_00108.png  read 39.4 | infer 42.5 | to_cpu 0.8 | post 154.5 | masks 3 | triangles 2 => proc 197.8 ms\n",
      "[110/144] frame_00109.png  read 38.5 | infer 58.4 | to_cpu 0.6 | post 167.1 | masks 3 | triangles 2 => proc 226.2 ms\n",
      "[111/144] frame_00110.png  read 40.8 | infer 33.7 | to_cpu 0.7 | post 149.8 | masks 4 | triangles 2 => proc 184.1 ms\n",
      "[112/144] frame_00111.png  read 38.5 | infer 38.7 | to_cpu 0.8 | post 149.2 | masks 4 | triangles 2 => proc 188.7 ms\n",
      "[113/144] frame_00112.png  read 36.3 | infer 33.9 | to_cpu 0.6 | post 163.2 | masks 3 | triangles 3 => proc 197.7 ms\n",
      "[114/144] frame_00113.png  read 39.6 | infer 34.5 | to_cpu 0.7 | post 154.7 | masks 3 | triangles 2 => proc 189.9 ms\n",
      "[115/144] frame_00114.png  read 36.6 | infer 32.6 | to_cpu 0.7 | post 151.5 | masks 3 | triangles 2 => proc 184.8 ms\n",
      "[116/144] frame_00115.png  read 36.2 | infer 44.5 | to_cpu 0.9 | post 143.0 | masks 4 | triangles 1 => proc 188.4 ms\n",
      "[117/144] frame_00116.png  read 38.9 | infer 43.0 | to_cpu 0.8 | post 131.0 | masks 4 | triangles 1 => proc 174.8 ms\n",
      "[118/144] frame_00117.png  read 36.6 | infer 38.3 | to_cpu 0.8 | post 119.0 | masks 5 | triangles 1 => proc 158.1 ms\n",
      "[119/144] frame_00118.png  read 41.6 | infer 32.6 | to_cpu 0.6 | post 114.4 | masks 4 | triangles 1 => proc 147.6 ms\n",
      "[120/144] frame_00119.png  read 36.6 | infer 41.9 | to_cpu 0.9 | post 114.8 | masks 5 | triangles 1 => proc 157.5 ms\n",
      "[121/144] frame_00120.png  read 37.1 | infer 36.3 | to_cpu 0.7 | post 117.9 | masks 4 | triangles 2 => proc 154.9 ms\n",
      "[122/144] frame_00121.png  read 145.1 | infer 41.4 | to_cpu 1.9 | post 306.2 | masks 4 | triangles 2 => proc 349.5 ms\n",
      "[123/144] frame_00122.png  read 38.8 | infer 46.9 | to_cpu 0.7 | post 76.1 | masks 4 | triangles 1 => proc 123.8 ms\n",
      "[124/144] frame_00123.png  read 37.9 | infer 332.3 | to_cpu 1.6 | post 42.5 | masks 6 | triangles 0 => proc 376.4 ms\n",
      "[125/144] frame_00124.png  read 37.7 | infer 44.1 | to_cpu 0.6 | post 130.3 | masks 4 | triangles 1 => proc 175.1 ms\n",
      "[126/144] frame_00125.png  read 39.5 | infer 34.4 | to_cpu 0.8 | post 177.8 | masks 5 | triangles 2 => proc 213.1 ms\n",
      "[127/144] frame_00126.png  read 37.4 | infer 37.9 | to_cpu 0.6 | post 146.0 | masks 3 | triangles 2 => proc 184.5 ms\n",
      "[128/144] frame_00127.png  read 38.5 | infer 35.0 | to_cpu 0.8 | post 145.8 | masks 4 | triangles 2 => proc 181.6 ms\n",
      "[129/144] frame_00128.png  read 36.5 | infer 53.5 | to_cpu 0.6 | post 140.6 | masks 2 | triangles 3 => proc 194.7 ms\n",
      "[130/144] frame_00129.png  read 38.0 | infer 31.1 | to_cpu 0.9 | post 0.0 | masks 4 | triangles 0 => proc 32.0 ms\n",
      "[131/144] frame_00130.png  read 37.3 | infer 82.4 | to_cpu 1.6 | post 96.4 | masks 11 | triangles 3 => proc 180.5 ms\n",
      "[132/144] frame_00131.png  read 37.9 | infer 57.0 | to_cpu 1.3 | post 105.0 | masks 9 | triangles 2 => proc 163.4 ms\n",
      "[133/144] frame_00132.png  read 41.3 | infer 47.1 | to_cpu 1.1 | post 129.6 | masks 8 | triangles 2 => proc 177.8 ms\n",
      "[134/144] frame_00133.png  read 54.3 | infer 41.5 | to_cpu 1.0 | post 133.6 | masks 7 | triangles 2 => proc 176.1 ms\n",
      "[135/144] frame_00134.png  read 37.2 | infer 39.9 | to_cpu 0.9 | post 134.3 | masks 6 | triangles 2 => proc 175.1 ms\n",
      "[136/144] frame_00135.png  read 41.8 | infer 47.4 | to_cpu 1.1 | post 158.7 | masks 6 | triangles 1 => proc 207.2 ms\n",
      "[137/144] frame_00136.png  read 37.7 | infer 48.0 | to_cpu 0.9 | post 156.2 | masks 5 | triangles 1 => proc 205.1 ms\n",
      "[138/144] frame_00137.png  read 39.7 | infer 44.7 | to_cpu 1.3 | post 202.9 | masks 7 | triangles 2 => proc 248.9 ms\n",
      "[139/144] frame_00138.png  read 38.2 | infer 56.0 | to_cpu 1.1 | post 168.2 | masks 5 | triangles 2 => proc 225.3 ms\n",
      "[140/144] frame_00139.png  read 21.7 | infer 26.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 26.6 ms\n",
      "[141/144] frame_00140.png  read 17.3 | infer 22.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.1 ms\n",
      "[142/144] frame_00141.png  read 17.1 | infer 24.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 24.5 ms\n",
      "[143/144] frame_00142.png  read 21.4 | infer 27.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 27.5 ms\n",
      "[144/144] frame_00143.png  read 17.3 | infer 26.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 26.1 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Renders ALL masks + triangles coloured by the mask sampled N px above the tip\n",
    "# + Scout lines (render only)\n",
    "# + Starburst lines from each triangle tip to Jake's lane point\n",
    "# + NEW: Lane-bearing selector: choose triangle whose signed degrees-from-vertical\n",
    "#       is closest to the lane's target (left=+10.7°, mid=+1.5°, right=-15.0°)\n",
    "\n",
    "import os, glob, sys, time, math\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "# SAVE HERE\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays4\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Triangle mask scan distance (N pixels above tip)\n",
    "SAMPLE_UP_PX        = 65\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "COLOR_WHITE  = (255, 255, 255)\n",
    "COLOR_CYAN   = (255, 255, 0)\n",
    "COLOR_BLACK  = (0, 0, 0)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None   # None → all frames\n",
    "RENDER_FIRST_N      = 150    # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# Jake lane points (you can switch which one by changing JAKE_POINT)\n",
    "# =======================\n",
    "LANE_LEFT   = (300, 1340)\n",
    "LANE_MID    = (490, 1340)\n",
    "LANE_RIGHT  = (680, 1340)\n",
    "JAKE_POINT  = LANE_RIGHT  # pick one: LANE_LEFT / LANE_MID / LANE_RIGHT\n",
    "\n",
    "# Lane target bearings (degrees from vertical; left=positive, right=negative)\n",
    "LANE_TARGET_DEG = {\n",
    "    \"left\":  -10.7,\n",
    "    \"mid\":   +1.5,\n",
    "    \"right\": +15.0,\n",
    "}\n",
    "\n",
    "def lane_name_from_point(p):\n",
    "    if p == LANE_LEFT:  return \"left\"\n",
    "    if p == LANE_MID:   return \"mid\"\n",
    "    if p == LANE_RIGHT: return \"right\"\n",
    "    # default to mid if unmatched\n",
    "    return \"mid\"\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "SAFE_GREEN = {9, 10}\n",
    "WARN_YELLOW = {2,3,4,5,8}\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "def classify_triangles_at_sample(tri_positions, masks_np, classes_np, frame_H, frame_W, sample_up=SAMPLE_UP_PX):\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "    colours = []\n",
    "    for (x, y) in tri_positions:\n",
    "        ys = max(0, y - sample_up)\n",
    "        mx = int(round(x * sx)); my = int(round(ys * sy))\n",
    "        if mx < 0: mx = 0\n",
    "        elif mx >= mw: mx = mw - 1\n",
    "        if my < 0: my = 0\n",
    "        elif my >= mh: my = mh - 1\n",
    "        cls_here = None\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            if m[my, mx] > 0.5:\n",
    "                cls_here = int(c); break\n",
    "        if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "            colours.append(COLOR_GREEN)\n",
    "        elif cls_here == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif cls_here in WARN_YELLOW:\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "    return colours\n",
    "\n",
    "def _colour_for_point(x, y, masks_np, classes_np, frame_H, frame_W):\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "    mx = int(round(x * sx)); my = int(round(y * sy))\n",
    "    if mx < 0: mx = 0\n",
    "    elif mx >= mw: mx = mw - 1\n",
    "    if my < 0: my = 0\n",
    "    elif my >= mh: my = mh - 1\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5:\n",
    "            cls_here = int(c); break\n",
    "    if (cls_here is None) or (cls_here in SAFE_GREEN): return COLOR_GREEN\n",
    "    if cls_here == 0: return COLOR_PINK\n",
    "    if cls_here in WARN_YELLOW: return COLOR_YELLOW\n",
    "    return COLOR_RED\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, COLOR_BLACK, 1, cv2.LINE_AA)\n",
    "\n",
    "def triangle_pts(x, y, size=TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    return np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "\n",
    "# ===== Bearing-based Jake triangle selection =====\n",
    "def signed_degrees_from_vertical(dx, dy):\n",
    "    \"\"\"\n",
    "    Signed angle (degrees) from vertical (upwards).\n",
    "    Conventions:\n",
    "      - left of Jake (dx < 0) => +degrees\n",
    "      - right of Jake (dx > 0) => -degrees\n",
    "      - straight ahead (vertical) => ~0°\n",
    "    Implementation: angle = -atan2(dx, -dy)  (since -dy>0 for triangles above)\n",
    "    \"\"\"\n",
    "    if dx == 0 and dy == 0:\n",
    "        return 0.0\n",
    "    return -math.degrees(math.atan2(dx, -dy))\n",
    "\n",
    "def select_triangle_by_bearing(tri_positions, jx, jy, target_deg, min_dy=6):\n",
    "    \"\"\"\n",
    "    Pick the triangle ahead of Jake (yt < jy - min_dy) whose signed degrees-from-vertical\n",
    "    is closest to the lane target.\n",
    "    Returns (best_index, best_deg, best_err) or (-1, None, None) if none ahead.\n",
    "    \"\"\"\n",
    "    best_i, best_deg, best_err = -1, None, None\n",
    "    for i, (xt, yt) in enumerate(tri_positions):\n",
    "        dx = xt - jx\n",
    "        dy = yt - jy\n",
    "        if dy >= -min_dy:  # requires triangle be above Jake by at least min_dy px\n",
    "            continue\n",
    "        deg = signed_degrees_from_vertical(dx, dy)\n",
    "        err = abs(deg - target_deg)\n",
    "        if (best_err is None) or (err < best_err):\n",
    "            best_i, best_deg, best_err = i, deg, err\n",
    "    return best_i, best_deg, best_err\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, coloured triangles,\n",
    "       scout lines, and starburst lines to Jake's lane point. Highlight the triangle\n",
    "       whose bearing is closest to the lane target.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    # masks\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Scout lines\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                col = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "                out[yy, x] = col\n",
    "\n",
    "    # Prepare lane target\n",
    "    lane_name = lane_name_from_point(JAKE_POINT)\n",
    "    target_deg = LANE_TARGET_DEG[lane_name]\n",
    "\n",
    "    # Select best triangle by bearing\n",
    "    xj, yj = JAKE_POINT\n",
    "    best_idx, best_deg, _ = select_triangle_by_bearing(tri_positions, xj, yj, target_deg, min_dy=6)\n",
    "\n",
    "    # Starburst lines + degree labels; highlight best\n",
    "    for idx, (xt, yt) in enumerate(tri_positions):\n",
    "        xt = max(0, min(W-1, int(xt)))\n",
    "        yt = max(0, min(H-1, int(yt)))\n",
    "\n",
    "        dx = xt - xj\n",
    "        dy = yt - yj\n",
    "        # degrees from vertical (signed as defined)\n",
    "        deg_signed = signed_degrees_from_vertical(dx, dy)\n",
    "        label = f\"{deg_signed:.1f}°\"\n",
    "\n",
    "        line_color = COLOR_CYAN if idx == best_idx else COLOR_WHITE\n",
    "        cv2.line(out, (xj, yj), (xt, yt), line_color, 2, cv2.LINE_AA)\n",
    "\n",
    "        mid_x = int((xj + xt) / 2)\n",
    "        mid_y = int((yj + yt) / 2)\n",
    "        cv2.putText(out, label, (mid_x, mid_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, label, (mid_x, mid_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Triangles (draw after lines)\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "\n",
    "    # Emphasize selected triangle + tag\n",
    "    if best_idx is not None and 0 <= best_idx < len(tri_positions):\n",
    "        xt, yt = tri_positions[best_idx]\n",
    "        pts = triangle_pts(int(xt), int(yt), size=TRI_SIZE_PX)\n",
    "        cv2.polylines(out, [pts.reshape(-1,1,2)], True, COLOR_CYAN, 3, cv2.LINE_AA)\n",
    "        tag = f\"JAKE_TRI ({lane_name}: target {target_deg:.1f}°)\"\n",
    "        cv2.putText(out, tag, (max(5, int(xt)-70), max(20, int(yt)-16)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, COLOR_BLACK, 2, cv2.LINE_AA)\n",
    "        cv2.putText(out, tag, (max(5, int(xt)-70), max(20, int(yt)-16)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03865d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
