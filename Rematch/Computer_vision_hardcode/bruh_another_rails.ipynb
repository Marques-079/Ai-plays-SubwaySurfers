{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inversed filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 01:56:26.815 Python[40138:28838161] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-08-05 01:56:26.815 Python[40138:28838161] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    # Crop to rail ROI\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # Vectorized color match\n",
    "    targets_bgr = np.array([(b,g,r) for r,g,b in target_colors_rgb], np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    # Connected-component filter\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out        : original + red tint on rails + neon-green on unfiltered rails\n",
    "      - rail_mask  : boolean mask of all rails\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        return img_bgr.copy(), np.zeros((H, W), bool)\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (original neon-green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # inverted mask = rails minus the filtered zones\n",
    "    inverted_mask = rail_mask & ~filtered_mask\n",
    "\n",
    "    # compose visualization\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    # red tint for rails\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "\n",
    "    # neon-green on the *inverse* region\n",
    "    out[inverted_mask] = (0, 255, 0)\n",
    "\n",
    "    return out, rail_mask\n",
    "\n",
    "# =======================\n",
    "# Main: run & step through\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _ = process_frame(img)\n",
    "\n",
    "        # show original | inverted neon-green\n",
    "        combo = np.hstack((img, vis))\n",
    "        cv2.imshow(\"Original (Left) | Inverted Rails (Right)\", combo)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ad26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 01:30:39.590 Python[38613:28807275] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-08-05 01:30:39.590 Python[38613:28807275] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# Centerline settings\n",
    "N_LINES           = 3\n",
    "MIN_GAP_FRAC      = 0.15      # min horizontal separation between lines (fraction of width)\n",
    "BAND_FRAC         = 0.04      # half-width (as fraction of image width) for local centroid band\n",
    "Y_TOP_FRAC        = 0.25      # start tracing from this fraction downwards (perspective)\n",
    "BOTTOM_FOCUS_FRAC = 0.60      # use bottom 60% to score column density\n",
    "THICKNESS         = 6\n",
    "PURPLE            = (255, 0, 255)  # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # RGB -> BGR\n",
    "    targets_bgr = np.array([(b,g,r) for r,g,b in target_colors_rgb], np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Column-peak picking (no SciPy)\n",
    "# =======================\n",
    "def pick_top_columns(mask: np.ndarray, n: int, min_gap: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Greedily pick up to n columns with highest vertical density, enforcing min_gap separation.\n",
    "    Uses bottom portion of the image to score columns (more reliable).\n",
    "    \"\"\"\n",
    "    H, W = mask.shape\n",
    "    y_start = int(H * (1 - BOTTOM_FOCUS_FRAC))\n",
    "    dens = mask[y_start:, :].sum(axis=0).astype(np.float32)\n",
    "\n",
    "    order = np.argsort(-dens)  # descending\n",
    "    chosen = []\n",
    "    for x in order:\n",
    "        if dens[x] <= 0:\n",
    "            break\n",
    "        if all(abs(int(x) - int(c)) >= min_gap for c in chosen):\n",
    "            chosen.append(int(x))\n",
    "            if len(chosen) == n:\n",
    "                break\n",
    "    chosen.sort()\n",
    "    return chosen\n",
    "\n",
    "def trace_centerline(mask: np.ndarray, x0: int, band_w: int,\n",
    "                     y_top: int, step: int = 4, smooth: float = 0.6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Follow dense green region from bottom to y_top by taking the centroid within [x0-band_w, x0+band_w].\n",
    "    Returns Nx1x2 array of int points for cv2.polylines.\n",
    "    \"\"\"\n",
    "    H, W = mask.shape\n",
    "    pts = []\n",
    "    x_prev = x0\n",
    "\n",
    "    for y in range(H-1, y_top-1, -step):\n",
    "        xl = max(0, x_prev - band_w)\n",
    "        xr = min(W, x_prev + band_w + 1)\n",
    "        row = mask[y, xl:xr]\n",
    "        if row.any():\n",
    "            xs = np.nonzero(row)[0] + xl\n",
    "            x_c = xs.mean()\n",
    "            x_prev = int(round(smooth * x_prev + (1.0 - smooth) * x_c))\n",
    "        # if no pixels, keep previous x_prev (continues straight)\n",
    "        pts.append([x_prev, y])\n",
    "\n",
    "    if len(pts) >= 2:\n",
    "        return np.array(pts, dtype=np.int32).reshape(-1, 1, 2)\n",
    "    return np.empty((0, 1, 2), dtype=np.int32)\n",
    "\n",
    "def draw_three_centerlines(out_img: np.ndarray, green_mask: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Find 3 dense green centerlines and draw them in purple on out_img in-place.\n",
    "    \"\"\"\n",
    "    H, W = green_mask.shape\n",
    "    min_gap = max(12, int(W * MIN_GAP_FRAC))\n",
    "    band_w  = max(6,  int(W * BAND_FRAC))\n",
    "    y_top   = int(H * Y_TOP_FRAC)\n",
    "\n",
    "    xs = pick_top_columns(green_mask, N_LINES, min_gap)\n",
    "    for x0 in xs:\n",
    "        poly = trace_centerline(green_mask, x0, band_w, y_top)\n",
    "        if poly.size > 0:\n",
    "            cv2.polylines(out_img, [poly], isClosed=False, color=PURPLE, thickness=THICKNESS, lineType=cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out        : original + rails red tint + inverted green + 3 purple centerlines\n",
    "      - rail_mask  : boolean mask of all rails\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        return img_bgr.copy(), np.zeros((H, W), bool)\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (original neon-green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # inverted mask = rails minus the filtered zones (this is your green background)\n",
    "    inverted_mask = rail_mask & ~filtered_mask\n",
    "\n",
    "    # compose visualization\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    # red tint for rails\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "\n",
    "    # neon-green on the *inverse* region\n",
    "    out[inverted_mask] = (0, 255, 0)\n",
    "\n",
    "    # --- draw 3 purple lines in the densest green regions (no overlap) ---\n",
    "    draw_three_centerlines(out, inverted_mask)\n",
    "\n",
    "    return out, rail_mask\n",
    "\n",
    "# =======================\n",
    "# Main: run & step through\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _ = process_frame(img)\n",
    "\n",
    "        combo = np.hstack((img, vis))\n",
    "        cv2.imshow(\"Original (Left) | Inverted Rails + 3 Purple Lines (Right)\", combo)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39728424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap straight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701f5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:03:22.587 Python[40446:28844547] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-08-05 02:03:22.587 Python[40446:28844547] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 206\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Wait for SPACE (next) or 'q' (quit)\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     key = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m & \u001b[32m0xFF\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[32m32\u001b[39m:        \u001b[38;5;66;03m# SPACE\u001b[39;00m\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)  # (K,3)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)                                  # (h,w,3)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]        # (h,w,K,3)\n",
    "    dist2 = np.sum(diff * diff, axis=-1)                                 # (h,w,K)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)   # (h,w)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green)\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a heatmap where high values (red) indicate regions with more *red* pixels than green,\n",
    "    and low values (blue) indicate fewer red pixels. Uses a large blur for local density.\n",
    "    \"\"\"\n",
    "    H, W = red_mask.shape\n",
    "    # convert to float densities then smooth\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    # normalize to 0..255 with zero centered around ~128 using symmetric scaling\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)  # blue -> red\n",
    "    return heat\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out_bgr     : original with red rail mask + neon green filtered regions\n",
    "      - rail_mask   : boolean rail mask\n",
    "      - heatmap_bgr : red-vs-green heatmap (blue=less red, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat  = red_vs_green_heatmap(empty, empty)\n",
    "        return img_bgr, empty, heat\n",
    "\n",
    "    # Union of rail masks\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # Apply fast color/size filter inside rails (these are the green regions)\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        target_colors_rgb=TARGET_COLORS_RGB,\n",
    "        tolerance=TOLERANCE,\n",
    "        min_region_size=MIN_REGION_SIZE,\n",
    "        min_region_height=MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails but not filtered\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Compose visualization\n",
    "    out = img_bgr.copy()\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)       # red tint for all rails\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "    out[filtered_mask] = (0, 255, 0)       # neon green for filtered regions\n",
    "\n",
    "    # Heatmap below: red-dominance vs green\n",
    "    heat = red_vs_green_heatmap(red_area, green_area)\n",
    "\n",
    "    return out, rail_mask, heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _rail, heat = process_frame(img)\n",
    "\n",
    "        # Top row: original | rails+filtered\n",
    "        top = np.hstack((img, vis))\n",
    "        # Bottom: heatmap stretched to same width\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "        cv2.imshow(\"Top: Original (Left) | Rails+Filtered (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # Wait for SPACE (next) or 'q' (quit)\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:        # SPACE\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap overlay with rail ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b61b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:14:05.905 Python[40926:28855408] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-08-05 02:14:05.905 Python[40926:28855408] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# ---- Heatmap→triangle picking params ----\n",
    "HEAT_BLUR_KSIZE     = 51            # local averaging\n",
    "RED_SCORE_THRESH    = 220           # 0..255; \"dark red\" threshold\n",
    "EXCLUDE_TOP_PX      = 400            # ignore top Y pixels\n",
    "EXCLUDE_BOTTOM_PX   = 120           # ignore bottom X pixels (from bottom up)\n",
    "MIN_DARK_RED_AREA   = 1200          # min area (px) for a dark-red blob\n",
    "TRI_SIZE_PX         = 18            # triangle size\n",
    "PURPLE              = (255, 0, 255) # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # RGB -> BGR targets\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green) + score map\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build a heatmap where high values (red) indicate regions with more *red* pixels than green,\n",
    "    and low values (blue) indicate fewer red pixels. Also returns the normalized score (0..255).\n",
    "    \"\"\"\n",
    "    # convert to float densities then smooth\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    # normalize to 0..255 with zero centered around ~128 using symmetric scaling\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)  # blue -> red\n",
    "    return heat, norm_u8\n",
    "\n",
    "# =======================\n",
    "# Draw a small triangle marker with apex at (x, y)\n",
    "# =======================\n",
    "def draw_purple_triangle(img: np.ndarray, x: int, y: int, size: int = TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([\n",
    "        [x, y],                    # apex\n",
    "        [x - size, y + h],         # base left\n",
    "        [x + size, y + h],         # base right\n",
    "    ], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, PURPLE)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out_bgr     : original with rail tint + green regions + purple triangles at rail ends\n",
    "      - rail_mask   : boolean rail mask\n",
    "      - heatmap_bgr : red-vs-green heatmap (blue=more green, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat, _ = red_vs_green_heatmap(empty, empty, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "        return img_bgr.copy(), empty, heat\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails minus the filtered zones\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Compose visualization\n",
    "    orig_marked = img_bgr.copy()             # triangles go on ORIGINAL\n",
    "    out = img_bgr.copy()                      # rails viz on the right panel\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "    out[filtered_mask] = (0, 255, 0)\n",
    "\n",
    "    # Heatmap + score (0..255, 255 = most red-dominant)\n",
    "    heat, score = red_vs_green_heatmap(red_area, green_area, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # ---- pick dark-red blobs within Y-range and mark their uppermost point ----\n",
    "    score_mask = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "\n",
    "    # limit vertical search band\n",
    "    top = max(0, EXCLUDE_TOP_PX)\n",
    "    bot = max(0, EXCLUDE_BOTTOM_PX)\n",
    "    score_mask[:top, :] = 0\n",
    "    if bot > 0:\n",
    "        score_mask[H - bot:, :] = 0\n",
    "\n",
    "    # remove tiny speckle\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "    score_mask = cv2.morphologyEx(score_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(score_mask, 8)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "\n",
    "        # uppermost y in this blob\n",
    "        mask_lbl = (labels == lbl)\n",
    "        ys, xs = np.where(mask_lbl)\n",
    "        y_min = int(ys.min())\n",
    "\n",
    "        # x at the top-most row for stability (mean of that row's xs)\n",
    "        xs_top = xs[ys == y_min]\n",
    "        x_mid = int(np.clip(int(np.round(xs_top.mean())), 0, W - 1))\n",
    "\n",
    "        # draw triangle on the ORIGINAL image\n",
    "        draw_purple_triangle(orig_marked, x_mid, y_min, TRI_SIZE_PX)\n",
    "\n",
    "    return (orig_marked, rail_mask, heat), out  # return both left(original+triangles) and right(viz), plus heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        (orig_with_tri, _rail, heat), rails_viz = process_frame(img)\n",
    "\n",
    "        # Top row: ORIGINAL(with triangles) | rails+filtered viz\n",
    "        top = np.hstack((orig_with_tri, rails_viz))\n",
    "\n",
    "        # Bottom: heatmap resized to match width\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "        cv2.imshow(\"Top: Original + Rail-End Triangles (Left) | Rails+Filtered (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working on %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba516b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:16:45.803 Python[41068:28858725] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2025-08-05 02:16:45.803 Python[41068:28858725] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0\n",
    "MIN_REGION_SIZE   = 30\n",
    "MIN_REGION_HEIGHT = 150\n",
    "\n",
    "# ---- Heatmap→triangle picking params ----\n",
    "HEAT_BLUR_KSIZE       = 51            # local averaging window\n",
    "RED_SCORE_THRESH      = 220           # 0..255; \"dark red\" threshold\n",
    "EXCLUDE_TOP_FRAC      = 0.40          # exclude top 10% of the image (before analysis)\n",
    "EXCLUDE_BOTTOM_FRAC   = 0.15          # exclude bottom 15% of the image (before analysis)\n",
    "MIN_DARK_RED_AREA     = 1200          # min area (px) for a dark-red blob\n",
    "TRI_SIZE_PX           = 18            # triangle size\n",
    "PURPLE                = (255, 0, 255) # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Boolean mask of rail pixels that (1) color-match within tolerance,\n",
    "    (2) lie inside rail_mask, and (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green) + score map\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Heatmap (JET) and normalized score 0..255 where higher means more *red* than green.\n",
    "    \"\"\"\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)\n",
    "    return heat, norm_u8\n",
    "\n",
    "# =======================\n",
    "# Draw a small triangle marker with apex at (x, y)\n",
    "# =======================\n",
    "def draw_purple_triangle(img: np.ndarray, x: int, y: int, size: int = TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([\n",
    "        [x, y],                    # apex\n",
    "        [x - size, y + h],         # base left\n",
    "        [x + size, y + h],         # base right\n",
    "    ], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, PURPLE)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - orig_with_tri : ORIGINAL image with purple triangles at uppermost points of dark-red heat regions\n",
    "      - rail_mask     : boolean rail mask\n",
    "      - heatmap_bgr   : red-vs-green heatmap (blue=more green, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat, _ = red_vs_green_heatmap(empty, empty, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "        return img_bgr.copy(), empty, heat\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails minus the filtered zones\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Heatmap + score (0..255, 255 = most red-dominant)\n",
    "    heat, score = red_vs_green_heatmap(red_area, green_area, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # ---- percentage-based exclusion applied BEFORE analysis for triangle plotting ----\n",
    "    top_rows = int(H * max(0.0, min(1.0, EXCLUDE_TOP_FRAC)))\n",
    "    bot_rows = int(H * max(0.0, min(1.0, EXCLUDE_BOTTOM_FRAC)))\n",
    "    score[:top_rows, :] = 0\n",
    "    if bot_rows > 0:\n",
    "        score[H - bot_rows:, :] = 0\n",
    "\n",
    "    # threshold dark-red regions\n",
    "    score_mask = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "\n",
    "    # denoise small speckle\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "    score_mask = cv2.morphologyEx(score_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # find blobs and mark the uppermost point per blob\n",
    "    orig_marked = img_bgr.copy()\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(score_mask, 8)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "        mask_lbl = (labels == lbl)\n",
    "        ys, xs = np.where(mask_lbl)\n",
    "        y_min = int(ys.min())\n",
    "        xs_top = xs[ys == y_min]\n",
    "        x_mid = int(np.clip(int(np.round(xs_top.mean())), 0, W - 1))\n",
    "        draw_purple_triangle(orig_marked, x_mid, y_min, TRI_SIZE_PX)\n",
    "\n",
    "    return orig_marked, rail_mask, heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        orig_with_tri, _rail, heat = process_frame(img)\n",
    "\n",
    "        # For reference, also render rails+filtered (right pane)\n",
    "        # (Optional: remove this block if you only want original + heatmap)\n",
    "        overlay = img.copy()\n",
    "        res_rails = model.predict(\n",
    "            img, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "            max_det=20, verbose=False, half=half\n",
    "        )[0]\n",
    "        if res_rails.masks is not None:\n",
    "            m = res_rails.masks.data\n",
    "            union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "            if union.shape != img.shape[:2]:\n",
    "                union = cv2.resize(union, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            rail_mask_viz = union.astype(bool)\n",
    "            overlay2 = img.copy()\n",
    "            overlay2[rail_mask_viz] = (0, 0, 255)\n",
    "            right = cv2.addWeighted(overlay2, ALPHA, img, 1 - ALPHA, 0)\n",
    "        else:\n",
    "            right = img.copy()\n",
    "\n",
    "        top = np.hstack((orig_with_tri, right))\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "\n",
    "        cv2.imshow(\"Top: Original + Purple Rail-End Triangles (Left) | Rails Viz (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b519f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
