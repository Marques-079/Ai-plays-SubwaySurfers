{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inversed filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    # Crop to rail ROI\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # Vectorized color match\n",
    "    targets_bgr = np.array([(b,g,r) for r,g,b in target_colors_rgb], np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    # Connected-component filter\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out        : original + red tint on rails + neon-green on unfiltered rails\n",
    "      - rail_mask  : boolean mask of all rails\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        return img_bgr.copy(), np.zeros((H, W), bool)\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (original neon-green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # inverted mask = rails minus the filtered zones\n",
    "    inverted_mask = rail_mask & ~filtered_mask\n",
    "\n",
    "    # compose visualization\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    # red tint for rails\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "\n",
    "    # neon-green on the *inverse* region\n",
    "    out[inverted_mask] = (0, 255, 0)\n",
    "\n",
    "    return out, rail_mask\n",
    "\n",
    "# =======================\n",
    "# Main: run & step through\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _ = process_frame(img)\n",
    "\n",
    "        # show original | inverted neon-green\n",
    "        combo = np.hstack((img, vis))\n",
    "        cv2.imshow(\"Original (Left) | Inverted Rails (Right)\", combo)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ad26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# Centerline settings\n",
    "N_LINES           = 3\n",
    "MIN_GAP_FRAC      = 0.15      # min horizontal separation between lines (fraction of width)\n",
    "BAND_FRAC         = 0.04      # half-width (as fraction of image width) for local centroid band\n",
    "Y_TOP_FRAC        = 0.25      # start tracing from this fraction downwards (perspective)\n",
    "BOTTOM_FOCUS_FRAC = 0.60      # use bottom 60% to score column density\n",
    "THICKNESS         = 6\n",
    "PURPLE            = (255, 0, 255)  # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # RGB -> BGR\n",
    "    targets_bgr = np.array([(b,g,r) for r,g,b in target_colors_rgb], np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Column-peak picking (no SciPy)\n",
    "# =======================\n",
    "def pick_top_columns(mask: np.ndarray, n: int, min_gap: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Greedily pick up to n columns with highest vertical density, enforcing min_gap separation.\n",
    "    Uses bottom portion of the image to score columns (more reliable).\n",
    "    \"\"\"\n",
    "    H, W = mask.shape\n",
    "    y_start = int(H * (1 - BOTTOM_FOCUS_FRAC))\n",
    "    dens = mask[y_start:, :].sum(axis=0).astype(np.float32)\n",
    "\n",
    "    order = np.argsort(-dens)  # descending\n",
    "    chosen = []\n",
    "    for x in order:\n",
    "        if dens[x] <= 0:\n",
    "            break\n",
    "        if all(abs(int(x) - int(c)) >= min_gap for c in chosen):\n",
    "            chosen.append(int(x))\n",
    "            if len(chosen) == n:\n",
    "                break\n",
    "    chosen.sort()\n",
    "    return chosen\n",
    "\n",
    "def trace_centerline(mask: np.ndarray, x0: int, band_w: int,\n",
    "                     y_top: int, step: int = 4, smooth: float = 0.6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Follow dense green region from bottom to y_top by taking the centroid within [x0-band_w, x0+band_w].\n",
    "    Returns Nx1x2 array of int points for cv2.polylines.\n",
    "    \"\"\"\n",
    "    H, W = mask.shape\n",
    "    pts = []\n",
    "    x_prev = x0\n",
    "\n",
    "    for y in range(H-1, y_top-1, -step):\n",
    "        xl = max(0, x_prev - band_w)\n",
    "        xr = min(W, x_prev + band_w + 1)\n",
    "        row = mask[y, xl:xr]\n",
    "        if row.any():\n",
    "            xs = np.nonzero(row)[0] + xl\n",
    "            x_c = xs.mean()\n",
    "            x_prev = int(round(smooth * x_prev + (1.0 - smooth) * x_c))\n",
    "        # if no pixels, keep previous x_prev (continues straight)\n",
    "        pts.append([x_prev, y])\n",
    "\n",
    "    if len(pts) >= 2:\n",
    "        return np.array(pts, dtype=np.int32).reshape(-1, 1, 2)\n",
    "    return np.empty((0, 1, 2), dtype=np.int32)\n",
    "\n",
    "def draw_three_centerlines(out_img: np.ndarray, green_mask: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Find 3 dense green centerlines and draw them in purple on out_img in-place.\n",
    "    \"\"\"\n",
    "    H, W = green_mask.shape\n",
    "    min_gap = max(12, int(W * MIN_GAP_FRAC))\n",
    "    band_w  = max(6,  int(W * BAND_FRAC))\n",
    "    y_top   = int(H * Y_TOP_FRAC)\n",
    "\n",
    "    xs = pick_top_columns(green_mask, N_LINES, min_gap)\n",
    "    for x0 in xs:\n",
    "        poly = trace_centerline(green_mask, x0, band_w, y_top)\n",
    "        if poly.size > 0:\n",
    "            cv2.polylines(out_img, [poly], isClosed=False, color=PURPLE, thickness=THICKNESS, lineType=cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out        : original + rails red tint + inverted green + 3 purple centerlines\n",
    "      - rail_mask  : boolean mask of all rails\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        return img_bgr.copy(), np.zeros((H, W), bool)\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (original neon-green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # inverted mask = rails minus the filtered zones (this is your green background)\n",
    "    inverted_mask = rail_mask & ~filtered_mask\n",
    "\n",
    "    # compose visualization\n",
    "    out = img_bgr.copy()\n",
    "\n",
    "    # red tint for rails\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "\n",
    "    # neon-green on the *inverse* region\n",
    "    out[inverted_mask] = (0, 255, 0)\n",
    "\n",
    "    # --- draw 3 purple lines in the densest green regions (no overlap) ---\n",
    "    draw_three_centerlines(out, inverted_mask)\n",
    "\n",
    "    return out, rail_mask\n",
    "\n",
    "# =======================\n",
    "# Main: run & step through\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _ = process_frame(img)\n",
    "\n",
    "        combo = np.hstack((img, vis))\n",
    "        cv2.imshow(\"Original (Left) | Inverted Rails + 3 Purple Lines (Right)\", combo)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39728424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap straight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)  # (K,3)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)                                  # (h,w,3)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]        # (h,w,K,3)\n",
    "    dist2 = np.sum(diff * diff, axis=-1)                                 # (h,w,K)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)   # (h,w)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green)\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a heatmap where high values (red) indicate regions with more *red* pixels than green,\n",
    "    and low values (blue) indicate fewer red pixels. Uses a large blur for local density.\n",
    "    \"\"\"\n",
    "    H, W = red_mask.shape\n",
    "    # convert to float densities then smooth\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    # normalize to 0..255 with zero centered around ~128 using symmetric scaling\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)  # blue -> red\n",
    "    return heat\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out_bgr     : original with red rail mask + neon green filtered regions\n",
    "      - rail_mask   : boolean rail mask\n",
    "      - heatmap_bgr : red-vs-green heatmap (blue=less red, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat  = red_vs_green_heatmap(empty, empty)\n",
    "        return img_bgr, empty, heat\n",
    "\n",
    "    # Union of rail masks\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # Apply fast color/size filter inside rails (these are the green regions)\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        target_colors_rgb=TARGET_COLORS_RGB,\n",
    "        tolerance=TOLERANCE,\n",
    "        min_region_size=MIN_REGION_SIZE,\n",
    "        min_region_height=MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails but not filtered\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Compose visualization\n",
    "    out = img_bgr.copy()\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)       # red tint for all rails\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "    out[filtered_mask] = (0, 255, 0)       # neon green for filtered regions\n",
    "\n",
    "    # Heatmap below: red-dominance vs green\n",
    "    heat = red_vs_green_heatmap(red_area, green_area)\n",
    "\n",
    "    return out, rail_mask, heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        vis, _rail, heat = process_frame(img)\n",
    "\n",
    "        # Top row: original | rails+filtered\n",
    "        top = np.hstack((img, vis))\n",
    "        # Bottom: heatmap stretched to same width\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "        cv2.imshow(\"Top: Original (Left) | Rails+Filtered (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # Wait for SPACE (next) or 'q' (quit)\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:        # SPACE\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap overlay with rail ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b61b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0      # color distance (BGR) – increase if too strict\n",
    "MIN_REGION_SIZE   = 30        # connected-component area in px\n",
    "MIN_REGION_HEIGHT = 150       # connected-component bbox height in px\n",
    "\n",
    "# ---- Heatmap→triangle picking params ----\n",
    "HEAT_BLUR_KSIZE     = 51            # local averaging\n",
    "RED_SCORE_THRESH    = 220           # 0..255; \"dark red\" threshold\n",
    "EXCLUDE_TOP_PX      = 400            # ignore top Y pixels\n",
    "EXCLUDE_BOTTOM_PX   = 120           # ignore bottom X pixels (from bottom up)\n",
    "MIN_DARK_RED_AREA   = 1200          # min area (px) for a dark-red blob\n",
    "TRI_SIZE_PX         = 18            # triangle size\n",
    "PURPLE              = (255, 0, 255) # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns boolean mask of rail pixels that:\n",
    "      (1) color-match any target color within tolerance, AND\n",
    "      (2) lie inside rail_mask, AND\n",
    "      (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # RGB -> BGR targets\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green) + score map\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build a heatmap where high values (red) indicate regions with more *red* pixels than green,\n",
    "    and low values (blue) indicate fewer red pixels. Also returns the normalized score (0..255).\n",
    "    \"\"\"\n",
    "    # convert to float densities then smooth\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    # normalize to 0..255 with zero centered around ~128 using symmetric scaling\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)  # blue -> red\n",
    "    return heat, norm_u8\n",
    "\n",
    "# =======================\n",
    "# Draw a small triangle marker with apex at (x, y)\n",
    "# =======================\n",
    "def draw_purple_triangle(img: np.ndarray, x: int, y: int, size: int = TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([\n",
    "        [x, y],                    # apex\n",
    "        [x - size, y + h],         # base left\n",
    "        [x + size, y + h],         # base right\n",
    "    ], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, PURPLE)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - out_bgr     : original with rail tint + green regions + purple triangles at rail ends\n",
    "      - rail_mask   : boolean rail mask\n",
    "      - heatmap_bgr : red-vs-green heatmap (blue=more green, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat, _ = red_vs_green_heatmap(empty, empty, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "        return img_bgr.copy(), empty, heat\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails minus the filtered zones\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Compose visualization\n",
    "    orig_marked = img_bgr.copy()             # triangles go on ORIGINAL\n",
    "    out = img_bgr.copy()                      # rails viz on the right panel\n",
    "    overlay = out.copy()\n",
    "    overlay[rail_mask] = (0, 0, 255)\n",
    "    out = cv2.addWeighted(overlay, ALPHA, out, 1 - ALPHA, 0)\n",
    "    out[filtered_mask] = (0, 255, 0)\n",
    "\n",
    "    # Heatmap + score (0..255, 255 = most red-dominant)\n",
    "    heat, score = red_vs_green_heatmap(red_area, green_area, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # ---- pick dark-red blobs within Y-range and mark their uppermost point ----\n",
    "    score_mask = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "\n",
    "    # limit vertical search band\n",
    "    top = max(0, EXCLUDE_TOP_PX)\n",
    "    bot = max(0, EXCLUDE_BOTTOM_PX)\n",
    "    score_mask[:top, :] = 0\n",
    "    if bot > 0:\n",
    "        score_mask[H - bot:, :] = 0\n",
    "\n",
    "    # remove tiny speckle\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "    score_mask = cv2.morphologyEx(score_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(score_mask, 8)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "\n",
    "        # uppermost y in this blob\n",
    "        mask_lbl = (labels == lbl)\n",
    "        ys, xs = np.where(mask_lbl)\n",
    "        y_min = int(ys.min())\n",
    "\n",
    "        # x at the top-most row for stability (mean of that row's xs)\n",
    "        xs_top = xs[ys == y_min]\n",
    "        x_mid = int(np.clip(int(np.round(xs_top.mean())), 0, W - 1))\n",
    "\n",
    "        # draw triangle on the ORIGINAL image\n",
    "        draw_purple_triangle(orig_marked, x_mid, y_min, TRI_SIZE_PX)\n",
    "\n",
    "    return (orig_marked, rail_mask, heat), out  # return both left(original+triangles) and right(viz), plus heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        (orig_with_tri, _rail, heat), rails_viz = process_frame(img)\n",
    "\n",
    "        # Top row: ORIGINAL(with triangles) | rails+filtered viz\n",
    "        top = np.hstack((orig_with_tri, rails_viz))\n",
    "\n",
    "        # Bottom: heatmap resized to match width\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "        cv2.imshow(\"Top: Original + Rail-End Triangles (Left) | Rails+Filtered (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEAK CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0\n",
    "MIN_REGION_SIZE   = 30\n",
    "MIN_REGION_HEIGHT = 150\n",
    "\n",
    "# ---- Heatmap→triangle picking params ----\n",
    "HEAT_BLUR_KSIZE       = 51            # local averaging window\n",
    "RED_SCORE_THRESH      = 220           # 0..255; \"dark red\" threshold\n",
    "EXCLUDE_TOP_FRAC      = 0.40          # exclude top 10% of the image (before analysis)\n",
    "EXCLUDE_BOTTOM_FRAC   = 0.15          # exclude bottom 15% of the image (before analysis)\n",
    "MIN_DARK_RED_AREA     = 1200          # min area (px) for a dark-red blob\n",
    "TRI_SIZE_PX           = 18            # triangle size\n",
    "PURPLE                = (255, 0, 255) # BGR\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warmup)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# FAST color+size filter (vectorized + ROI-cropped)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Boolean mask of rail pixels that (1) color-match within tolerance,\n",
    "    (2) lie inside rail_mask, and (3) pass connected-component size/height filters.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "# =======================\n",
    "# Heatmap (red-dominance vs green) + score map\n",
    "# =======================\n",
    "def red_vs_green_heatmap(red_mask: np.ndarray, green_mask: np.ndarray,\n",
    "                         blur_ksize: int = 51) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Heatmap (JET) and normalized score 0..255 where higher means more *red* than green.\n",
    "    \"\"\"\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    red_d   = cv2.blur(red_mask.astype(np.float32),   k)\n",
    "    green_d = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = red_d - green_d  # >0 => red-dominant, <0 => green-dominant\n",
    "\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)  # 0..1 with 0.5 at tie\n",
    "    norm_u8 = np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    heat = cv2.applyColorMap(norm_u8, cv2.COLORMAP_JET)\n",
    "    return heat, norm_u8\n",
    "\n",
    "# =======================\n",
    "# Draw a small triangle marker with apex at (x, y)\n",
    "# =======================\n",
    "def draw_purple_triangle(img: np.ndarray, x: int, y: int, size: int = TRI_SIZE_PX):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([\n",
    "        [x, y],                    # apex\n",
    "        [x - size, y + h],         # base left\n",
    "        [x + size, y + h],         # base right\n",
    "    ], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, PURPLE)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame pipeline\n",
    "# =======================\n",
    "def process_frame(img_bgr: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - orig_with_tri : ORIGINAL image with purple triangles at uppermost points of dark-red heat regions\n",
    "      - rail_mask     : boolean rail mask\n",
    "      - heatmap_bgr   : red-vs-green heatmap (blue=more green, red=more red)\n",
    "    \"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        empty = np.zeros((H, W), bool)\n",
    "        heat, _ = red_vs_green_heatmap(empty, empty, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "        return img_bgr.copy(), empty, heat\n",
    "\n",
    "    # union of rail segments\n",
    "    m = res.masks.data\n",
    "    union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    # compute filtered (green) mask\n",
    "    filtered_mask = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask,\n",
    "        TARGET_COLORS_RGB, TOLERANCE,\n",
    "        MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "\n",
    "    # red area = rails minus the filtered zones\n",
    "    red_area   = rail_mask & (~filtered_mask)\n",
    "    green_area = filtered_mask\n",
    "\n",
    "    # Heatmap + score (0..255, 255 = most red-dominant)\n",
    "    heat, score = red_vs_green_heatmap(red_area, green_area, blur_ksize=HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # ---- percentage-based exclusion applied BEFORE analysis for triangle plotting ----\n",
    "    top_rows = int(H * max(0.0, min(1.0, EXCLUDE_TOP_FRAC)))\n",
    "    bot_rows = int(H * max(0.0, min(1.0, EXCLUDE_BOTTOM_FRAC)))\n",
    "    score[:top_rows, :] = 0\n",
    "    if bot_rows > 0:\n",
    "        score[H - bot_rows:, :] = 0\n",
    "\n",
    "    # threshold dark-red regions\n",
    "    score_mask = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "\n",
    "    # denoise small speckle\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "    score_mask = cv2.morphologyEx(score_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # find blobs and mark the uppermost point per blob\n",
    "    orig_marked = img_bgr.copy()\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(score_mask, 8)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "        mask_lbl = (labels == lbl)\n",
    "        ys, xs = np.where(mask_lbl)\n",
    "        y_min = int(ys.min())\n",
    "        xs_top = xs[ys == y_min]\n",
    "        x_mid = int(np.clip(int(np.round(xs_top.mean())), 0, W - 1))\n",
    "        draw_purple_triangle(orig_marked, x_mid, y_min, TRI_SIZE_PX)\n",
    "\n",
    "    return orig_marked, rail_mask, heat\n",
    "\n",
    "# =======================\n",
    "# Run over a folder: show side-by-side with heatmap underneath\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        orig_with_tri, _rail, heat = process_frame(img)\n",
    "\n",
    "        # For reference, also render rails+filtered (right pane)\n",
    "        # (Optional: remove this block if you only want original + heatmap)\n",
    "        overlay = img.copy()\n",
    "        res_rails = model.predict(\n",
    "            img, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "            max_det=20, verbose=False, half=half\n",
    "        )[0]\n",
    "        if res_rails.masks is not None:\n",
    "            m = res_rails.masks.data\n",
    "            union = (m.sum(dim=0) > 0).float().cpu().numpy()\n",
    "            if union.shape != img.shape[:2]:\n",
    "                union = cv2.resize(union, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            rail_mask_viz = union.astype(bool)\n",
    "            overlay2 = img.copy()\n",
    "            overlay2[rail_mask_viz] = (0, 0, 255)\n",
    "            right = cv2.addWeighted(overlay2, ALPHA, img, 1 - ALPHA, 0)\n",
    "        else:\n",
    "            right = img.copy()\n",
    "\n",
    "        top = np.hstack((orig_with_tri, right))\n",
    "        heat_resized = cv2.resize(heat, (top.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        display_img = np.vstack((top, heat_resized))\n",
    "\n",
    "        cv2.imshow(\"Top: Original + Purple Rail-End Triangles (Left) | Rails Viz (Right)  |  Bottom: Red-vs-Green Heatmap\", display_img)\n",
    "\n",
    "        # SPACE → next, 'q' → quit\n",
    "        while True:\n",
    "            key = cv2.waitKey(0) & 0xFF\n",
    "            if key == 32:\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b519f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee1d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Benchmark rail-processing pipeline.\n",
    "Processes an entire folder of frames *without* any GUI,\n",
    "collects per-frame runtimes, and prints timing statistics.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # red tint on rail mask\n",
    "\n",
    "# Color/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0\n",
    "MIN_REGION_SIZE   = 30\n",
    "MIN_REGION_HEIGHT = 150\n",
    "\n",
    "# ---- Heatmap→triangle picking params ----\n",
    "HEAT_BLUR_KSIZE       = 51\n",
    "RED_SCORE_THRESH      = 220\n",
    "EXCLUDE_TOP_FRAC      = 0.40   # ignore top 40 % before triangle search\n",
    "EXCLUDE_BOTTOM_FRAC   = 0.15   # ignore bottom 15 %\n",
    "MIN_DARK_RED_AREA     = 1200\n",
    "TRI_SIZE_PX           = 18\n",
    "PURPLE                = (255, 0, 255)\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warm-up)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(\n",
    "    _dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "    verbose=False, half=half\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(\n",
    "    img_bgr: np.ndarray,\n",
    "    rail_mask: np.ndarray,\n",
    "    target_colors_rgb: list[tuple[int,int,int]],\n",
    "    tolerance: float = 30.0,\n",
    "    min_region_size: int = 50,\n",
    "    min_region_height: int = 150\n",
    ") -> np.ndarray:\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(rbg[2], rbg[1], rbg[0]) for rbg in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    color_mask_roi = np.any(dist2 <= (tolerance * tolerance), axis=-1)\n",
    "\n",
    "    combined_roi = mask_roi & color_mask_roi\n",
    "\n",
    "    comp_u8 = combined_roi.astype(np.uint8)\n",
    "    n_labels, labels, stats, _ = cv2.connectedComponentsWithStats(comp_u8, 8)\n",
    "\n",
    "    filtered_roi = np.zeros_like(combined_roi)\n",
    "    for lbl in range(1, n_labels):\n",
    "        area   = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        height = stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and height >= min_region_height:\n",
    "            filtered_roi[labels == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = filtered_roi\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask: np.ndarray,\n",
    "                       green_mask: np.ndarray,\n",
    "                       blur_ksize: int = 51) -> np.ndarray:\n",
    "    \"\"\"Return a 0-255 score map (higher = more red-dominant).\"\"\"\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)          # 0..1\n",
    "    return np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def process_frame(img_bgr: np.ndarray):\n",
    "    \"\"\"Process one frame; returns nothing (we only benchmark).\"\"\"\n",
    "    res = model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "        conf=CONF, iou=IOU, classes=[RAIL_ID],\n",
    "        max_det=20, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "    if res.masks is None:\n",
    "        return\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    union = (res.masks.data.sum(dim=0) > 0).float().cpu().numpy()\n",
    "    if union.shape != (H, W):\n",
    "        union = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    rail_mask = union.astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(\n",
    "        img_bgr, rail_mask, TARGET_COLORS_RGB,\n",
    "        TOLERANCE, MIN_REGION_SIZE, MIN_REGION_HEIGHT\n",
    "    )\n",
    "    red   = rail_mask & ~green\n",
    "\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # Exclusion before any potential triangle logic (kept for timing parity)\n",
    "    top_rows = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_rows = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_rows, :] = 0\n",
    "    if bot_rows:\n",
    "        score[H - bot_rows:, :] = 0\n",
    "\n",
    "    # Extract blobs, but we do NOT draw anything for the benchmark\n",
    "    mask = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    cv2.connectedComponentsWithStats(mask, 8)  # just to emulate same workload\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Benchmark loop\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(image_dir, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found in\", image_dir)\n",
    "        sys.exit(1)\n",
    "\n",
    "    per_frame = []\n",
    "    t0_all = time.perf_counter()\n",
    "\n",
    "    for p in paths[::5]:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        t0 = time.perf_counter()\n",
    "        process_frame(img)\n",
    "        per_frame.append(time.perf_counter() - t0)\n",
    "\n",
    "    total = time.perf_counter() - t0_all\n",
    "    per_frame_np = np.array(per_frame)\n",
    "\n",
    "    # Print timing statistics\n",
    "    print(f\"Frames processed  : {len(per_frame)}\")\n",
    "    print(f\"Total time (s)    : {total:8.3f}\")\n",
    "    print(f\"Average/frame (s) : {per_frame_np.mean():8.4f}\")\n",
    "    print(f\"Median/frame (s)  : {np.median(per_frame_np):8.4f}\")\n",
    "    print(f\"Min/frame (s)     : {per_frame_np.min():8.4f}\")\n",
    "    print(f\"Max/frame (s)     : {per_frame_np.max():8.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks.\n",
    "\n",
    "• Rails are still tinted red (right-hand panel) and used for the\n",
    "  heat-map + purple-triangle logic exactly as before.\n",
    "• Every other detected mask is over-laid on the *original* frame\n",
    "  (left-hand panel) with a distinct solid colour so you can see\n",
    "  what the network is segmenting besides the rails.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9                     # class-id for rails in the custom model\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40                  # red tint on rail mask (right pane)\n",
    "\n",
    "# Colour/size filter (RGB targets; converted to BGR internally)\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0\n",
    "MIN_REGION_SIZE   = 30\n",
    "MIN_REGION_HEIGHT = 150\n",
    "\n",
    "# ---- Heat-map → triangle params ----\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40   # ignore top   40 % before triangle search\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15   # ignore bottom 15 %\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)      # triangle colour (BGR)\n",
    "\n",
    "# Palette for **other** masks (cyclic if > len)\n",
    "OTHER_COLOURS = [\n",
    "    (  0,128,255),   # orange\n",
    "    (  0,255,255),   # yellow\n",
    "    ( 60,180, 75),   # green\n",
    "    (255,  0,127),   # pink\n",
    "    (255,255,  0),   # cyan\n",
    "    (128,  0,255),   # violet\n",
    "    (255,128,  0),   # sky blue\n",
    "]\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model (load, fuse, warm-up)\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# one dummy forward so first real frame is fast\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "              conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions (unchanged rail filter + heat-map)\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)  # RGB->BGR swap\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y],\n",
    "                    [x-size, y+h],\n",
    "                    [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Main per-frame pipeline\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:                         # no detections\n",
    "        return img_bgr.copy(), img_bgr.copy(), np.zeros_like(img_bgr)\n",
    "\n",
    "    masks = res.masks.data.cpu().numpy()          # (N, h, w)\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()    # fallback\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    # ---------------- Rails mask / green filter / heat-map ------------\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB,\n",
    "                                           TOLERANCE,\n",
    "                                           MIN_REGION_SIZE,\n",
    "                                           MIN_REGION_HEIGHT)\n",
    "    red = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # exclusion\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(dark, cv2.MORPH_OPEN,\n",
    "                            cv2.getStructuringElement(cv2.MORPH_RECT, (5,9)),\n",
    "                            iterations=1)\n",
    "\n",
    "    # ---------------- left panel: original + other-mask colours + triangles ----\n",
    "    left = img_bgr.copy()\n",
    "\n",
    "    # Overlay OTHER masks (everything that's NOT RAIL_ID)\n",
    "    overlay = left.copy()\n",
    "    colour_idx = 0\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        colour = OTHER_COLOURS[colour_idx % len(OTHER_COLOURS)]\n",
    "        overlay[mask_full] = colour\n",
    "        colour_idx += 1\n",
    "\n",
    "    # alpha-blend overlay on left frame\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # Purple triangles (after overlay so they stay visible)\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        if stats[lbl, cv2.CC_STAT_AREA] < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # ---------------- right panel: rails tinted red -------------------\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    if rail_mask.shape != right.shape[:2]:\n",
    "        rail_mask = rail_mask.astype(np.uint8)\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    # ---------------- heat-map visual ----------------\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1]+right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Drive over folder\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(folder, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        frame = cv2.imread(p);  t0 = time.time()\n",
    "        left, right, heat = process_frame(frame)\n",
    "        top = np.hstack((left, right))\n",
    "        canvas = np.vstack((top, heat))\n",
    "        cv2.imshow(\"Left: Original + coloured other-masks + triangles | \"\n",
    "                   \"Right: Rails tinted   |  Bottom: heat-map\", canvas)\n",
    "        print(f\"{os.path.basename(p):>20s}   proc {1000*(time.time()-t0):5.1f} ms\")\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key in (ord('q'), 27):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeabcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays.\n",
    "\n",
    "• Rails are still tinted red (right-hand panel) and used for the\n",
    "  heat-map + purple-triangle logic exactly as before.\n",
    "• Every other detected mask is over-laid on the *original* frame\n",
    "  with its true label and a consistent colour.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE         = 20.0\n",
    "MIN_REGION_SIZE   = 30\n",
    "MIN_REGION_HEIGHT = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0: (255, 255, 0), 1: (192, 192, 192), 2: (0, 128, 255), 3: (0, 255, 0),\n",
    "    4: (255, 0, 255), 5: (0, 255, 255), 6: (255, 128, 0), 7: (128, 0, 255),\n",
    "    8: (0, 0, 128), 10: (128, 128, 0), 11: (255, 255, 102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "              conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any(): return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb], dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        return img_bgr.copy(), img_bgr.copy(), np.zeros_like(img_bgr)\n",
    "\n",
    "    masks = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB,\n",
    "                                           TOLERANCE,\n",
    "                                           MIN_REGION_SIZE,\n",
    "                                           MIN_REGION_HEIGHT)\n",
    "    red = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(dark, cv2.MORPH_OPEN,\n",
    "                            cv2.getStructuringElement(cv2.MORPH_RECT, (5,9)),\n",
    "                            iterations=1)\n",
    "\n",
    "    left = img_bgr.copy()\n",
    "    overlay = left.copy()\n",
    "    for m, c in zip(masks, classes):\n",
    "        cid = int(c)\n",
    "        if cid == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "        label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "        colour = CLASS_COLOURS.get(cid, (255, 255, 255))\n",
    "        overlay[mask_full] = colour\n",
    "\n",
    "        ys, xs = np.where(mask_full)\n",
    "        if len(xs):\n",
    "            x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        if stats[lbl, cv2.CC_STAT_AREA] < MIN_DARK_RED_AREA:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    if rail_mask.shape != right.shape[:2]:\n",
    "        rail_mask = rail_mask.astype(np.uint8)\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1]+right.shape[1], H), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = f\"{home}/SubwaySurfers/train_screenshots\"\n",
    "    paths = sorted(glob.glob(os.path.join(folder, \"frame_*.jpg\")))\n",
    "    if not paths:\n",
    "        print(\"No frames found\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    for p in paths:\n",
    "        frame = cv2.imread(p);  t0 = time.time()\n",
    "        left, right, heat = process_frame(frame)\n",
    "        top = np.hstack((left, right))\n",
    "        canvas = np.vstack((top, heat))\n",
    "        cv2.imshow(\"Left: Labelled masks | Right: Rails tinted | Bottom: heat-map\", canvas)\n",
    "        print(f\"{os.path.basename(p):>20s}   proc {1000*(time.time()-t0):5.1f} ms\")\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key in (ord('q'), 27):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c4644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLUESTACKS dimensions uses mobile resolution vertical frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays.\n",
    "\n",
    "• Rails are tinted red (right) and used for the heat-map + purple-triangle.\n",
    "• Other masks are labelled and coloured on the original (left).\n",
    "• Bottom panel shows the heat-map.\n",
    "\n",
    "Controls:\n",
    "  SPACE: next frame   |   q / ESC: quit\n",
    "\n",
    "Notes:\n",
    "- Uses a responsive event loop (waitKey(1)) so keys register immediately.\n",
    "- Canvas is auto-rescaled to avoid huge window draw latency.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# UI / display constraints\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat-map (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600   # shrink canvas if wider than this to avoid huge blits\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Warm-up so the first real frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"Returns (left, right, heat_col) – all uint8 BGR images.\"\"\"\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        blank_heat = np.zeros((H, W), np.uint8)\n",
    "        return img_bgr.copy(), img_bgr.copy(), cv2.applyColorMap(blank_heat, cv2.COLORMAP_JET)\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # left: labels overlaid\n",
    "    left    = img_bgr.copy()\n",
    "    overlay = left.copy()\n",
    "    for m, c in zip(masks, classes):\n",
    "        cid = int(c)\n",
    "        if cid == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        label  = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "        colour = CLASS_COLOURS.get(cid, (255, 255, 255))\n",
    "        overlay[mask_full] = colour\n",
    "\n",
    "        ys, xs = np.where(mask_full)\n",
    "        if len(xs):\n",
    "            x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # purple triangle warnings\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        if stats[lbl, cv2.CC_STAT_AREA] < MIN_DARK_RED_AREA: continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # right: rails tinted\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    # bottom: heat map (width = left+right, height = H)\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    canvas = np.vstack((top, heat))\n",
    "    return canvas\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    i = 0\n",
    "    n = len(paths)\n",
    "    while i < n:\n",
    "        p = paths[i]\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            left, right, heat = process_frame(frame)\n",
    "            proc_ms = (time.perf_counter() - t0) * 1000.0\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "\n",
    "            # On-screen text for processing time\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] error on {os.path.basename(p)}: {e}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Responsive event loop: keep pumping events so SPACE is captured\n",
    "        while True:\n",
    "            cv2.imshow(WIN_NAME, canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Handle window close (on some platforms returns -1 repeatedly after close)\n",
    "            if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "            if key == 32:          # SPACE → next\n",
    "                i += 1\n",
    "                break\n",
    "            elif key in (ord('q'), 27):  # q or ESC\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "            # else: loop continues; window remains responsive\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Speed-test: run the full segmentation/overlay pipeline on every image in\n",
    "~/Documents/GitHub/Ai-plays-SubwaySurfers/frames and print a timing\n",
    "summary at the end.\n",
    "\n",
    "Changes in this version\n",
    "────────────────────────\n",
    "• The first WARMUP_FRAMES (default 10) are *executed* but **not timed**,\n",
    "  so model/kernel warm-up and disk cache effects don’t skew results.\n",
    "• Everything else is unchanged: no GUI overhead, concise summary.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time, statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ───────────────────────────────────────────────────────── Config ──\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES       = 10   # how many frames to skip from timing stats\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────── Device / model init ─\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "model.predict(\n",
    "    np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8),\n",
    "    task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, verbose=False, half=half\n",
    ")\n",
    "\n",
    "# ───────────────────────────── Helper processing functions ─\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    diff  = img_roi.astype(np.float32)[:, :, None, :] - targets_bgr[None, None]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    diff = (cv2.blur(red_mask.astype(np.float32), k) -\n",
    "            cv2.blur(green_mask.astype(np.float32), k))\n",
    "    norm = (diff / (2*(np.max(np.abs(diff))+1e-6)) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def process_frame(img_bgr):\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "    if res.masks is None:\n",
    "        return\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    rail_union = np.zeros(masks.shape[1:], bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # exclude top/bottom\n",
    "    score[:int(H*EXCLUDE_TOP_FRAC), :] = 0\n",
    "    score[H-int(H*EXCLUDE_BOTTOM_FRAC):, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        dst=dark, iterations=1\n",
    "    )\n",
    "    # outputs are not displayed; function exists for timing only.\n",
    "\n",
    "# ─────────────────────────────────────────────────────── Main test ──\n",
    "if __name__ == \"__main__\":\n",
    "    folder = (Path.home() / \"Documents\" / \"GitHub\" /\n",
    "              \"Ai-plays-SubwaySurfers\" / \"frames\")\n",
    "\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    times = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    for idx, p in enumerate(paths):\n",
    "        frame = cv2.imread(p)\n",
    "\n",
    "        if idx < WARMUP_FRAMES:\n",
    "            # Warm-up: run but don't time\n",
    "            process_frame(frame)\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        process_frame(frame)\n",
    "        times.append(time.perf_counter() - t0)\n",
    "        print(time.perf_counter() - t0)\n",
    "\n",
    "    total_time = time.perf_counter() - t_start\n",
    "    timed_frames = len(times)\n",
    "\n",
    "    # ─────────────────────────────── Summary ─\n",
    "    ms = [t * 1_000 for t in times]\n",
    "    if timed_frames == 0:\n",
    "        print(\"\\n[WARNING] fewer frames than WARMUP_FRAMES; nothing timed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "    print(f\"Total frames           : {len(paths)}\")\n",
    "    print(f\"Warm-up frames ignored : {WARMUP_FRAMES}\")\n",
    "    print(f\"Frames timed           : {timed_frames}\")\n",
    "    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "    print(f\"Average / frame        : {statistics.mean(ms):,.2f} ms\"\n",
    "          f\"  ({1_000/statistics.mean(ms):,.2f} FPS)\")\n",
    "    print(f\"Median                 : {statistics.median(ms):,.2f} ms\")\n",
    "    print(f\"Fastest                : {min(ms):,.2f} ms\")\n",
    "    print(f\"Slowest                : {max(ms):,.2f} ms\")\n",
    "    print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out smaller red regions to minimise misreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef260ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays.\n",
    "\n",
    "• Rails are tinted red (right) and used for the heat-map + purple-triangle.\n",
    "• Other masks are labelled and coloured on the original (left).\n",
    "• Bottom panel shows the heat-map.\n",
    "\n",
    "Controls:\n",
    "  SPACE: next frame   |   q / ESC: quit\n",
    "\n",
    "Loads images from:\n",
    "    ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\n",
    "Change requested:\n",
    "  Before plotting a purple triangle, require that the component's dark-red\n",
    "  area is at least 15% of the *total* dark-red area observed for the frame.\n",
    "  Implemented with negligible overhead and no other logic changes.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# New: minimum fraction of total dark-red area a blob must contribute\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "# UI / display constraints\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat-map (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warm up once so the first frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"Returns (left, right, heat_col) – all uint8 BGR images.\"\"\"\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        blank_heat = np.zeros((H, W), np.uint8)\n",
    "        return img_bgr.copy(), img_bgr.copy(), cv2.applyColorMap(blank_heat, cv2.COLORMAP_JET)\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # ================== New tiny-overhead filter ==================\n",
    "    # Require a component to be at least MIN_DARK_FRACTION of total dark area.\n",
    "    total_dark_area = int(dark.sum())\n",
    "    frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "    # =============================================================\n",
    "\n",
    "    # left: labels overlaid\n",
    "    left    = img_bgr.copy()\n",
    "    overlay = left.copy()\n",
    "    for m, c in zip(masks, classes):\n",
    "        cid = int(c)\n",
    "        if cid == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        label  = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "        colour = CLASS_COLOURS.get(cid, (255, 255, 255))\n",
    "        overlay[mask_full] = colour\n",
    "\n",
    "        ys, xs = np.where(mask_full)\n",
    "        if len(xs):\n",
    "            x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # purple triangle warnings\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # right: rails tinted\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    # bottom: heat map (width = left+right, height = H)\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    canvas = np.vstack((top, heat))\n",
    "    return canvas\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    i = 0\n",
    "    n = len(paths)\n",
    "    while i < n:\n",
    "        p = paths[i]\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            left, right, heat = process_frame(frame)\n",
    "            proc_ms = (time.perf_counter() - t0) * 1000.0\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "\n",
    "            # On-screen text for processing time\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] error on {os.path.basename(p)}: {e}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Responsive event loop\n",
    "        while True:\n",
    "            cv2.imshow(WIN_NAME, canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Handle window close\n",
    "            if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "            if key == 32:          # SPACE → next\n",
    "                i += 1\n",
    "                break\n",
    "            elif key in (ord('q'), 27):  # q or ESC\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7856ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays + Jake bbox.\n",
    "\n",
    "Additions (no double work, minimal overhead):\n",
    "• Runs RF-DETR once per frame to detect Jake (green rectangle).\n",
    "• Finds the YOLO mask with the largest overlap under Jake's bbox and\n",
    "  tints that object PINK so you can see what he's under.\n",
    "• Reuses the same YOLO segmentation output for everything (no duplicate inference).\n",
    "• Keeps the responsive SPACE-next UI and the purple-triangle logic (with 15% area filter).\n",
    "\n",
    "Controls:\n",
    "  SPACE: next frame   |   q / ESC: quit\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "# ── Enable CPU fallback before importing torch (for MPS gaps) ────────────────\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# ── Monkey-patch interpolate to disable antialias (avoids unsupported MPS op) ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "yolo_weights = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Purple-triangle extra filter: blob must be ≥ this fraction of total dark area\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "# UI / display constraints\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "JAKE_BOX_CLR    = (0, 255, 0)   # green bbox around Jake\n",
    "UNDER_TINT_BGR  = (255, 0, 255) # pink/magenta tint for object Jake is under\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "# YOLO device: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "\n",
    "# RF-DETR device: prefer MPS if present, else CPU (it throws NotImplementedError for some ops)\n",
    "det_device = \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Load models + warmup\n",
    "# =======================\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# Warm-up YOLO so first frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                       device=yolo_device, conf=CONF, iou=IOU,\n",
    "                       verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    canvas = np.vstack((top, heat))\n",
    "    return canvas\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"\n",
    "    One-stop processing:\n",
    "    • RF-DETR (Jake bbox)\n",
    "    • YOLO-seg once\n",
    "    • build left/right/heat\n",
    "    • tint object under Jake pink on the LEFT pane, draw Jake bbox\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    # RF-DETR: Jake bbox (use PIL once; reuse the same pixels)\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    try:\n",
    "        dets = jake_model.predict(pil_img, threshold=0.5, device=det_device)[0]\n",
    "    except NotImplementedError:\n",
    "        dets = jake_model.predict(pil_img, threshold=0.5, device=\"cpu\")[0]\n",
    "\n",
    "    jake_xyxy = None\n",
    "    if hasattr(dets, \"xyxy\") and len(dets.xyxy) > 0:\n",
    "        x1, y1, x2, y2 = dets.xyxy[0].astype(int).tolist()\n",
    "        # clamp to image\n",
    "        x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "        y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "        if x2 > x1 and y2 > y1:\n",
    "            jake_xyxy = (x1, y1, x2, y2)\n",
    "\n",
    "    # YOLO segmentation ONCE (use original BGR frame)\n",
    "    res = yolo_model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                             device=yolo_device, conf=CONF, iou=IOU,\n",
    "                             max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    if res.masks is None:\n",
    "        # nothing detected; return pass-through panes\n",
    "        left = img_bgr.copy()\n",
    "        right = img_bgr.copy()\n",
    "        heat_col = cv2.applyColorMap(np.zeros((H, W), np.uint8), cv2.COLORMAP_JET)\n",
    "        # draw Jake bbox even if no masks\n",
    "        if jake_xyxy:\n",
    "            x1, y1, x2, y2 = jake_xyxy\n",
    "            cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "        return left, right, heat_col\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    classes = classes.astype(int)\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    # Build rail mask union at low-res then resize once\n",
    "    rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "    rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    # Green/red rail segmentation\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # Exclude top/bottom bands\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # Total dark area + 15% fraction threshold (tiny overhead)\n",
    "    total_dark_area   = int(dark.sum())\n",
    "    frac_area_thresh  = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "    # LEFT PANE: labels overlaid + Jake tinting of object above him\n",
    "    left    = img_bgr.copy()\n",
    "    overlay = left.copy()\n",
    "\n",
    "    # First pass: overlay class masks (non-rail) with fixed colours + labels\n",
    "    # We'll also compute which mask Jake is under with low-res overlap (no per-mask resize).\n",
    "    best_idx, best_area, best_cid = None, 0, None\n",
    "    if jake_xyxy:\n",
    "        x1, y1, x2, y2 = jake_xyxy\n",
    "        sx, sy = w_m / W, h_m / H\n",
    "        mx1, mx2 = max(0, int(x1 * sx)), min(w_m, int(x2 * sx))\n",
    "        my1, my2 = max(0, int(y1 * sy)), min(h_m, int(y2 * sy))\n",
    "    else:\n",
    "        mx1 = mx2 = my1 = my2 = None\n",
    "\n",
    "    for idx, cid in enumerate(classes):\n",
    "        if cid != RAIL_ID:\n",
    "            m_low = masks[idx]  # low-res\n",
    "            # Draw class overlay (need full-res mask just for drawing)\n",
    "            mask_full = cv2.resize(m_low.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            colour = CLASS_COLOURS.get(int(cid), (255, 255, 255))\n",
    "            overlay[mask_full] = colour\n",
    "\n",
    "            # label position\n",
    "            ys, xs = np.where(mask_full)\n",
    "            if len(xs):\n",
    "                x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "                label = obstacle_classes.get(int(cid), f\"CLASS {int(cid)}\")\n",
    "                cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "            # If Jake exists, compute overlap at low-res without resizing every mask\n",
    "            if jake_xyxy and (mx2 > mx1) and (my2 > my1):\n",
    "                area = int(m_low[my1:my2, mx1:mx2].sum())\n",
    "                if area > best_area:\n",
    "                    best_idx, best_area, best_cid = idx, area, int(cid)\n",
    "\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # Purple-triangle warnings on LEFT (apply area thresholds, including 15%)\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top  = ys.min()\n",
    "        x_mid  = int(xs[ys == ys.min()].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # If Jake was detected, draw his bbox and tint the object he's under PINK on LEFT\n",
    "    if jake_xyxy:\n",
    "        x1, y1, x2, y2 = jake_xyxy\n",
    "        cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "        if best_idx is not None:\n",
    "            # Resize only the best mask once to full-res for the tint\n",
    "            best_mask_full = cv2.resize(masks[best_idx].astype(np.uint8), (W, H),\n",
    "                                        interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            pink_layer = left.copy()\n",
    "            pink_layer[best_mask_full] = UNDER_TINT_BGR\n",
    "            left = cv2.addWeighted(pink_layer, 0.35, left, 0.65, 0)\n",
    "\n",
    "    # RIGHT PANE: rails tinted (red) and green highlights\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    rails_tinted[rail_mask] = (0,0,255)          # red tint\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)                     # green for colour-matched\n",
    "\n",
    "    # BOTTOM: heat-map\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    i = 0\n",
    "    n = len(paths)\n",
    "    while i < n:\n",
    "        p = paths[i]\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            left, right, heat = process_frame(frame)\n",
    "            proc_ms = (time.perf_counter() - t0) * 1000.0\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "\n",
    "            # On-screen text for processing time\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] error on {os.path.basename(p)}: {e}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Responsive event loop: SPACE to advance, q/ESC to quit\n",
    "        while True:\n",
    "            cv2.imshow(WIN_NAME, canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                cv2.destroyAllWindows(); sys.exit(0)\n",
    "\n",
    "            if key == 32:          # SPACE → next\n",
    "                i += 1\n",
    "                break\n",
    "            elif key in (ord('q'), 27):  # q or ESC\n",
    "                cv2.destroyAllWindows(); sys.exit(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Speed-test the integrated RF-DETR (Jake bbox) + YOLO-seg pipeline.\n",
    "\n",
    "• Uses the same processing logic as the interactive viewer, but with NO GUI.\n",
    "• Runs through all images in: ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "• First 10 frames are executed as WARMUP (not timed).\n",
    "• Prints per-frame processing time (after warmup) and a summary at the end.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time, statistics\n",
    "# ── Enable CPU fallback before importing torch (for MPS gaps) ────────────────\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# ── Monkey-patch interpolate to disable antialias (avoids unsupported MPS op) ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# ─────────────────────────────────────────────────────────── Config ──\n",
    "home     = os.path.expanduser(\"~\")\n",
    "yolo_weights = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Purple-triangle extra filter: blob must be ≥ this fraction of total dark area\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "WARMUP_FRAMES       = 10\n",
    "\n",
    "# ─────────────────────────────────────────────── Device / model init ─\n",
    "# YOLO device: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "\n",
    "# RF-DETR device: prefer MPS if present, else CPU\n",
    "det_device = \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# Warm-up YOLO so first frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                       device=yolo_device, conf=CONF, iou=IOU,\n",
    "                       verbose=False, half=half)\n",
    "\n",
    "# ─────────────────────────────────────── Helper processing functions ─\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ─────────────────────────────────────────── Pipeline per frame ─\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"\n",
    "    Core pipeline used for timing:\n",
    "    • RF-DETR (Jake bbox) once\n",
    "    • YOLO-seg once\n",
    "    • rail green/red + heat computation\n",
    "    • purple triangle logic with 15% total dark-area filter\n",
    "    We do NOT build/display the 3-panel canvas here (no GUI).\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    # RF-DETR: Jake bbox (PIL once)\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    try:\n",
    "        dets = jake_model.predict(pil_img, threshold=0.5, device=det_device)[0]\n",
    "    except NotImplementedError:\n",
    "        dets = jake_model.predict(pil_img, threshold=0.5, device=\"cpu\")[0]\n",
    "\n",
    "    # YOLO segmentation ONCE (use original BGR frame)\n",
    "    res = yolo_model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                             device=yolo_device, conf=CONF, iou=IOU,\n",
    "                             max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    if res.masks is None:\n",
    "        return  # nothing detected; timing still counts\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    classes = classes.astype(int)\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    # Rail union\n",
    "    rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "    rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    # Green/red rails + heat\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # Exclude top/bottom bands\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # purple triangles (area checks incl. 15% of total dark area)\n",
    "    total_dark_area  = int(dark.sum())\n",
    "    frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    # (we don't draw here – timing only; this loop is kept for parity with viewer)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "            continue\n",
    "        # would draw triangle in viewer version\n",
    "\n",
    "# ──────────────────────────────────────────────────────── Main test ──\n",
    "if __name__ == \"__main__\":\n",
    "    folder = (Path.home() / \"Documents\" / \"GitHub\" /\n",
    "              \"Ai-plays-SubwaySurfers\" / \"frames\")\n",
    "\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    times = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    # Run with warmup\n",
    "    for idx, p in enumerate(paths):\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            continue\n",
    "\n",
    "        if idx < WARMUP_FRAMES:\n",
    "            # Warm-up: execute but don't time or print\n",
    "            process_frame(frame)\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        process_frame(frame)\n",
    "        dt = time.perf_counter() - t0\n",
    "        times.append(dt)\n",
    "\n",
    "        # Per-frame timing print (post-warmup only)\n",
    "        print(f\"{os.path.basename(p):>20s}  {dt*1000:7.2f} ms\")\n",
    "\n",
    "    total_time = time.perf_counter() - t_start\n",
    "    timed_frames = len(times)\n",
    "\n",
    "    # ─────────────────────────────── Summary ─\n",
    "    if timed_frames == 0:\n",
    "        print(\"\\n[WARNING] fewer frames than WARMUP_FRAMES; nothing timed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    ms = [t * 1_000 for t in times]\n",
    "    avg = statistics.mean(ms)\n",
    "    med = statistics.median(ms)\n",
    "    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "    print(f\"Total frames           : {len(paths)}\")\n",
    "    print(f\"Warm-up frames ignored : {WARMUP_FRAMES}\")\n",
    "    print(f\"Frames timed           : {timed_frames}\")\n",
    "    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "    print(f\"Average / frame        : {avg:,.2f} ms  ({1_000/avg:,.2f} FPS)\")\n",
    "    print(f\"Median                 : {med:,.2f} ms\")\n",
    "    print(f\"Fastest                : {min(ms):,.2f} ms\")\n",
    "    print(f\"Slowest                : {max(ms):,.2f} ms\")\n",
    "    print(\"───────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More gassss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76347d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Speed-test the integrated RF-DETR (Jake bbox) + YOLO-seg pipeline.\n",
    "\n",
    "• Same processing logic as the interactive viewer, but with NO GUI.\n",
    "• Scans:  ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "• First 10 frames are WARMUP (not timed).\n",
    "• Prints per-frame time (after warmup) and a summary at the end.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time, statistics\n",
    "# ── Enable CPU fallback before importing torch (for MPS gaps) ────────────────\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# ── Monkey-patch interpolate to disable antialias (avoids unsupported MPS op) ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# ─────────────────────────────────────────────────────────── Config ──\n",
    "home     = os.path.expanduser(\"~\")\n",
    "yolo_weights = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40  # (kept for parity; no GUI draw here)\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Purple-triangle extra filter: blob must be ≥ this fraction of total dark area\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "WARMUP_FRAMES       = 10\n",
    "\n",
    "# ─────────────────────────────────────────────── Device / model init ─\n",
    "# YOLO device: CUDA > MPS > CPU\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "\n",
    "# RF-DETR device: prefer MPS if present, else CPU\n",
    "det_device = \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "cv2.setUseOptimized(True)\n",
    "\n",
    "# ── Load models once ────────────────────────────────────────────────────────\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try:\n",
    "    yolo_model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# ── Precompute constants used every frame ───────────────────────────────────\n",
    "# target colors -> BGR float32, tolerance^2\n",
    "_TARGETS_BGR_F32 = np.array([(r, g, b)[::-1] for (r, g, b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "_TOL2 = float(TOLERANCE * TOLERANCE)\n",
    "# morphology kernel reused\n",
    "_MORPH_KERNEL = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9))\n",
    "\n",
    "# ── Warm-up both models so first timed frame isn't polluted ─────────────────\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "with torch.inference_mode():\n",
    "    _ = yolo_model.predict(\n",
    "        _dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "        device=yolo_device, conf=CONF, iou=IOU,\n",
    "        verbose=False, half=half\n",
    "    )\n",
    "# RF-DETR expects PIL; use tiny gray image to compile weights/graphs\n",
    "try:\n",
    "    _pil_dummy = Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n",
    "    _ = jake_model.predict(_pil_dummy, threshold=0.5, device=det_device)\n",
    "except NotImplementedError:\n",
    "    _ = jake_model.predict(_pil_dummy, threshold=0.5, device=\"cpu\")\n",
    "\n",
    "# ─────────────────────────────────────── Helper processing functions ─\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    \"\"\"\n",
    "    Color + size filter inside rail_mask.\n",
    "    Uses precomputed _TARGETS_BGR_F32 and _TOL2, avoids Python loops.\n",
    "    \"\"\"\n",
    "    # Quick reject\n",
    "    if rail_mask is None or not rail_mask.any():\n",
    "        return np.zeros(rail_mask.shape, dtype=bool)\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max() + 1\n",
    "    x0, x1 = xs.min(), xs.max() + 1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    # Compute min color distance to any target in a vectorized way\n",
    "    img_f = img_roi.astype(np.float32, copy=False)\n",
    "    diff  = img_f[:, :, None, :] - _TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.einsum(\"...c,...c->...\", diff, diff)  # sum over BGR\n",
    "    # dist2 shape: (h, w, n_targets) -> min across targets\n",
    "    if dist2.ndim == 3:\n",
    "        min_dist2 = dist2.min(axis=2)\n",
    "    else:\n",
    "        min_dist2 = dist2  # just in case\n",
    "\n",
    "    colour_hit = (min_dist2 <= _TOL2)\n",
    "    combined = colour_hit & mask_roi\n",
    "\n",
    "    if not combined.any():\n",
    "        out = np.zeros((H, W), dtype=bool)\n",
    "        return out\n",
    "\n",
    "    comp = combined.view(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    if n <= 1:\n",
    "        out = np.zeros((H, W), dtype=bool)\n",
    "        return out\n",
    "\n",
    "    good = np.zeros_like(comp, dtype=np.uint8)\n",
    "    # Vectorized filter for components (skip label 0)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = (areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT)\n",
    "    if not keep.any():\n",
    "        out = np.zeros((H, W), dtype=bool)\n",
    "        return out\n",
    "\n",
    "    # Paint kept labels\n",
    "    kept_labels = (np.where(keep)[0] + 1).tolist()\n",
    "    for lbl in kept_labels:\n",
    "        good[lbls == lbl] = 1\n",
    "\n",
    "    out = np.zeros((H, W), dtype=bool)\n",
    "    out[y0:y1, x0:x1] = good.astype(bool)\n",
    "    return out\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    # cv2.blur is an optimized box filter; keep it for large kernels\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32, copy=False), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32, copy=False), k)\n",
    "    diff = r - g\n",
    "    # Normalize to 0..255 without repeated max calls\n",
    "    amax = float(np.max(diff)) if np.max(diff) > -np.min(diff) else float(-np.min(diff))\n",
    "    amax = amax + 1e-6\n",
    "    norm = (diff / (2 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0.0, 255.0).astype(np.uint8)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def yolo_seg_once(img_bgr):\n",
    "    return yolo_model.predict(\n",
    "        img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "        device=yolo_device, conf=CONF, iou=IOU,\n",
    "        max_det=30, verbose=False, half=half\n",
    "    )[0]\n",
    "\n",
    "\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"\n",
    "    Core pipeline used for timing:\n",
    "    • RF-DETR (Jake bbox) once (kept for parity)\n",
    "    • YOLO-seg once\n",
    "    • rail green/red + heat computation\n",
    "    • purple triangle logic with 15% total dark-area filter\n",
    "    No GUI work here.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    # RF-DETR: Jake bbox (PIL). We call it to mirror the viewer cost,\n",
    "    # but don't consume results here.\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "    try:\n",
    "        _ = jake_model.predict(pil_img, threshold=0.5, device=det_device)[0]\n",
    "    except NotImplementedError:\n",
    "        _ = jake_model.predict(pil_img, threshold=0.5, device=\"cpu\")[0]\n",
    "\n",
    "    # YOLO segmentation ONCE\n",
    "    res = yolo_seg_once(img_bgr)\n",
    "    masks_obj = res.masks\n",
    "    if masks_obj is None:\n",
    "        return  # nothing detected; timing still counts\n",
    "\n",
    "    # Prefer boxes.cls (always present); fall back if needed\n",
    "    try:\n",
    "        classes = res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "    except Exception:\n",
    "        classes = (masks_obj.cls.detach().cpu().numpy().astype(int)\n",
    "                   if hasattr(masks_obj, \"cls\") else None)\n",
    "\n",
    "    masks = masks_obj.data.detach().cpu().numpy().astype(bool)  # (N, h_m, w_m)\n",
    "    if classes is None or masks.size == 0:\n",
    "        return\n",
    "\n",
    "    # Rail union without Python loop\n",
    "    rail_idx = (classes == RAIL_ID)\n",
    "    if not rail_idx.any():\n",
    "        return\n",
    "    rail_union_small = np.any(masks[rail_idx, :, :], axis=0)\n",
    "    rail_mask = cv2.resize(rail_union_small.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    if not rail_mask.any():\n",
    "        return\n",
    "\n",
    "    # Green/red rails + heat\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask)\n",
    "    red   = rail_mask & ~green\n",
    "\n",
    "    if not red.any() and not green.any():\n",
    "        return\n",
    "\n",
    "    score = red_vs_green_score(red, green)\n",
    "\n",
    "    # Exclude top/bottom bands (index math only, no copies)\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    if top_ex > 0:\n",
    "        score[:top_ex, :] = 0\n",
    "    if bot_ex > 0:\n",
    "        score[H - bot_ex:, :] = 0\n",
    "\n",
    "    # Threshold to \"dark\" and do a single morphology open\n",
    "    # (branchless threshold via cv2 works fine; >= RED_SCORE_THRESH)\n",
    "    _, dark = cv2.threshold(score, RED_SCORE_THRESH - 1, 255, cv2.THRESH_BINARY)\n",
    "    if not np.any(dark):\n",
    "        return\n",
    "    dark = cv2.morphologyEx(dark, cv2.MORPH_OPEN, _MORPH_KERNEL, iterations=1)\n",
    "\n",
    "    # purple triangles (area checks incl. 15% of total dark area)\n",
    "    total_dark_area = int(cv2.countNonZero(dark))\n",
    "    if total_dark_area == 0:\n",
    "        return\n",
    "\n",
    "    frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return\n",
    "\n",
    "    # Filter blobs via vector ops; we don't draw in this headless speed test\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    keep  = (areas >= MIN_DARK_RED_AREA) & (areas >= frac_area_thresh)\n",
    "    # If needed, we could short-circuit on keep.any(), but either way we’re done.\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────── Main test ──\n",
    "if __name__ == \"__main__\":\n",
    "    folder = (Path.home() / \"Documents\" / \"GitHub\" /\n",
    "              \"Ai-plays-SubwaySurfers\" / \"frames\")\n",
    "\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Prefer the \"frame_*.{jpg,png}\" pattern first; fallback to all images\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\"))\n",
    "        + glob.glob(str(folder / \"frame_*.png\"))\n",
    "        + glob.glob(str(folder / \"*.jpg\"))\n",
    "        + glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    times = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    # Run with warmup\n",
    "    for idx, p in enumerate(paths):\n",
    "        frame = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            continue\n",
    "\n",
    "        if idx < WARMUP_FRAMES:\n",
    "            process_frame(frame)\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        process_frame(frame)\n",
    "        dt = time.perf_counter() - t0\n",
    "        times.append(dt)\n",
    "\n",
    "        # Per-frame timing print (post-warmup only)\n",
    "        print(f\"{os.path.basename(p):>20s}  {dt*1000:7.2f} ms\")\n",
    "\n",
    "    total_time = time.perf_counter() - t_start\n",
    "    timed_frames = len(times)\n",
    "\n",
    "    # ─────────────────────────────── Summary ─\n",
    "    if timed_frames == 0:\n",
    "        print(\"\\n[WARNING] fewer frames than WARMUP_FRAMES; nothing timed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    ms = [t * 1_000 for t in times]\n",
    "    avg = statistics.mean(ms)\n",
    "    med = statistics.median(ms)\n",
    "    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "    print(f\"Total frames           : {len(paths)}\")\n",
    "    print(f\"Warm-up frames ignored : {WARMUP_FRAMES}\")\n",
    "    print(f\"Frames timed           : {timed_frames}\")\n",
    "    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "    print(f\"Average / frame        : {avg:,.2f} ms  ({1_000/avg:,.2f} FPS)\")\n",
    "    print(f\"Median                 : {med:,.2f} ms\")\n",
    "    print(f\"Fastest                : {min(ms):,.2f} ms\")\n",
    "    print(f\"Slowest                : {max(ms):,.2f} ms\")\n",
    "    print(\"───────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1bd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to spread load of CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Speed-test: run the full segmentation/overlay pipeline on every image in\n",
    "~/Documents/GitHub/Ai-plays-SubwaySurfers/frames and print a timing\n",
    "summary at the end.\n",
    "\n",
    "Changes in this version\n",
    "────────────────────────\n",
    "• The first WARMUP_FRAMES (default 10) are *executed* but **not timed**,\n",
    "  so model/kernel warm-up and disk cache effects don’t skew results.\n",
    "• Everything else is unchanged: no GUI overhead, concise summary.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time, statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ───────────────────────────────────────────────────────── Config ──\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES       = 10   # how many frames to skip from timing stats\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# ─────────────────────────────────────── Device / model init ─\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "model.predict(\n",
    "    np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8),\n",
    "    task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, verbose=False, half=half\n",
    ")\n",
    "\n",
    "# ───────────────────────────── Helper processing functions ─\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    diff  = img_roi.astype(np.float32)[:, :, None, :] - targets_bgr[None, None]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    diff = (cv2.blur(red_mask.astype(np.float32), k) -\n",
    "            cv2.blur(green_mask.astype(np.float32), k))\n",
    "    norm = (diff / (2*(np.max(np.abs(diff))+1e-6)) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def process_frame(img_bgr):\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "    if res.masks is None:\n",
    "        return\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    rail_union = np.zeros(masks.shape[1:], bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # exclude top/bottom\n",
    "    score[:int(H*EXCLUDE_TOP_FRAC), :] = 0\n",
    "    score[H-int(H*EXCLUDE_BOTTOM_FRAC):, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        dst=dark, iterations=1\n",
    "    )\n",
    "    # outputs are not displayed; function exists for timing only.\n",
    "\n",
    "# ─────────────────────────────────────────────────────── Main test ──\n",
    "if __name__ == \"__main__\":\n",
    "    folder = (Path.home() / \"Documents\" / \"GitHub\" /\n",
    "              \"Ai-plays-SubwaySurfers\" / \"frames\")\n",
    "\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    times = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    for idx, p in enumerate(paths):\n",
    "        frame = cv2.imread(p)\n",
    "\n",
    "        if idx < WARMUP_FRAMES:\n",
    "            # Warm-up: run but don't time\n",
    "            process_frame(frame)\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        process_frame(frame)\n",
    "        times.append(time.perf_counter() - t0)\n",
    "        print(time.perf_counter() - t0)\n",
    "\n",
    "    total_time = time.perf_counter() - t_start\n",
    "    timed_frames = len(times)\n",
    "\n",
    "    # ─────────────────────────────── Summary ─\n",
    "    ms = [t * 1_000 for t in times]\n",
    "    if timed_frames == 0:\n",
    "        print(\"\\n[WARNING] fewer frames than WARMUP_FRAMES; nothing timed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "    print(f\"Total frames           : {len(paths)}\")\n",
    "    print(f\"Warm-up frames ignored : {WARMUP_FRAMES}\")\n",
    "    print(f\"Frames timed           : {timed_frames}\")\n",
    "    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "    print(f\"Average / frame        : {statistics.mean(ms):,.2f} ms\"\n",
    "          f\"  ({1_000/statistics.mean(ms):,.2f} FPS)\")\n",
    "    print(f\"Median                 : {statistics.median(ms):,.2f} ms\")\n",
    "    print(f\"Fastest                : {min(ms):,.2f} ms\")\n",
    "    print(f\"Slowest                : {max(ms):,.2f} ms\")\n",
    "    print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Speed-test: run the full segmentation/overlay pipeline on every image in\n",
    "~/Documents/GitHub/Ai-plays-SubwaySurfers/frames, show each processed\n",
    "frame inline in Jupyter (stacked), and print a timing summary at the end.\n",
    "\n",
    "Warm-up frames are executed but not timed or displayed.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time, statistics\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Optional notebook display (safe fallback if not in Jupyter)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    from PIL import Image\n",
    "    _HAS_IPY = True\n",
    "except Exception:\n",
    "    _HAS_IPY = False\n",
    "\n",
    "# ───────────────────────────────────────────────────────── Config ──\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES       = 10   # how many frames to skip from timing stats\n",
    "\n",
    "# ─────────────────────────────────────── Device / model init ─\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "model.predict(\n",
    "    np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8),\n",
    "    task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "    conf=CONF, iou=IOU, verbose=False, half=half\n",
    ")\n",
    "\n",
    "# ───────────────────────────── Helper processing functions ─\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    diff  = img_roi.astype(np.float32)[:, :, None, :] - targets_bgr[None, None]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    diff = (cv2.blur(red_mask.astype(np.float32), k) -\n",
    "            cv2.blur(green_mask.astype(np.float32), k))\n",
    "    norm = (diff / (2*(np.max(np.abs(diff))+1e-6)) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def make_overlay_panel(img_bgr, rail_mask, green_mask, score_u8):\n",
    "    \"\"\"Build a side-by-side panel: original | overlays (red rail, green keep, score heat).\"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    # Color overlays\n",
    "    overlay = img_bgr.copy()\n",
    "    # red = rail minus green\n",
    "    red_mask = (rail_mask & ~green_mask)\n",
    "\n",
    "    # tint red & green\n",
    "    red_layer = np.zeros_like(img_bgr);    red_layer[:,:,2] = 255\n",
    "    green_layer = np.zeros_like(img_bgr);  green_layer[:,:,1] = 255\n",
    "\n",
    "    overlay = np.where(red_mask[...,None], cv2.addWeighted(overlay, 1-ALPHA, red_layer, ALPHA, 0), overlay)\n",
    "    overlay = np.where(green_mask[...,None], cv2.addWeighted(overlay, 1-ALPHA, green_layer, ALPHA, 0), overlay)\n",
    "\n",
    "    # score to heat (JET)\n",
    "    score_color = cv2.applyColorMap(score_u8, cv2.COLORMAP_JET)\n",
    "    score_vis = cv2.addWeighted(img_bgr, 0.55, score_color, 0.45, 0)\n",
    "\n",
    "    # stack: original | overlay | score\n",
    "    panel = np.concatenate([img_bgr, overlay, score_vis], axis=1)\n",
    "\n",
    "    # simple rulers/text\n",
    "    cv2.putText(panel, \"original\", (10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (32,32,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(panel, \"rail(red) / keep(green)\", (W+10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (32,255,32), 2, cv2.LINE_AA)\n",
    "    cv2.putText(panel, \"red-vs-green score\", (2*W+10, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,32), 2, cv2.LINE_AA)\n",
    "\n",
    "    return panel\n",
    "\n",
    "\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"Run segmentation + masks + score; return rail_mask, green_mask, score_u8, and a display panel.\"\"\"\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "    if res.masks is None:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        empty = np.zeros((H, W), dtype=bool)\n",
    "        score = np.zeros((H, W), dtype=np.uint8)\n",
    "        panel = make_overlay_panel(img_bgr, empty, empty, score)\n",
    "        return empty, empty, score, panel\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    rail_union = np.zeros(masks.shape[1:], bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                           interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # exclude top/bottom bands from consideration\n",
    "    score[:int(H*EXCLUDE_TOP_FRAC), :] = 0\n",
    "    score[H-int(H*EXCLUDE_BOTTOM_FRAC):, :] = 0\n",
    "\n",
    "    panel = make_overlay_panel(img_bgr, rail_mask, green, score)\n",
    "    return rail_mask, green, score, panel\n",
    "\n",
    "# ─────────────────────────────────────────────────────── Main test ──\n",
    "if __name__ == \"__main__\":\n",
    "    folder = (Path.home() / \"Documents\" / \"GitHub\" /\n",
    "              \"Ai-plays-SubwaySurfers\" / \"frames\")\n",
    "\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    times = []\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    for idx, p in enumerate(paths):\n",
    "        frame = cv2.imread(p)\n",
    "\n",
    "        if idx < WARMUP_FRAMES:\n",
    "            # Warm-up: run but don't time or display\n",
    "            _ = process_frame(frame)\n",
    "            continue\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        rail_mask, green_mask, score_u8, panel_bgr = process_frame(frame)\n",
    "        dt = time.perf_counter() - t0\n",
    "        times.append(dt)\n",
    "\n",
    "        # print timing line\n",
    "        print(f\"{idx:04d} | {Path(p).name} | {dt*1000:7.2f} ms\")\n",
    "\n",
    "        # show stacked image in Jupyter (if available)\n",
    "        if _HAS_IPY:\n",
    "            rgb = cv2.cvtColor(panel_bgr, cv2.COLOR_BGR2RGB)\n",
    "            display(Image.fromarray(rgb))\n",
    "\n",
    "    total_time = time.perf_counter() - t_start\n",
    "    timed_frames = len(times)\n",
    "\n",
    "    # ─────────────────────────────── Summary ─\n",
    "    ms = [t * 1_000 for t in times]\n",
    "    if timed_frames == 0:\n",
    "        print(\"\\n[WARNING] fewer frames than WARMUP_FRAMES; nothing timed.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "    print(f\"Total frames           : {len(paths)}\")\n",
    "    print(f\"Warm-up frames ignored : {WARMUP_FRAMES}\")\n",
    "    print(f\"Frames timed           : {timed_frames}\")\n",
    "    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "    print(f\"Average / frame        : {statistics.mean(ms):,.2f} ms\"\n",
    "          f\"  ({1_000/statistics.mean(ms):,.2f} FPS)\")\n",
    "    print(f\"Median                 : {statistics.median(ms):,.2f} ms\")\n",
    "    print(f\"Fastest                : {min(ms):,.2f} ms\")\n",
    "    print(f\"Slowest                : {max(ms):,.2f} ms\")\n",
    "    print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cf016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
