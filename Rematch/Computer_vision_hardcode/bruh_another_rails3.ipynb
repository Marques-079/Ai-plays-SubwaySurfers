{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUst running the detection and ground pathing. will need to think smart about how to do top of trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays.\n",
    "\n",
    "• Rails are tinted red (right) and used for the heat-map + purple-triangle.\n",
    "• Other masks are labelled and coloured on the original (left).\n",
    "• Bottom panel shows the heat-map.\n",
    "\n",
    "Controls:\n",
    "  SPACE: next frame   |   q / ESC: quit\n",
    "\n",
    "Loads images from:\n",
    "    ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\n",
    "Change requested:\n",
    "  Before plotting a purple triangle, require that the component's dark-red\n",
    "  area is at least 15% of the *total* dark-red area observed for the frame.\n",
    "  Implemented with negligible overhead and no other logic changes.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home     = os.path.expanduser(\"~\")\n",
    "weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID  = 9\n",
    "\n",
    "IMG_SIZE = 512\n",
    "CONF, IOU = 0.30, 0.45\n",
    "ALPHA    = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# New: minimum fraction of total dark-red area a blob must contribute\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "# UI / display constraints\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat-map (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# Optional: reduce OpenCV CPU thread contention with PyTorch\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# warm up once so the first frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0,\n",
    "                                   min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "def process_frame(img_bgr):\n",
    "    \"\"\"Returns (left, right, heat_col) – all uint8 BGR images.\"\"\"\n",
    "    res = model.predict(img_bgr, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if res.masks is None:\n",
    "        blank_heat = np.zeros((H, W), np.uint8)\n",
    "        return img_bgr.copy(), img_bgr.copy(), cv2.applyColorMap(blank_heat, cv2.COLORMAP_JET)\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()\n",
    "    classes = res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\") \\\n",
    "              else res.boxes.cls.cpu().numpy()\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(img_bgr, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # ================== New tiny-overhead filter ==================\n",
    "    # Require a component to be at least MIN_DARK_FRACTION of total dark area.\n",
    "    total_dark_area = int(dark.sum())\n",
    "    frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "    # =============================================================\n",
    "\n",
    "    # left: labels overlaid\n",
    "    left    = img_bgr.copy()\n",
    "    overlay = left.copy()\n",
    "    for m, c in zip(masks, classes):\n",
    "        cid = int(c)\n",
    "        if cid == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        label  = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "        colour = CLASS_COLOURS.get(cid, (255, 255, 255))\n",
    "        overlay[mask_full] = colour\n",
    "\n",
    "        ys, xs = np.where(mask_full)\n",
    "        if len(xs):\n",
    "            x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # purple triangle warnings\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # right: rails tinted\n",
    "    right = img_bgr.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    # bottom: heat map (width = left+right, height = H)\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    canvas = np.vstack((top, heat))\n",
    "    return canvas\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    i = 0\n",
    "    n = len(paths)\n",
    "    while i < n:\n",
    "        p = paths[i]\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            t0 = time.perf_counter()\n",
    "            left, right, heat = process_frame(frame)\n",
    "            proc_ms = (time.perf_counter() - t0) * 1000.0\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "\n",
    "            # On-screen text for processing time\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, f\"{os.path.basename(p)}  |  proc: {proc_ms:.1f} ms\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                        (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] error on {os.path.basename(p)}: {e}\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Responsive event loop\n",
    "        while True:\n",
    "            cv2.imshow(WIN_NAME, canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Handle window close\n",
    "            if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "            if key == 32:          # SPACE → next\n",
    "                i += 1\n",
    "                break\n",
    "            elif key in (ord('q'), 27):  # q or ESC\n",
    "                cv2.destroyAllWindows()\n",
    "                sys.exit(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a254fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays — high-utilization version.\n",
    "\n",
    "• Fully pipelined to use CPU + GPU:\n",
    "  - Frame prefetch (I/O)\n",
    "  - Batched YOLO inference on GPU/MPS (or CPU) with configurable batch size\n",
    "  - Parallel CPU postprocessing workers (triangles, labels, overlays, heat)\n",
    "  - UI thread only displays; compute continues in background\n",
    "• Logic unchanged: rails, heat-map, purple triangle (≥15% of total dark area), labels\n",
    "\n",
    "Controls:\n",
    "  SPACE: next frame   |   q / ESC: quit\n",
    "\n",
    "Loads images from:\n",
    "    ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, threading, queue\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config (tune these)\n",
    "# =======================\n",
    "home          = os.path.expanduser(\"~\")\n",
    "weights       = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "RAIL_ID       = 9\n",
    "\n",
    "IMG_SIZE      = 512\n",
    "CONF, IOU     = 0.30, 0.45\n",
    "ALPHA         = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Require blob to be at least this fraction of total dark-red area\n",
    "MIN_DARK_FRACTION   = 0.15  # 15%\n",
    "\n",
    "# UI\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat-map (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "\n",
    "# Pipeline sizing\n",
    "YOLO_BATCH      = 4    # try 2–8 depending on VRAM\n",
    "PREFETCH        = 32   # frames buffered from disk\n",
    "INFER_QUEUE     = 32   # frames waiting for inference\n",
    "POST_QUEUE      = 32   # inference outputs waiting for postproc\n",
    "POST_WORKERS    = max(2, (os.cpu_count() or 8) - 1)  # CPU worker threads\n",
    "\n",
    "# =======================\n",
    "# Class colours/names\n",
    "# =======================\n",
    "obstacle_classes = {\n",
    "    0: \"BOOTS\", 1: \"GREYTRAIN\", 2: \"HIGHBARRIER1\", 3: \"JUMP\", 4: \"LOWBARRIER1\",\n",
    "    5: \"LOWBARRIER2\", 6: \"ORANGETRAIN\", 7: \"PILLAR\", 8: \"RAMP\", 9: \"RAILS\",\n",
    "    10: \"SIDEWALK\", 11: \"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0: (255,255,0), 1: (192,192,192), 2: (0,128,255), 3: (0,255,0),\n",
    "    4: (255,0,255), 5: (0,255,255), 6: (255,128,0), 7: (128,0,255),\n",
    "    8: (0,0,128), 10: (128,128,0), 11: (255,255,102)\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Device / precision\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# Optional: reduce OpenCV thread contention with PyTorch (GPU-heavy workloads)\n",
    "try:\n",
    "    cv2.setNumThreads(1)  # our own thread pool does the parallelism\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warm up once so the first frame isn't laggy\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half)\n",
    "\n",
    "# =======================\n",
    "# Helpers (logic unchanged)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    \"\"\"Stack LEFT|RIGHT on top row and HEAT on bottom. Auto-fix minor width drift.\"\"\"\n",
    "    top = np.hstack((left, right))\n",
    "    th, tw = top.shape[:2]\n",
    "    hh, hw = heat.shape[:2]\n",
    "    if hw != tw:\n",
    "        # Auto-resize heat width to match top’s width (height stays heat’s height)\n",
    "        heat = cv2.resize(heat, (tw, hh), interpolation=cv2.INTER_LINEAR)\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Post-processing: build left/right/heat for one frame\n",
    "# (logic preserved; called from CPU worker threads)\n",
    "# =======================\n",
    "def build_panes_from_result(frame, res):\n",
    "    H, W = frame.shape[:2]\n",
    "\n",
    "    # ── NO DETECTIONS: left/right are W×H; heat must be (2W)×H to match top row\n",
    "    if res is None or res.masks is None:\n",
    "        left  = frame.copy()\n",
    "        right = frame.copy()\n",
    "        blank_heat = np.zeros((H, W), np.uint8)\n",
    "        heat_col = cv2.applyColorMap(blank_heat, cv2.COLORMAP_JET)\n",
    "        # *** FIX: make heat width = left.width + right.width = 2W ***\n",
    "        heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "        return left, right, heat_col\n",
    "\n",
    "    masks   = res.masks.data.cpu().numpy()   # (N, h_m, w_m)\n",
    "    classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "               else res.boxes.cls.cpu().numpy())\n",
    "    h_m, w_m = masks.shape[1:]\n",
    "\n",
    "    rail_union = np.zeros((h_m, w_m), bool)\n",
    "    for m, c in zip(masks, classes):\n",
    "        if int(c) == RAIL_ID:\n",
    "            rail_union |= m.astype(bool)\n",
    "\n",
    "    rail_mask = rail_union\n",
    "    if rail_mask.shape != (H, W):\n",
    "        rail_mask = cv2.resize(rail_mask.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                           TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                           MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "    red   = rail_mask & ~green\n",
    "    score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "    # Exclude top/bottom\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "    score[:top_ex, :] = 0\n",
    "    if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "\n",
    "    # 15% fraction filter\n",
    "    total_dark_area  = int(dark.sum())\n",
    "    frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "    # LEFT: labels overlaid\n",
    "    left    = frame.copy()\n",
    "    overlay = left.copy()\n",
    "    for m, c in zip(masks, classes):\n",
    "        cid = int(c)\n",
    "        if cid == RAIL_ID:\n",
    "            continue\n",
    "        mask_full = m\n",
    "        if mask_full.shape != (H, W):\n",
    "            mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "        label  = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "        colour = CLASS_COLOURS.get(cid, (255, 255, 255))\n",
    "        overlay[mask_full] = colour\n",
    "\n",
    "        ys, xs = np.where(mask_full)\n",
    "        if len(xs):\n",
    "            x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, label, (x_c - 40, y_c),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "    # Purple triangle warnings\n",
    "    n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "            continue\n",
    "        ys, xs = np.where(lbl_mat == lbl)\n",
    "        y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "        draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "    # RIGHT: rails tinted + green\n",
    "    right = frame.copy()\n",
    "    rails_tinted = right.copy()\n",
    "    rails_tinted[rail_mask] = (0,0,255)\n",
    "    right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "    right[green] = (0,255,0)\n",
    "\n",
    "    # HEAT\n",
    "    heat_col = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "    # width must equal left.width + right.width\n",
    "    heat_col = cv2.resize(heat_col, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return left, right, heat_col\n",
    "\n",
    "# =======================\n",
    "# Pipeline threads\n",
    "# =======================\n",
    "class Prefetcher(threading.Thread):\n",
    "    def __init__(self, paths, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.paths = paths\n",
    "        self.out_q = out_q\n",
    "\n",
    "    def run(self):\n",
    "        for idx, p in enumerate(self.paths):\n",
    "            img = cv2.imread(p)\n",
    "            self.out_q.put((idx, p, img))\n",
    "        self.out_q.put((None, None, None))  # sentinel\n",
    "\n",
    "class InferenceWorker(threading.Thread):\n",
    "    \"\"\"Batched YOLO inference on GPU/MPS/CPU\"\"\"\n",
    "    def __init__(self, in_q, out_q, batch=YOLO_BATCH):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q = in_q\n",
    "        self.out_q = out_q\n",
    "        self.batch = batch\n",
    "\n",
    "    def run(self):\n",
    "        pend = []\n",
    "        while True:\n",
    "            # Fill a batch\n",
    "            if not pend:\n",
    "                item = self.in_q.get()\n",
    "                if item[0] is None:\n",
    "                    break\n",
    "                pend.append(item)\n",
    "            while len(pend) < self.batch:\n",
    "                try:\n",
    "                    it = self.in_q.get_nowait()\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "                if it[0] is None:\n",
    "                    # push current batch then stop\n",
    "                    break\n",
    "                pend.append(it)\n",
    "\n",
    "            # Infer the current batch\n",
    "            idxs  = [i for i, _, _ in pend if i is not None]\n",
    "            paths = [p for i, p, _ in pend if i is not None]\n",
    "            frames= [f for i, _, f in pend if i is not None]\n",
    "\n",
    "            if frames:\n",
    "                res_list = model.predict(\n",
    "                    frames, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                    device=device, conf=CONF, iou=IOU, max_det=30,\n",
    "                    verbose=False, half=half\n",
    "                )\n",
    "\n",
    "                # Ensure GPU kernels complete before posting\n",
    "                try:\n",
    "                    if device == 0 and torch.cuda.is_available():\n",
    "                        torch.cuda.synchronize()\n",
    "                    elif device == \"mps\" and torch.backends.mps.is_available():\n",
    "                        torch.mps.synchronize()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                for idx, p, f, res in zip(idxs, paths, frames, res_list):\n",
    "                    self.out_q.put((idx, p, f, res))\n",
    "\n",
    "            # If last sentinel seen, break after draining\n",
    "            if pend and pend[-1][0] is None:\n",
    "                break\n",
    "\n",
    "            pend = []\n",
    "\n",
    "        self.out_q.put((None, None, None, None))  # sentinel\n",
    "\n",
    "class PostprocWorker(threading.Thread):\n",
    "    \"\"\"CPU worker: convert YOLO result to final canvas panes\"\"\"\n",
    "    def __init__(self, in_q, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q = in_q\n",
    "        self.out_q = out_q\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            idx, p, frame, res = self.in_q.get()\n",
    "            if idx is None:\n",
    "                break\n",
    "            # Build panes and assemble canvas\n",
    "            left, right, heat = build_panes_from_result(frame, res)\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "            self.out_q.put((idx, p, canvas))\n",
    "        self.out_q.put((None, None, None))\n",
    "\n",
    "# =======================\n",
    "# Main\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    # Queues\n",
    "    prefetch_q = queue.Queue(maxsize=PREFETCH)\n",
    "    post_q     = queue.Queue(maxsize=POST_QUEUE)\n",
    "    display_q  = queue.Queue(maxsize=POST_QUEUE)\n",
    "\n",
    "    # Threads: prefetch -> inference -> postproc (N workers)\n",
    "    pf = Prefetcher(paths, prefetch_q); pf.start()\n",
    "    inf = InferenceWorker(prefetch_q, post_q, batch=YOLO_BATCH); inf.start()\n",
    "\n",
    "    post_workers = []\n",
    "    for _ in range(POST_WORKERS):\n",
    "        w = PostprocWorker(post_q, display_q)\n",
    "        w.start(); post_workers.append(w)\n",
    "\n",
    "    # UI loop: show frames IN ORDER; compute runs in background\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "    next_to_show = 0\n",
    "    buffer = {}  # idx -> (path, canvas)\n",
    "\n",
    "    total = len(paths)\n",
    "    finished_workers = 0\n",
    "    expected_worker_sentinels = POST_WORKERS\n",
    "\n",
    "    while True:\n",
    "        # Drain display queue into buffer\n",
    "        try:\n",
    "            while True:\n",
    "                idx, p, canvas = display_q.get(timeout=0.02)\n",
    "                if idx is None:\n",
    "                    finished_workers += 1\n",
    "                    continue\n",
    "                buffer[idx] = (p, canvas)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "\n",
    "        # Present next frame in order when ready\n",
    "        if next_to_show in buffer:\n",
    "            p, canvas = buffer.pop(next_to_show)\n",
    "            # On-screen text: show index + filename\n",
    "            cv2.putText(canvas, f\"{next_to_show+1}/{total}  |  {os.path.basename(p)}\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, f\"{next_to_show+1}/{total}  |  {os.path.basename(p)}\",\n",
    "                        (12, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "            while True:\n",
    "                cv2.imshow(WIN_NAME, canvas)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    cv2.destroyAllWindows(); sys.exit(0)\n",
    "\n",
    "                if key == 32:  # SPACE → next\n",
    "                    next_to_show += 1\n",
    "                    break\n",
    "                elif key in (ord('q'), 27):  # q/ESC\n",
    "                    cv2.destroyAllWindows(); sys.exit(0)\n",
    "        else:\n",
    "            # If all workers finished and nothing left to show, exit\n",
    "            if finished_workers >= expected_worker_sentinels and next_to_show >= total:\n",
    "                break\n",
    "            time.sleep(0.005)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indivudal processing of frames and timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Visualise *all* segmentation masks with labelled overlays — single-frame, on-demand.\n",
    "\n",
    "WHAT THIS DOES\n",
    "• Waits for SPACE, then:\n",
    "  - loads exactly one frame from disk (no prefetch, no batching)\n",
    "  - runs YOLO segmentation on GPU/MPS (or CPU fallback)\n",
    "  - does all CPU post-processing (labels, rails, heat, purple-triangle ≥15%)\n",
    "  - prints honest end-to-end time for that frame and overlays it on the canvas\n",
    "• Uses all CPU cores (OpenCV + PyTorch thread hints) and your GPU/MPS.\n",
    "\n",
    "Controls:\n",
    "  SPACE: process next frame   |   q / ESC: quit\n",
    "\n",
    "Frames folder:\n",
    "    ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "ALPHA      = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15   # require ≥15% of total dark-red area\n",
    "\n",
    "# UI settings\n",
    "WIN_NAME      = \"SPACE: next | q/ESC: quit\"\n",
    "MAX_DISPLAY_W = 1600\n",
    "TEXT_CLR      = (255,255,255)\n",
    "\n",
    "# =======================\n",
    "# Maximize CPU/GPU utilization\n",
    "# =======================\n",
    "try:\n",
    "    torch.set_num_threads(os.cpu_count() or 1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Leave 1 core free for the OS/UI\n",
    "    OPENCV_THREADS = max(1, (os.cpu_count() or 1) - 1)\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Enable best GPU/matmul mode if CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# =======================\n",
    "# Device & model init\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Warmup once so the first real frame isn't penalized by lazy inits\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                  device=device, conf=CONF, iou=IOU,\n",
    "                  verbose=False, half=half)\n",
    "\n",
    "# =======================\n",
    "# Helper functions (logic unchanged)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    \"\"\"Stack LEFT|RIGHT on the top row and HEAT on the bottom; width-safe.\"\"\"\n",
    "    top = np.hstack((left, right))\n",
    "    th, tw = top.shape[:2]\n",
    "    hh, hw = heat.shape[:2]\n",
    "    if hw != tw or hh != th:\n",
    "        # Make heat exactly the same size as 'top'\n",
    "        heat = cv2.resize(heat, (tw, th), interpolation=cv2.INTER_LINEAR)\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    new_size = (int(w*scale), int(h*scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Single-frame processing (called after SPACE)\n",
    "# =======================\n",
    "def process_one_frame(frame):\n",
    "    \"\"\"\n",
    "    Process one frame end-to-end (inference + postproc) and return:\n",
    "      canvas (BGR), processing_time_ms\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # YOLO inference (single image)\n",
    "    res = model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "    # Ensure GPU/MPS kernels are done before timing postproc or reading tensors\n",
    "    if device == 0 and torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        torch.mps.synchronize()\n",
    "\n",
    "    H, W = frame.shape[:2]\n",
    "    if res.masks is None:\n",
    "        left  = frame.copy()\n",
    "        right = frame.copy()\n",
    "        blank = np.zeros((H, W), np.uint8)\n",
    "        heat  = cv2.applyColorMap(blank, cv2.COLORMAP_JET)\n",
    "        heat  = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        masks = res.masks.data.cpu().numpy()\n",
    "        classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                   else res.boxes.cls.cpu().numpy()).astype(int)\n",
    "\n",
    "        # Build rail mask\n",
    "        h_m, w_m = masks.shape[1:]\n",
    "        union = np.zeros((h_m, w_m), bool)\n",
    "        for m, c in zip(masks, classes):\n",
    "            if int(c) == RAIL_ID:\n",
    "                union |= m.astype(bool)\n",
    "        rail_mask = cv2.resize(union.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "        # Green/red + heat\n",
    "        green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                               TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                               MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "        red   = rail_mask & ~green\n",
    "        score = red_vs_green_score(red, green)\n",
    "\n",
    "        # Exclude bands\n",
    "        top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "        bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "        score[:top_ex, :] = 0\n",
    "        if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "        dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "        dark = cv2.morphologyEx(\n",
    "            dark, cv2.MORPH_OPEN,\n",
    "            cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "            iterations=1\n",
    "        )\n",
    "\n",
    "        total_dark = int(dark.sum())\n",
    "        frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "\n",
    "        # LEFT with labels\n",
    "        left = frame.copy()\n",
    "        overlay = left.copy()\n",
    "        CLASS_COLOURS = {\n",
    "            0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "            4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "            8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "        }\n",
    "        obstacle_classes = {\n",
    "            0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "            5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "            10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "        }\n",
    "        for m, c in zip(masks, classes):\n",
    "            cid = int(c)\n",
    "            if cid == RAIL_ID:\n",
    "                continue\n",
    "            mask_full = m\n",
    "            if mask_full.shape != (H, W):\n",
    "                mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            colour = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "            overlay[mask_full] = colour\n",
    "\n",
    "            ys, xs = np.where(mask_full)\n",
    "            if len(xs):\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                cv2.putText(overlay, label, (xc-40, yc),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(overlay, label, (xc-40, yc),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "        # Purple triangles subject to absolute+fraction area thresholds\n",
    "        n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "        for lbl in range(1, n_lbl):\n",
    "            area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "            if area < MIN_DARK_RED_AREA or area < frac_thresh:\n",
    "                continue\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "            draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "        # RIGHT rails + green\n",
    "        right = frame.copy()\n",
    "        tint = right.copy()\n",
    "        tint[rail_mask] = (0,0,255)\n",
    "        right = cv2.addWeighted(tint, ALPHA, right, 1-ALPHA, 0)\n",
    "        right[green] = (0,255,0)\n",
    "\n",
    "        # HEAT (width must be left+right)\n",
    "        heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "        heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Assemble + annotate\n",
    "    canvas = assemble_canvas(left, right, heat)\n",
    "    ms = (time.perf_counter() - t0) * 1000.0\n",
    "    tag = f\"{ms:.1f} ms\"\n",
    "    cv2.putText(canvas, tag, (12, 28),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(canvas, tag, (12, 28),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "    canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "    return canvas, ms\n",
    "\n",
    "# =======================\n",
    "# Main loop (no batching, no precompute)\n",
    "# =======================\n",
    "if __name__==\"__main__\":\n",
    "    if not frames_dir.is_dir():\n",
    "        print(f\"[ERROR] Frames folder not found: {frames_dir}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    paths = sorted(#glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "                   #glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "                   #glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "                   glob.glob(str(frames_dir/\"*.png\")))\n",
    "    if not paths:\n",
    "        print(\"[ERROR] No frame images found.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "    total = len(paths)\n",
    "    idx = 0\n",
    "\n",
    "    # Show an instruction screen\n",
    "    canvas0 = np.zeros((320, 960, 3), np.uint8)\n",
    "    cv2.putText(canvas0, \"Press SPACE to process next frame   |   q/ESC to quit\",\n",
    "                (20, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(WIN_NAME, canvas0)\n",
    "\n",
    "    while idx < total:\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key in (ord('q'), 27):\n",
    "            break\n",
    "        if key != 32:  # not SPACE\n",
    "            continue\n",
    "\n",
    "        p = paths[idx]\n",
    "        frame = cv2.imread(p)\n",
    "        if frame is None:\n",
    "            print(f\"[WARN] unreadable image: {p}\")\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        canvas, ms = process_one_frame(frame)\n",
    "        print(f\"[{idx+1}/{total}] {os.path.basename(p)}  →  {ms:.1f} ms\")\n",
    "        # filename overlay\n",
    "        cv2.putText(canvas, f\"{idx+1}/{total}  |  {os.path.basename(p)}\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, f\"{idx+1}/{total}  |  {os.path.basename(p)}\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(WIN_NAME, canvas)\n",
    "        idx += 1\n",
    "\n",
    "        # If window closed manually, exit cleanly\n",
    "        if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50194a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First 20 frames, ready for ground logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Notebook inline visualiser — single-frame processing with *granular* timing.\n",
    "\n",
    "What it does\n",
    "• Processes the first N frames (no prefetch, no batching, no UI window).\n",
    "• For each frame:\n",
    "  - YOLO segmentation on GPU/MPS (or CPU)\n",
    "  - CPU post-processing (labels, rails, heat, purple-triangle ≥15%)\n",
    "  - Prints a compact per-frame timing breakdown (read, infer, sync, to_cpu, post, assemble)\n",
    "  - 'proc_total' = inference + sync + to_cpu + post + assemble (no display/printing)\n",
    "• Shows the image inline (if in JN/VSCode). Display/printing are excluded from timings.\n",
    "\n",
    "Frames folder:\n",
    "    ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Inline display (not part of timing)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    from PIL import Image\n",
    "    _HAS_IPY = True\n",
    "except Exception:\n",
    "    _HAS_IPY = False\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "SHOW_FIRST_N = 20  # process only first N frames; set None to do all\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "ALPHA      = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15   # ≥15% of total dark-red area\n",
    "\n",
    "# Display overlay settings\n",
    "MAX_DISPLAY_W = 1200\n",
    "TEXT_CLR      = (255,255,255)\n",
    "\n",
    "# =======================\n",
    "# Maximize CPU/GPU utilization (thread hints)\n",
    "# =======================\n",
    "try:\n",
    "    torch.set_num_threads(os.cpu_count() or 1)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Leave 1 core for OS/UI\n",
    "    OPENCV_THREADS = max(1, (os.cpu_count() or 1) - 1)\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# CUDA backend optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# =======================\n",
    "# Device & model init\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "model = YOLO(weights)\n",
    "try:\n",
    "    model.fuse()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Warmup to avoid first-frame penalty (not timed)\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                  device=device, conf=CONF, iou=IOU,\n",
    "                  verbose=False, half=half)\n",
    "\n",
    "# =======================\n",
    "# Helpers (logic unchanged)\n",
    "# =======================\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb],\n",
    "                           dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    \"\"\"Stack LEFT|RIGHT on top row and HEAT on bottom; exact width match.\"\"\"\n",
    "    top = np.hstack((left, right))\n",
    "    th, tw = top.shape[:2]\n",
    "    hh, hw = heat.shape[:2]\n",
    "    if hw != tw or hh != th:\n",
    "        heat = cv2.resize(heat, (tw, th), interpolation=cv2.INTER_LINEAR)\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Per-frame processing with segmented timing\n",
    "# =======================\n",
    "def process_one_frame_with_timers(frame):\n",
    "    \"\"\"\n",
    "    Returns (canvas_bgr, timings_dict)\n",
    "\n",
    "    timings_dict fields (ms):\n",
    "      infer, sync, to_cpu, post, assemble, proc_total\n",
    "    \"\"\"\n",
    "    t0_infer = time.perf_counter()\n",
    "\n",
    "    # YOLO inference (single image)\n",
    "    res = model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                        device=device, conf=CONF, iou=IOU,\n",
    "                        max_det=30, verbose=False, half=half)[0]\n",
    "    t1_infer = time.perf_counter()\n",
    "\n",
    "    # Ensure GPU/MPS kernels complete before using results\n",
    "    t0_sync = time.perf_counter()\n",
    "    try:\n",
    "        if device == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "            torch.mps.synchronize()\n",
    "    except Exception:\n",
    "        pass\n",
    "    t1_sync = time.perf_counter()\n",
    "\n",
    "    # Move tensors to CPU (measured separately)\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    if res.masks is None:\n",
    "        masks_np, classes_np = None, None\n",
    "    else:\n",
    "        masks_np = res.masks.data.cpu().numpy()\n",
    "        classes_np = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                      else res.boxes.cls.cpu().numpy()).astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "\n",
    "    # Post-processing\n",
    "    t0_post = time.perf_counter()\n",
    "    H, W = frame.shape[:2]\n",
    "    if masks_np is None:\n",
    "        left  = frame.copy()\n",
    "        right = frame.copy()\n",
    "        blank = np.zeros((H, W), np.uint8)\n",
    "        heat  = cv2.applyColorMap(blank, cv2.COLORMAP_JET)\n",
    "        heat  = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                           interpolation=cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        masks   = masks_np\n",
    "        classes = classes_np\n",
    "\n",
    "        # Rail union at model mask res → upsample to frame res\n",
    "        h_m, w_m = masks.shape[1:]\n",
    "        union = np.zeros((h_m, w_m), bool)\n",
    "        for m, c in zip(masks, classes):\n",
    "            if int(c) == RAIL_ID:\n",
    "                union |= m.astype(bool)\n",
    "        rail_mask = cv2.resize(union.astype(np.uint8), (W, H),\n",
    "                               interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "        # Green/red + heat precursor\n",
    "        green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                               TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                               MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "        red   = rail_mask & ~green\n",
    "        score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "        # Exclude top/bottom bands\n",
    "        top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "        bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "        score[:top_ex, :] = 0\n",
    "        if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "        dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "        dark = cv2.morphologyEx(\n",
    "            dark, cv2.MORPH_OPEN,\n",
    "            cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "            iterations=1\n",
    "        )\n",
    "\n",
    "        total_dark  = int(dark.sum())\n",
    "        frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "\n",
    "        # LEFT with labels\n",
    "        left    = frame.copy()\n",
    "        overlay = left.copy()\n",
    "        CLASS_COLOURS = {\n",
    "            0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "            4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "            8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "        }\n",
    "        obstacle_classes = {\n",
    "            0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "            5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "            10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "        }\n",
    "        for m, c in zip(masks, classes):\n",
    "            cid = int(c)\n",
    "            if cid == RAIL_ID:\n",
    "                continue\n",
    "            mask_full = m\n",
    "            if mask_full.shape != (H, W):\n",
    "                mask_full = cv2.resize(mask_full.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            overlay[mask_full] = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "\n",
    "            ys, xs = np.where(mask_full)\n",
    "            if len(xs):\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                cv2.putText(overlay, label, (xc-40, yc),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(overlay, label, (xc-40, yc),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "        # Purple triangles: absolute + fraction thresholds\n",
    "        n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "        for lbl in range(1, n_lbl):\n",
    "            area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "            if area < MIN_DARK_RED_AREA or area < frac_thresh:\n",
    "                continue\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            y_top, x_mid = ys.min(), int(xs[ys == ys.min()].mean())\n",
    "            draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "        # RIGHT rails + green\n",
    "        right = frame.copy()\n",
    "        tint = right.copy()\n",
    "        tint[rail_mask] = (0,0,255)\n",
    "        right = cv2.addWeighted(tint, ALPHA, right, 1-ALPHA, 0)\n",
    "        right[green] = (0,255,0)\n",
    "\n",
    "        # HEAT (width = left + right)\n",
    "        heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "        heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                          interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "\n",
    "    # Assemble + downscale\n",
    "    t0_assemble = time.perf_counter()\n",
    "    canvas = assemble_canvas(left, right, heat)\n",
    "    canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "    t1_assemble = time.perf_counter()\n",
    "\n",
    "    # Compose timing dict\n",
    "    infer_ms    = (t1_infer    - t0_infer)    * 1000.0\n",
    "    sync_ms     = (t1_sync     - t0_sync)     * 1000.0\n",
    "    to_cpu_ms   = (t1_to_cpu   - t0_to_cpu)   * 1000.0\n",
    "    post_ms     = (t1_post     - t0_post)     * 1000.0\n",
    "    assemble_ms = (t1_assemble - t0_assemble) * 1000.0\n",
    "    proc_total  = infer_ms + sync_ms + to_cpu_ms + post_ms + assemble_ms\n",
    "\n",
    "    timings = {\n",
    "        \"infer\": infer_ms,\n",
    "        \"sync\": sync_ms,\n",
    "        \"to_cpu\": to_cpu_ms,\n",
    "        \"post\": post_ms,\n",
    "        \"assemble\": assemble_ms,\n",
    "        \"proc_total\": proc_total\n",
    "    }\n",
    "    return canvas, timings\n",
    "\n",
    "def tiny_line(idx, total, fname, read_ms, t):\n",
    "    # Compact, fixed-order timing print\n",
    "    return (f\"[{idx}/{total}] {fname}  \"\n",
    "            f\"read {read_ms:.1f} | infer {t['infer']:.1f} | sync {t['sync']:.1f} | \"\n",
    "            f\"to_cpu {t['to_cpu']:.1f} | post {t['post']:.1f} | asm {t['assemble']:.1f} \"\n",
    "            f\"=> proc {t['proc_total']:.1f} ms\")\n",
    "\n",
    "# =======================\n",
    "# Main (first N frames, inline prints)\n",
    "# =======================\n",
    "if __name__==\"__main__\":\n",
    "    if not frames_dir.is_dir():\n",
    "        print(f\"[ERROR] Frames folder not found: {frames_dir}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Gather frames once (I/O not included in processing timing)\n",
    "    paths_raw = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths_raw))\n",
    "    if not paths:\n",
    "        print(\"[ERROR] No frame images found.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    total = len(paths) if SHOW_FIRST_N is None else min(SHOW_FIRST_N, len(paths))\n",
    "\n",
    "    for i in range(total):\n",
    "        p = paths[i]\n",
    "\n",
    "        # --- disk I/O timing (for context only) ---\n",
    "        t0_read = time.perf_counter()\n",
    "        frame = cv2.imread(p)\n",
    "        t1_read = time.perf_counter()\n",
    "        read_ms = (t1_read - t0_read) * 1000.0\n",
    "        if frame is None:\n",
    "            print(f\"[warn] unreadable: {os.path.basename(p)}\")\n",
    "            continue\n",
    "\n",
    "        # --- processing timing (excludes any display/printing) ---\n",
    "        canvas, t = process_one_frame_with_timers(frame)\n",
    "\n",
    "        # Overlay *processing* time on image (proc_total)\n",
    "        tag = f\"{t['proc_total']:.1f} ms\"\n",
    "        cv2.putText(canvas, tag, (12, 28),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, tag, (12, 28),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, f\"{i+1}/{total} | {os.path.basename(p)}\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, f\"{i+1}/{total} | {os.path.basename(p)}\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        # --- display + tiny print (not timed) ---\n",
    "        if _HAS_IPY:\n",
    "            rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "            display(Image.fromarray(rgb))\n",
    "            print(tiny_line(i+1, total, os.path.basename(p), read_ms, t))\n",
    "        else:\n",
    "            print(tiny_line(i+1, total, os.path.basename(p), read_ms, t))\n",
    "\n",
    "    if _HAS_IPY and total < len(paths):\n",
    "        print(f\"\\nDone. Shown first {total} of {len(paths)} frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e82d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Pure inference timing on images in ~/Documents/GitHub/Ai-plays-SubwaySurfers/frames\n",
    "\n",
    "What we time:\n",
    "  start = just before model.predict(...)\n",
    "  end   = after GPU/MPS sync completes\n",
    "  => inference-only latency per image\n",
    "\n",
    "No post-processing, no display. Small prints.\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, statistics\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---------- Config ----------\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "WARMUP     = 5   # number of frames to run but not include in stats\n",
    "\n",
    "# ---------- Device & perf hints ----------\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# Use all CPU threads for any host-side work (tiny effect here, but harmless)\n",
    "try: torch.set_num_threads(os.cpu_count() or 1)\n",
    "except Exception: pass\n",
    "\n",
    "# ---------- Load model ----------\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup once (not timed)\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                  device=device, conf=CONF, iou=IOU,\n",
    "                  verbose=False, half=half)\n",
    "\n",
    "# ---------- Collect frames ----------\n",
    "if not frames_dir.is_dir():\n",
    "    print(f\"[ERROR] Frames folder not found: {frames_dir}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "paths = sorted(\n",
    "    set(glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\")))\n",
    ")\n",
    "if not paths:\n",
    "    print(\"[ERROR] No frame images found.\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---------- Run inference timing ----------\n",
    "times_ms = []\n",
    "n_total = len(paths)\n",
    "\n",
    "for i, p in enumerate(paths, start=1):\n",
    "    img = cv2.imread(p)\n",
    "    if img is None:\n",
    "        print(f\"[warn] unreadable: {os.path.basename(p)}\")\n",
    "        continue\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    res = model.predict(\n",
    "        img,\n",
    "        task=\"segment\",\n",
    "        imgsz=IMG_SIZE,\n",
    "        device=device,\n",
    "        conf=CONF,\n",
    "        iou=IOU,\n",
    "        max_det=MAX_DET,\n",
    "        verbose=False,\n",
    "        half=half\n",
    "    )\n",
    "    # Ensure kernels complete before stopping the clock\n",
    "    try:\n",
    "        if device == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elif device == \"mps\" and torch.backends.mps.is_available():\n",
    "            torch.mps.synchronize()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    t_ms = (time.perf_counter() - t0) * 1000.0\n",
    "    # Skip counting the first WARMUP frames in stats, but still show a print\n",
    "    show_idx = i\n",
    "    if i > WARMUP:\n",
    "        times_ms.append(t_ms)\n",
    "        print(f\"[{show_idx}/{n_total}] {os.path.basename(p)} → {t_ms:.1f} ms\")\n",
    "    else:\n",
    "        print(f\"[warmup {i}/{WARMUP}] {os.path.basename(p)} → {t_ms:.1f} ms\")\n",
    "\n",
    "# ---------- Summary ----------\n",
    "if times_ms:\n",
    "    avg = statistics.mean(times_ms)\n",
    "    med = statistics.median(times_ms)\n",
    "    print(\"\\n--- Inference-only summary (warmup skipped) ---\")\n",
    "    print(f\"Frames timed : {len(times_ms)}\")\n",
    "    print(f\"Average      : {avg:.1f} ms  ({1000.0/avg:.2f} FPS)\")\n",
    "    print(f\"Median       : {med:.1f} ms\")\n",
    "    print(f\"Fastest      : {min(times_ms):.1f} ms\")\n",
    "    print(f\"Slowest      : {max(times_ms):.1f} ms\")\n",
    "else:\n",
    "    print(\"\\nNo frames were timed (all were warmup or unreadable).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddfcb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
