{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperfast External printing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e94d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "High-utilization visualiser: pipelined prefetch → inference → postproc.\n",
    "\n",
    "• Keeps GPU/MPS saturated: inference on frame N+1 overlaps CPU postproc on N\n",
    "• Runs YOLO on GPU/MPS, RF-DETR on CPU by default (detected automatically)\n",
    "• Preserves all logic: labels, Jake bbox, under-mask tint, triangle, heat\n",
    "• Warmup frames executed but not timed; summary at exit\n",
    "• SPACE to advance; q/ESC to quit\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, statistics, threading, queue\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# ── disable antialias to avoid unsupported MPS op on some ops ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home          = os.path.expanduser(\"~\")\n",
    "yolo_weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights  = f\"{home}/downloads/weightsjake.pt\"\n",
    "RAIL_ID       = 9\n",
    "IMG_SIZE      = 512\n",
    "CONF, IOU     = 0.30, 0.45\n",
    "ALPHA         = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "\n",
    "WIN_NAME        = \"Left: labels | Right: rails | Bottom: heat (SPACE=next, q=quit)\"\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "JAKE_BOX_CLR    = (0, 255, 0)\n",
    "UNDER_TINT_BGR  = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES   = 10\n",
    "PREFETCH        = 24    # bigger prefetch helps saturate I/O\n",
    "INFER_QUEUE     = 4     # frames in-flight through inference\n",
    "\n",
    "# CPU threading (OpenCV)\n",
    "OPENCV_THREADS  = max(1, (os.cpu_count() or 8) - 1)\n",
    "\n",
    "# =======================\n",
    "# Device selection\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "    DET_ON_CPU = True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "    DET_ON_CPU = True  # keep RF-DETR on CPU to overlap with MPS\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "    DET_ON_CPU = False  # both CPU; still benefits from pipeline\n",
    "\n",
    "# =======================\n",
    "# Models\n",
    "# =======================\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# warmup YOLO\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                       device=yolo_device, conf=CONF, iou=IOU,\n",
    "                       verbose=False, half=half)\n",
    "\n",
    "# OpenCV threads\n",
    "try:\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Utils\n",
    "# =======================\n",
    "obstacle_classes = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb], dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w: return img\n",
    "    scale = max_w / float(w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Inference worker (persistent)\n",
    "# =======================\n",
    "class InferenceWorker(threading.Thread):\n",
    "    \"\"\"\n",
    "    Consumes frames from in_q, runs YOLO (GPU/MPS) + RF-DETR (CPU optionally),\n",
    "    returns (path, frame, masks(np), classes(np), jake_xyxy or None)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_q, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q  = in_q\n",
    "        self.out_q = out_q\n",
    "        self.stop  = False\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop:\n",
    "            item = self.in_q.get()\n",
    "            if item is None:  # sentinel\n",
    "                self.out_q.put(None)\n",
    "                break\n",
    "            path, frame = item\n",
    "            H, W = frame.shape[:2]\n",
    "\n",
    "            # Run YOLO on device\n",
    "            res = yolo_model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                                     device=yolo_device, conf=CONF, iou=IOU,\n",
    "                                     max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "            # RF-DETR on CPU to overlap with GPU (unless both CPU)\n",
    "            jake_xyxy = None\n",
    "            try:\n",
    "                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                det_dev = \"cpu\" if DET_ON_CPU else (\"cpu\" if yolo_device != 0 else 0)\n",
    "                dets = jake_model.predict(pil_img, threshold=0.5, device=det_dev)[0]\n",
    "                if hasattr(dets, \"xyxy\") and len(dets.xyxy) > 0:\n",
    "                    x1, y1, x2, y2 = dets.xyxy[0].astype(int).tolist()\n",
    "                    # clamp\n",
    "                    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "                    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "                    if x2 > x1 and y2 > y1:\n",
    "                        jake_xyxy = (x1, y1, x2, y2)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if res.masks is None:\n",
    "                self.out_q.put((path, frame, None, None, jake_xyxy))\n",
    "                continue\n",
    "\n",
    "            masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "            classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                       else res.boxes.cls.cpu().numpy())\n",
    "            classes = np.asarray(classes, dtype=int).ravel()  # <<< FIX: flatten here\n",
    "\n",
    "            self.out_q.put((path, frame, masks, classes, jake_xyxy))\n",
    "\n",
    "# =======================\n",
    "# Prefetcher\n",
    "# =======================\n",
    "class FramePrefetcher(threading.Thread):\n",
    "    def __init__(self, paths, out_q, maxsize=PREFETCH):\n",
    "        super().__init__(daemon=True)\n",
    "        self.paths = paths\n",
    "        self.q = out_q\n",
    "        self.stop = False\n",
    "\n",
    "    def run(self):\n",
    "        for p in self.paths:\n",
    "            if self.stop: break\n",
    "            img = cv2.imread(p)\n",
    "            self.q.put((p, img))\n",
    "        self.q.put(None)  # sentinel\n",
    "\n",
    "# =======================\n",
    "# Main\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    cv2.namedWindow(WIN_NAME, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    # Queues\n",
    "    prefetch_q = queue.Queue(maxsize=PREFETCH)\n",
    "    infer_in_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "    infer_out_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "\n",
    "    # Threads\n",
    "    pf = FramePrefetcher(paths, prefetch_q, maxsize=PREFETCH)\n",
    "    pf.start()\n",
    "\n",
    "    iw = InferenceWorker(infer_in_q, infer_out_q)\n",
    "    iw.start()\n",
    "\n",
    "    # Prime inference queue with a few frames\n",
    "    buffered = 0\n",
    "    while buffered < INFER_QUEUE:\n",
    "        item = prefetch_q.get()\n",
    "        infer_in_q.put(item)\n",
    "        if item is None: break\n",
    "        buffered += 1\n",
    "\n",
    "    times_ms = []\n",
    "    processed = 0\n",
    "    t_all_start = time.perf_counter()\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Keep inference fed\n",
    "        while not prefetch_q.empty() and infer_in_q.qsize() < INFER_QUEUE:\n",
    "            infer_in_q.put(prefetch_q.get())\n",
    "\n",
    "        out = infer_out_q.get()\n",
    "        if out is None:\n",
    "            break\n",
    "\n",
    "        p, frame, masks, classes, jake_xyxy = out\n",
    "        if frame is None:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # <<< Ensure classes is always a flat int array for safety\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes, dtype=int).ravel()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        H, W = frame.shape[:2]\n",
    "        if masks is None or classes is None:\n",
    "            left = frame.copy(); right = frame.copy()\n",
    "            heat = cv2.applyColorMap(np.zeros((H, W), np.uint8), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            h_m, w_m = masks.shape[1:]\n",
    "            rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "            for m, c in zip(masks, classes):\n",
    "                if int(c) == RAIL_ID:\n",
    "                    rail_union |= m.astype(bool)\n",
    "            rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "            # Green/red+score\n",
    "            green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                                   TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                                   MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "            red   = rail_mask & ~green\n",
    "            score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "            # bands\n",
    "            top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "            bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "            score[:top_ex, :] = 0\n",
    "            if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "            dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "            dark = cv2.morphologyEx(\n",
    "                dark, cv2.MORPH_OPEN,\n",
    "                cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "                iterations=1\n",
    "            )\n",
    "\n",
    "            total_dark_area  = int(dark.sum())\n",
    "            frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "            # LEFT labels + under-mask tint\n",
    "            left    = frame.copy()\n",
    "            overlay = left.copy()\n",
    "\n",
    "            # Jake overlap (low-res bbox)\n",
    "            best_idx = None\n",
    "            if jake_xyxy and masks is not None:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                sx, sy = w_m / W, h_m / H\n",
    "                mx1, mx2 = max(0, int(x1 * sx)), min(w_m, int(x2 * sx))\n",
    "                my1, my2 = max(0, int(y1 * sy)), min(h_m, int(y2 * sy))\n",
    "            else:\n",
    "                mx1 = mx2 = my1 = my2 = None\n",
    "\n",
    "            # <<< FIXED LOOP: no truthiness on numpy arrays\n",
    "            for idx in range(len(classes)):\n",
    "                cid = int(classes[idx])\n",
    "                if cid == RAIL_ID:\n",
    "                    continue\n",
    "                m_low = masks[idx]\n",
    "                mask_full = cv2.resize(m_low.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                colour = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "                overlay[mask_full] = colour\n",
    "\n",
    "                ys, xs = np.where(mask_full)\n",
    "                if len(xs):\n",
    "                    x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "                    label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "                if jake_xyxy and (mx2 > mx1) and (my2 > my1):\n",
    "                    area = int(m_low[my1:my2, mx1:mx2].sum())\n",
    "                    if best_idx is None:\n",
    "                        best_idx = idx\n",
    "                    else:\n",
    "                        prev = int(masks[best_idx][my1:my2, mx1:mx2].sum())\n",
    "                        if area > prev:\n",
    "                            best_idx = idx\n",
    "\n",
    "            left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "            # triangles\n",
    "            n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "            for lbl in range(1, n_lbl):\n",
    "                area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "                if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "                    continue\n",
    "                ys, xs = np.where(lbl_mat == lbl)\n",
    "                y_top  = ys.min()\n",
    "                x_mid  = int(xs[ys == ys.min()].mean())\n",
    "                draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "            # Jake bbox + under-mask tint\n",
    "            if jake_xyxy:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "                if best_idx is not None:\n",
    "                    best_mask_full = cv2.resize(masks[best_idx].astype(np.uint8), (W, H),\n",
    "                                                interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                    pink_layer = left.copy()\n",
    "                    pink_layer[best_mask_full] = UNDER_TINT_BGR\n",
    "                    left = cv2.addWeighted(pink_layer, 0.35, left, 0.65, 0)\n",
    "\n",
    "            # RIGHT rails + green\n",
    "            right = frame.copy()\n",
    "            rails_tinted = right.copy()\n",
    "            rails_tinted[rail_mask] = (0,0,255)\n",
    "            right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "            right[green] = (0,255,0)\n",
    "\n",
    "            # BOTTOM heat\n",
    "            heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "            heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # timing\n",
    "        dt_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        if i >= WARMUP_FRAMES:\n",
    "            times_ms.append(dt_ms)\n",
    "        processed += 1\n",
    "\n",
    "        # Display & controls\n",
    "        canvas = assemble_canvas(left, right, heat)\n",
    "        canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "        tag = f\"{os.path.basename(p)}  |  proc: {dt_ms:.1f} ms\"\n",
    "        cv2.putText(canvas, tag, (12, 28),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, tag, (12, 28),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 3, cv2.LINE_AA)\n",
    "        cv2.putText(canvas, \"SPACE: next   q/ESC: quit\",\n",
    "                    (12, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "\n",
    "        while True:\n",
    "            cv2.imshow(WIN_NAME, canvas)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if cv2.getWindowProperty(WIN_NAME, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                infer_in_q.put(None); cv2.destroyAllWindows(); sys.exit(0)\n",
    "            if key == 32:  # SPACE\n",
    "                break\n",
    "            if key in (ord('q'), 27):\n",
    "                infer_in_q.put(None); cv2.destroyAllWindows()\n",
    "                # summary\n",
    "                if times_ms:\n",
    "                    total_time = (time.perf_counter() - t_all_start)\n",
    "                    print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "                    print(f\"Total frames           : {processed}\")\n",
    "                    print(f\"Warm-up frames ignored : {min(WARMUP_FRAMES, processed)}\")\n",
    "                    print(f\"Frames timed           : {len(times_ms)}\")\n",
    "                    print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "                    avg = statistics.mean(times_ms)\n",
    "                    print(f\"Average / frame        : {avg:,.2f} ms  ({1000.0/avg:,.2f} FPS)\")\n",
    "                    print(f\"Median                 : {statistics.median(times_ms):,.2f} ms\")\n",
    "                    print(f\"Fastest                : {min(times_ms):,.2f} ms\")\n",
    "                    print(f\"Slowest                : {max(times_ms):,.2f} ms\")\n",
    "                    print(\"────────────────────────────────────────────────\")\n",
    "                sys.exit(0)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    total_time = (time.perf_counter() - t_all_start)\n",
    "    if times_ms:\n",
    "        avg = statistics.mean(times_ms)\n",
    "        print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "        print(f\"Total frames           : {processed}\")\n",
    "        print(f\"Warm-up frames ignored : {min(WARMUP_FRAMES, processed)}\")\n",
    "        print(f\"Frames timed           : {len(times_ms)}\")\n",
    "        print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "        print(f\"Average / frame        : {avg:,.2f} ms  ({1000.0/avg:,.2f} FPS)\")\n",
    "        print(f\"Median                 : {statistics.median(times_ms):,.2f} ms\")\n",
    "        print(f\"Fastest                : {min(times_ms):,.2f} ms\")\n",
    "        print(f\"Slowest                : {max(times_ms):,.2f} ms\")\n",
    "        print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Internal printing -> tryign to instane real move logic now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "JN/VSCode inline visualiser + speed-test for Subway Surfers pipeline.\n",
    "\n",
    "• Inline display: stacks each processed frame in the notebook (no cv2 windows)\n",
    "• SHOW_FIRST_N controls how many frames are displayed (rest still processed)\n",
    "• Pipelined: prefetch → persistent inference worker → CPU postproc\n",
    "• YOLO on GPU/MPS, RF-DETR on CPU by default to overlap compute\n",
    "• Warmup frames executed but not timed; summary printed at the end\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, statistics, threading, queue\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# Notebook display (inline)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    _HAS_IPY = True\n",
    "except Exception:\n",
    "    _HAS_IPY = False\n",
    "\n",
    "# ── disable antialias to avoid unsupported MPS op on some ops ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home          = os.path.expanduser(\"~\")\n",
    "yolo_weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights  = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "# ── New: only SHOW the first N frames inline (still process all) ──\n",
    "SHOW_FIRST_N  = 20\n",
    "\n",
    "RAIL_ID       = 9\n",
    "IMG_SIZE      = 512\n",
    "CONF, IOU     = 0.30, 0.45\n",
    "ALPHA         = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "\n",
    "MAX_DISPLAY_W   = 1600\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "JAKE_BOX_CLR    = (0, 255, 0)\n",
    "UNDER_TINT_BGR  = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES   = 10\n",
    "PREFETCH        = 24    # bigger prefetch helps saturate I/O\n",
    "INFER_QUEUE     = 4     # frames in-flight through inference\n",
    "\n",
    "# CPU threading (OpenCV)\n",
    "OPENCV_THREADS  = max(1, (os.cpu_count() or 8) - 1)\n",
    "\n",
    "# =======================\n",
    "# Device selection\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "    DET_ON_CPU = True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "    DET_ON_CPU = True   # RF-DETR on CPU to overlap with MPS\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "    DET_ON_CPU = False  # both CPU; pipeline still helps\n",
    "\n",
    "# =======================\n",
    "# Models\n",
    "# =======================\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# warmup YOLO\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                       device=yolo_device, conf=CONF, iou=IOU,\n",
    "                       verbose=False, half=half)\n",
    "\n",
    "# OpenCV threads\n",
    "try:\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Utils\n",
    "# =======================\n",
    "obstacle_classes = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb], dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def maybe_downscale(img, max_w=MAX_DISPLAY_W):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w: return img\n",
    "    scale = max_w / float(w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Inference worker (persistent)\n",
    "# =======================\n",
    "class InferenceWorker(threading.Thread):\n",
    "    \"\"\"\n",
    "    Consumes frames from in_q, runs YOLO (GPU/MPS) + RF-DETR (CPU optionally),\n",
    "    returns (path, frame, masks(np or None), classes(np or None), jake_xyxy or None)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_q, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q  = in_q\n",
    "        self.out_q = out_q\n",
    "        self.stop  = False\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop:\n",
    "            item = self.in_q.get()\n",
    "            if item is None:  # sentinel\n",
    "                self.out_q.put(None)\n",
    "                break\n",
    "            path, frame = item\n",
    "            H, W = frame.shape[:2]\n",
    "\n",
    "            # YOLO (device)\n",
    "            res = yolo_model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                                     device=yolo_device, conf=CONF, iou=IOU,\n",
    "                                     max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "            # RF-DETR (CPU to overlap by default)\n",
    "            jake_xyxy = None\n",
    "            try:\n",
    "                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                det_dev = \"cpu\" if DET_ON_CPU else (\"cpu\" if yolo_device != 0 else 0)\n",
    "                dets = jake_model.predict(pil_img, threshold=0.5, device=det_dev)[0]\n",
    "                if hasattr(dets, \"xyxy\") and len(dets.xyxy) > 0:\n",
    "                    x1, y1, x2, y2 = dets.xyxy[0].astype(int).tolist()\n",
    "                    # clamp\n",
    "                    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "                    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "                    if x2 > x1 and y2 > y1:\n",
    "                        jake_xyxy = (x1, y1, x2, y2)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if res.masks is None:\n",
    "                self.out_q.put((path, frame, None, None, jake_xyxy))\n",
    "                continue\n",
    "\n",
    "            masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "            classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                       else res.boxes.cls.cpu().numpy())\n",
    "            classes = np.asarray(classes, dtype=int).ravel()  # flatten once\n",
    "\n",
    "            self.out_q.put((path, frame, masks, classes, jake_xyxy))\n",
    "\n",
    "# =======================\n",
    "# Prefetcher\n",
    "# =======================\n",
    "class FramePrefetcher(threading.Thread):\n",
    "    def __init__(self, paths, out_q, maxsize=PREFETCH):\n",
    "        super().__init__(daemon=True)\n",
    "        self.paths = paths\n",
    "        self.q = out_q\n",
    "        self.stop = False\n",
    "\n",
    "    def run(self):\n",
    "        for p in self.paths:\n",
    "            if self.stop: break\n",
    "            img = cv2.imread(p)\n",
    "            self.q.put((p, img))\n",
    "        self.q.put(None)  # sentinel\n",
    "\n",
    "# =======================\n",
    "# Main (JN-friendly)\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    # Queues\n",
    "    prefetch_q = queue.Queue(maxsize=PREFETCH)\n",
    "    infer_in_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "    infer_out_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "\n",
    "    # Threads\n",
    "    pf = FramePrefetcher(paths, prefetch_q, maxsize=PREFETCH)\n",
    "    pf.start()\n",
    "\n",
    "    iw = InferenceWorker(infer_in_q, infer_out_q)\n",
    "    iw.start()\n",
    "\n",
    "    # Prime inference queue with a few frames\n",
    "    buffered = 0\n",
    "    while buffered < INFER_QUEUE:\n",
    "        item = prefetch_q.get()\n",
    "        infer_in_q.put(item)\n",
    "        if item is None: break\n",
    "        buffered += 1\n",
    "\n",
    "    times_ms = []\n",
    "    processed = 0\n",
    "    shown = 0\n",
    "    t_all_start = time.perf_counter()\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Keep inference fed\n",
    "        while not prefetch_q.empty() and infer_in_q.qsize() < INFER_QUEUE:\n",
    "            infer_in_q.put(prefetch_q.get())\n",
    "\n",
    "        out = infer_out_q.get()\n",
    "        if out is None:\n",
    "            break\n",
    "\n",
    "        p, frame, masks, classes, jake_xyxy = out\n",
    "        if frame is None:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Safety: ensure classes shape\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes, dtype=int).ravel()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        H, W = frame.shape[:2]\n",
    "        if masks is None or classes is None:\n",
    "            left = frame.copy(); right = frame.copy()\n",
    "            heat = cv2.applyColorMap(np.zeros((H, W), np.uint8), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            h_m, w_m = masks.shape[1:]\n",
    "            rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "            for m, c in zip(masks, classes):\n",
    "                if int(c) == RAIL_ID:\n",
    "                    rail_union |= m.astype(bool)\n",
    "            rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "            # Green/red + score\n",
    "            green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                                   TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                                   MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "            red   = rail_mask & ~green\n",
    "            score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "            # Exclude bands\n",
    "            top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "            bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "            score[:top_ex, :] = 0\n",
    "            if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "            dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "            dark = cv2.morphologyEx(\n",
    "                dark, cv2.MORPH_OPEN,\n",
    "                cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "                iterations=1\n",
    "            )\n",
    "\n",
    "            total_dark_area  = int(dark.sum())\n",
    "            frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "            # LEFT labels + under-mask tint\n",
    "            left    = frame.copy()\n",
    "            overlay = left.copy()\n",
    "\n",
    "            # Jake overlap (low-res bbox)\n",
    "            best_idx = None\n",
    "            if jake_xyxy and masks is not None:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                sx, sy = w_m / W, h_m / H\n",
    "                mx1, mx2 = max(0, int(x1 * sx)), min(w_m, int(x2 * sx))\n",
    "                my1, my2 = max(0, int(y1 * sy)), min(h_m, int(y2 * sy))\n",
    "            else:\n",
    "                mx1 = mx2 = my1 = my2 = None\n",
    "\n",
    "            for idx in range(len(classes)):\n",
    "                cid = int(classes[idx])\n",
    "                if cid == RAIL_ID:\n",
    "                    continue\n",
    "                m_low = masks[idx]\n",
    "                mask_full = cv2.resize(m_low.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                colour = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "                overlay[mask_full] = colour\n",
    "\n",
    "                ys, xs = np.where(mask_full)\n",
    "                if len(xs):\n",
    "                    x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "                    label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "                if jake_xyxy and (mx2 > mx1) and (my2 > my1):\n",
    "                    area = int(m_low[my1:my2, mx1:mx2].sum())\n",
    "                    if best_idx is None:\n",
    "                        best_idx = idx\n",
    "                    else:\n",
    "                        prev = int(masks[best_idx][my1:my2, mx1:mx2].sum())\n",
    "                        if area > prev:\n",
    "                            best_idx = idx\n",
    "\n",
    "            left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "            # Purple-triangle warnings\n",
    "            n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "            for lbl in range(1, n_lbl):\n",
    "                area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "                if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "                    continue\n",
    "                ys, xs = np.where(lbl_mat == lbl)\n",
    "                y_top  = ys.min()\n",
    "                x_mid  = int(xs[ys == ys.min()].mean())\n",
    "                draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "            # Jake bbox + under-mask tint\n",
    "            if jake_xyxy:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "                if best_idx is not None:\n",
    "                    best_mask_full = cv2.resize(masks[best_idx].astype(np.uint8), (W, H),\n",
    "                                                interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                    pink_layer = left.copy()\n",
    "                    pink_layer[best_mask_full] = UNDER_TINT_BGR\n",
    "                    left = cv2.addWeighted(pink_layer, 0.35, left, 0.65, 0)\n",
    "\n",
    "            # RIGHT rails + green\n",
    "            right = frame.copy()\n",
    "            rails_tinted = right.copy()\n",
    "            rails_tinted[rail_mask] = (0,0,255)\n",
    "            right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "            right[green] = (0,255,0)\n",
    "\n",
    "            # BOTTOM heat\n",
    "            heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "            heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # timing\n",
    "        dt_ms = (time.perf_counter() - t0) * 1000.0\n",
    "        if i >= WARMUP_FRAMES:\n",
    "            times_ms.append(dt_ms)\n",
    "        processed += 1\n",
    "\n",
    "        # Build canvas for inline display (only for first SHOW_FIRST_N)\n",
    "        if _HAS_IPY and shown < SHOW_FIRST_N:\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = maybe_downscale(canvas, MAX_DISPLAY_W)\n",
    "            tag = f\"{os.path.basename(p)}  |  proc: {dt_ms:.1f} ms\"\n",
    "            cv2.putText(canvas, tag, (12, 28),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 3, cv2.LINE_AA)\n",
    "            cv2.putText(canvas, tag, (12, 28),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, TEXT_CLR, 1, cv2.LINE_AA)\n",
    "            # show inline\n",
    "            rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "            display(Image.fromarray(rgb))\n",
    "            shown += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Done\n",
    "    total_time = (time.perf_counter() - t_all_start)\n",
    "    if times_ms:\n",
    "        avg = statistics.mean(times_ms)\n",
    "        print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "        print(f\"Total frames           : {processed}\")\n",
    "        print(f\"Warm-up frames ignored : {min(WARMUP_FRAMES, processed)}\")\n",
    "        print(f\"Frames timed           : {len(times_ms)}\")\n",
    "        print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "        print(f\"Average / frame        : {avg:,.2f} ms  ({1000.0/avg:,.2f} FPS)\")\n",
    "        print(f\"Median                 : {statistics.median(times_ms):,.2f} ms\")\n",
    "        print(f\"Fastest                : {min(times_ms):,.2f} ms\")\n",
    "        print(f\"Slowest                : {max(times_ms):,.2f} ms\")\n",
    "        print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated timing metrics and image sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30789467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "JN/VSCode inline visualiser + speed-test for Subway Surfers pipeline.\n",
    "\n",
    "• Inline display: stacks each processed frame in the notebook (no cv2 windows)\n",
    "• SHOW_FIRST_N controls how many frames are displayed (rest still processed)\n",
    "• Pipelined: prefetch → persistent inference worker → CPU postproc\n",
    "• YOLO on GPU/MPS, RF-DETR on CPU by default to overlap compute\n",
    "• Warmup frames executed but not timed; summary printed at the end\n",
    "• Timing excludes ANY display/printing work (only core processing is timed)\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, statistics, threading, queue\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# Notebook display (inline)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    _HAS_IPY = True\n",
    "except Exception:\n",
    "    _HAS_IPY = False\n",
    "\n",
    "# ── disable antialias to avoid unsupported MPS op on some ops ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home          = os.path.expanduser(\"~\")\n",
    "yolo_weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights  = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "# ── Only SHOW the first N frames inline (still process all) ──\n",
    "SHOW_FIRST_N   = 20\n",
    "\n",
    "# ── Make inline images neater/smaller ──\n",
    "DISPLAY_MAX_W  = 960    # target max width of the displayed canvas (px)\n",
    "TEXT_SCALE     = 0.6    # overlay text size on canvas\n",
    "TEXT_THICK     = 1      # overlay text thickness\n",
    "\n",
    "RAIL_ID       = 9\n",
    "IMG_SIZE      = 512\n",
    "CONF, IOU     = 0.30, 0.45\n",
    "ALPHA         = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "JAKE_BOX_CLR    = (0, 255, 0)\n",
    "UNDER_TINT_BGR  = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES   = 10\n",
    "PREFETCH        = 24    # prefetch helps saturate I/O\n",
    "INFER_QUEUE     = 4     # frames in-flight through inference\n",
    "\n",
    "# CPU threading (OpenCV)\n",
    "OPENCV_THREADS  = max(1, (os.cpu_count() or 8) - 1)\n",
    "\n",
    "# =======================\n",
    "# Device selection\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "    DET_ON_CPU = True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "    DET_ON_CPU = True   # RF-DETR on CPU to overlap with MPS\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "    DET_ON_CPU = False  # both CPU; pipeline still helps\n",
    "\n",
    "# =======================\n",
    "# Models\n",
    "# =======================\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# warmup YOLO\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                       device=yolo_device, conf=CONF, iou=IOU,\n",
    "                       verbose=False, half=half)\n",
    "\n",
    "# OpenCV threads\n",
    "try:\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Utils\n",
    "# =======================\n",
    "obstacle_classes = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb], dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def resize_to_width(img, max_w=DISPLAY_MAX_W):\n",
    "    \"\"\"Resize maintaining aspect ratio if wider than max_w.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Inference worker (persistent)\n",
    "# =======================\n",
    "class InferenceWorker(threading.Thread):\n",
    "    \"\"\"\n",
    "    Consumes frames from in_q, runs YOLO (GPU/MPS) + RF-DETR (CPU optionally),\n",
    "    returns (path, frame, masks(np or None), classes(np or None), jake_xyxy or None)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_q, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q  = in_q\n",
    "        self.out_q = out_q\n",
    "        self.stop  = False\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop:\n",
    "            item = self.in_q.get()\n",
    "            if item is None:  # sentinel\n",
    "                self.out_q.put(None)\n",
    "                break\n",
    "            path, frame = item\n",
    "            H, W = frame.shape[:2]\n",
    "\n",
    "            # YOLO (device)\n",
    "            res = yolo_model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                                     device=yolo_device, conf=CONF, iou=IOU,\n",
    "                                     max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "            # RF-DETR (CPU to overlap by default)\n",
    "            jake_xyxy = None\n",
    "            try:\n",
    "                pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                det_dev = \"cpu\" if DET_ON_CPU else (\"cpu\" if yolo_device != 0 else 0)\n",
    "                dets = jake_model.predict(pil_img, threshold=0.5, device=det_dev)[0]\n",
    "                if hasattr(dets, \"xyxy\") and len(dets.xyxy) > 0:\n",
    "                    x1, y1, x2, y2 = dets.xyxy[0].astype(int).tolist()\n",
    "                    # clamp\n",
    "                    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "                    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "                    if x2 > x1 and y2 > y1:\n",
    "                        jake_xyxy = (x1, y1, x2, y2)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if res.masks is None:\n",
    "                self.out_q.put((path, frame, None, None, jake_xyxy))\n",
    "                continue\n",
    "\n",
    "            masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "            classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                       else res.boxes.cls.cpu().numpy())\n",
    "            classes = np.asarray(classes, dtype=int).ravel()  # flatten once\n",
    "\n",
    "            self.out_q.put((path, frame, masks, classes, jake_xyxy))\n",
    "\n",
    "# =======================\n",
    "# Prefetcher\n",
    "# =======================\n",
    "class FramePrefetcher(threading.Thread):\n",
    "    def __init__(self, paths, out_q, maxsize=PREFETCH):\n",
    "        super().__init__(daemon=True)\n",
    "        self.paths = paths\n",
    "        self.q = out_q\n",
    "        self.stop = False\n",
    "\n",
    "    def run(self):\n",
    "        for p in self.paths:\n",
    "            if self.stop: break\n",
    "            img = cv2.imread(p)\n",
    "            self.q.put((p, img))\n",
    "        self.q.put(None)  # sentinel\n",
    "\n",
    "# =======================\n",
    "# Main (JN-friendly)\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    # Queues\n",
    "    prefetch_q = queue.Queue(maxsize=PREFETCH)\n",
    "    infer_in_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "    infer_out_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "\n",
    "    # Threads\n",
    "    pf = FramePrefetcher(paths, prefetch_q, maxsize=PREFETCH)\n",
    "    pf.start()\n",
    "\n",
    "    iw = InferenceWorker(infer_in_q, infer_out_q)\n",
    "    iw.start()\n",
    "\n",
    "    # Prime inference queue with a few frames\n",
    "    buffered = 0\n",
    "    while buffered < INFER_QUEUE:\n",
    "        item = prefetch_q.get()\n",
    "        infer_in_q.put(item)\n",
    "        if item is None: break\n",
    "        buffered += 1\n",
    "\n",
    "    times_ms = []\n",
    "    processed = 0\n",
    "    shown = 0\n",
    "    t_all_start = time.perf_counter()\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Keep inference fed\n",
    "        while not prefetch_q.empty() and infer_in_q.qsize() < INFER_QUEUE:\n",
    "            infer_in_q.put(prefetch_q.get())\n",
    "\n",
    "        out = infer_out_q.get()\n",
    "        if out is None:\n",
    "            break\n",
    "\n",
    "        p, frame, masks, classes, jake_xyxy = out\n",
    "        if frame is None:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Safety: ensure classes shape\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes, dtype=int).ravel()\n",
    "\n",
    "        # ─────────────────────── TIMING START (processing only) ───────────────────────\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        H, W = frame.shape[:2]\n",
    "        if masks is None or classes is None:\n",
    "            left = frame.copy(); right = frame.copy()\n",
    "            heat = cv2.applyColorMap(np.zeros((H, W), np.uint8), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            h_m, w_m = masks.shape[1:]\n",
    "            rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "            for m, c in zip(masks, classes):\n",
    "                if int(c) == RAIL_ID:\n",
    "                    rail_union |= m.astype(bool)\n",
    "            rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "            # Green/red + score\n",
    "            green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                                   TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                                   MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "            red   = rail_mask & ~green\n",
    "            score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "            # Exclude bands\n",
    "            top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "            bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "            score[:top_ex, :] = 0\n",
    "            if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "            dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "            dark = cv2.morphologyEx(\n",
    "                dark, cv2.MORPH_OPEN,\n",
    "                cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "                iterations=1\n",
    "            )\n",
    "\n",
    "            total_dark_area  = int(dark.sum())\n",
    "            frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "            # LEFT labels + under-mask tint\n",
    "            left    = frame.copy()\n",
    "            overlay = left.copy()\n",
    "\n",
    "            # Jake overlap (low-res bbox)\n",
    "            best_idx = None\n",
    "            if jake_xyxy and masks is not None:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                sx, sy = w_m / W, h_m / H\n",
    "                mx1, mx2 = max(0, int(x1 * sx)), min(w_m, int(x2 * sx))\n",
    "                my1, my2 = max(0, int(y1 * sy)), min(h_m, int(y2 * sy))\n",
    "            else:\n",
    "                mx1 = mx2 = my1 = my2 = None\n",
    "\n",
    "            for idx in range(len(classes)):\n",
    "                cid = int(classes[idx])\n",
    "                if cid == RAIL_ID:\n",
    "                    continue\n",
    "                m_low = masks[idx]\n",
    "                mask_full = cv2.resize(m_low.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                colour = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "                overlay[mask_full] = colour\n",
    "\n",
    "                ys, xs = np.where(mask_full)\n",
    "                if len(xs):\n",
    "                    x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "                    label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "                if jake_xyxy and (mx2 > mx1) and (my2 > my1):\n",
    "                    area = int(m_low[my1:my2, mx1:mx2].sum())\n",
    "                    if best_idx is None:\n",
    "                        best_idx = idx\n",
    "                    else:\n",
    "                        prev = int(masks[best_idx][my1:my2, mx1:mx2].sum())\n",
    "                        if area > prev:\n",
    "                            best_idx = idx\n",
    "\n",
    "            left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "            # Purple-triangle warnings\n",
    "            n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "            for lbl in range(1, n_lbl):\n",
    "                area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "                if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "                    continue\n",
    "                ys, xs = np.where(lbl_mat == lbl)\n",
    "                y_top  = ys.min()\n",
    "                x_mid  = int(xs[ys == ys.min()].mean())\n",
    "                draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "            # Jake bbox + under-mask tint\n",
    "            if jake_xyxy:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "                if best_idx is not None:\n",
    "                    best_mask_full = cv2.resize(masks[best_idx].astype(np.uint8), (W, H),\n",
    "                                                interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                    pink_layer = left.copy()\n",
    "                    pink_layer[best_mask_full] = UNDER_TINT_BGR\n",
    "                    left = cv2.addWeighted(pink_layer, 0.35, left, 0.65, 0)\n",
    "\n",
    "            # RIGHT rails + green\n",
    "            right = frame.copy()\n",
    "            rails_tinted = right.copy()\n",
    "            rails_tinted[rail_mask] = (0,0,255)\n",
    "            right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "            right[green] = (0,255,0)\n",
    "\n",
    "            # BOTTOM heat\n",
    "            heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "            heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # ─────────────────────── TIMING END (processing only) ───────────────────────\n",
    "        dt_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "        # record timing for non-warmup frames\n",
    "        if i >= WARMUP_FRAMES:\n",
    "            times_ms.append(dt_ms)\n",
    "        processed += 1\n",
    "\n",
    "        # ── DISPLAY (not timed): assemble, resize, annotate, convert, show ──\n",
    "        if _HAS_IPY and shown < SHOW_FIRST_N:\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = resize_to_width(canvas, DISPLAY_MAX_W)\n",
    "\n",
    "            tag = f\"{os.path.basename(p)}  |  proc: {dt_ms:.1f} ms\"\n",
    "            cv2.putText(canvas, tag, (12, 28),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, TEXT_SCALE, TEXT_CLR, TEXT_THICK, cv2.LINE_AA)\n",
    "\n",
    "            rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "            display(Image.fromarray(rgb))\n",
    "            shown += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Done\n",
    "    total_time = (time.perf_counter() - t_all_start)\n",
    "    if times_ms:\n",
    "        avg = statistics.mean(times_ms)\n",
    "        print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "        print(f\"Total frames           : {processed}\")\n",
    "        print(f\"Warm-up frames ignored : {min(WARMUP_FRAMES, processed)}\")\n",
    "        print(f\"Frames timed           : {len(times_ms)}\")\n",
    "        print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "        print(f\"Average / frame        : {avg:,.2f} ms  ({1000.0/avg:,.2f} FPS)\")\n",
    "        print(f\"Median                 : {statistics.median(times_ms):,.2f} ms\")\n",
    "        print(f\"Fastest                : {min(times_ms):,.2f} ms\")\n",
    "        print(f\"Slowest                : {max(times_ms):,.2f} ms\")\n",
    "        print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO CHEATING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c198b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "JN/VSCode inline visualiser + speed-test for Subway Surfers pipeline (honest timings).\n",
    "\n",
    "• End-to-end per-frame latency (no cheating): inference (YOLO+RF-DETR) + CPU postproc\n",
    "  - Worker records infer_start_ts / infer_end_ts and returns them\n",
    "  - Main times postproc and computes total_ms = post_end_ts - infer_start_ts\n",
    "• Inline display (first N frames) happens AFTER timing, never included\n",
    "• Pipeline: prefetch → persistent inference worker → CPU postproc\n",
    "• YOLO on GPU/MPS, RF-DETR on CPU by default to overlap compute\n",
    "• Warmup frames executed but not included in statistics; summary printed at the end\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, sys, time, statistics, threading, queue\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# Notebook display (inline)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    _HAS_IPY = True\n",
    "except Exception:\n",
    "    _HAS_IPY = False\n",
    "\n",
    "# ── disable antialias to avoid unsupported MPS op on some ops ─\n",
    "_original_interpolate = F.interpolate\n",
    "def _interpolate_no_antialias(input, *args, **kwargs):\n",
    "    kwargs['antialias'] = False\n",
    "    return _original_interpolate(input, *args, **kwargs)\n",
    "F.interpolate = _interpolate_no_antialias\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home          = os.path.expanduser(\"~\")\n",
    "yolo_weights  = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "jake_weights  = f\"{home}/downloads/weightsjake.pt\"\n",
    "\n",
    "# Display: only SHOW the first N frames inline (still process all)\n",
    "SHOW_FIRST_N   = 15\n",
    "DISPLAY_MAX_W  = 960    # target max width of displayed canvas\n",
    "TEXT_SCALE     = 0.6\n",
    "TEXT_THICK     = 1\n",
    "\n",
    "RAIL_ID       = 9\n",
    "IMG_SIZE      = 512\n",
    "CONF, IOU     = 0.30, 0.45\n",
    "ALPHA         = 0.40\n",
    "\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "\n",
    "TEXT_CLR        = (255, 255, 255)\n",
    "JAKE_BOX_CLR    = (0, 255, 0)\n",
    "UNDER_TINT_BGR  = (255, 0, 255)\n",
    "\n",
    "WARMUP_FRAMES   = 10\n",
    "PREFETCH        = 24    # prefetch helps saturate I/O\n",
    "INFER_QUEUE     = 4     # frames in-flight through inference\n",
    "\n",
    "# CPU threading (OpenCV)\n",
    "OPENCV_THREADS  = max(1, (os.cpu_count() or 8) - 1)\n",
    "try:\n",
    "    cv2.setNumThreads(OPENCV_THREADS)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =======================\n",
    "# Device selection\n",
    "# =======================\n",
    "if torch.cuda.is_available():\n",
    "    yolo_device, half = 0, True\n",
    "    DET_ON_CPU = True\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    yolo_device, half = \"mps\", False\n",
    "    DET_ON_CPU = True   # RF-DETR on CPU to overlap with MPS\n",
    "else:\n",
    "    yolo_device, half = \"cpu\", False\n",
    "    DET_ON_CPU = False  # both CPU; pipeline still helps\n",
    "\n",
    "# =======================\n",
    "# Models\n",
    "# =======================\n",
    "yolo_model = YOLO(yolo_weights)\n",
    "try: yolo_model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "jake_model = RFDETRBase(pretrain_weights=jake_weights, num_classes=3)\n",
    "\n",
    "# Warmup YOLO (so first frame isn't laggy)\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "with torch.inference_mode():\n",
    "    _ = yolo_model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                           device=yolo_device, conf=CONF, iou=IOU,\n",
    "                           verbose=False, half=half)\n",
    "\n",
    "# =======================\n",
    "# Utils\n",
    "# =======================\n",
    "obstacle_classes = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask, target_colors_rgb,\n",
    "                                   tolerance=30.0, min_region_size=50,\n",
    "                                   min_region_height=150):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    filtered_full = np.zeros((H, W), dtype=bool)\n",
    "    if not rail_mask.any():\n",
    "        return filtered_full\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "    targets_bgr = np.array([(r,g,b)[::-1] for r,g,b in target_colors_rgb], dtype=np.float32)\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - targets_bgr[None, None, :, :]\n",
    "    dist2 = np.sum(diff*diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= tolerance**2, axis=-1)\n",
    "    combined = colour_hit & mask_roi\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    good = np.zeros_like(combined)\n",
    "    for lbl in range(1, n):\n",
    "        area, h = stats[lbl, cv2.CC_STAT_AREA], stats[lbl, cv2.CC_STAT_HEIGHT]\n",
    "        if area >= min_region_size and h >= min_region_height:\n",
    "            good[lbls == lbl] = True\n",
    "    filtered_full[y0:y1, x0:x1] = good\n",
    "    return filtered_full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask, blur_ksize=51):\n",
    "    k = (blur_ksize, blur_ksize)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2*amax) + 0.5)\n",
    "    return np.clip(norm * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def assemble_canvas(left, right, heat):\n",
    "    top    = np.hstack((left, right))\n",
    "    return np.vstack((top, heat))\n",
    "\n",
    "def resize_to_width(img, max_w=DISPLAY_MAX_W):\n",
    "    \"\"\"Resize maintaining aspect ratio if wider than max_w.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img\n",
    "    scale = max_w / float(w)\n",
    "    return cv2.resize(img, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# =======================\n",
    "# Inference worker (persistent, measures inference time)\n",
    "# =======================\n",
    "class InferenceWorker(threading.Thread):\n",
    "    \"\"\"\n",
    "    Consumes frames from in_q, runs YOLO (GPU/MPS) + RF-DETR (CPU optionally),\n",
    "    and returns:\n",
    "      (path, frame, masks, classes, jake_xyxy, infer_start_ts, infer_end_ts)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_q, out_q):\n",
    "        super().__init__(daemon=True)\n",
    "        self.in_q  = in_q\n",
    "        self.out_q = out_q\n",
    "        self.stop  = False\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop:\n",
    "            item = self.in_q.get()\n",
    "            if item is None:  # sentinel\n",
    "                self.out_q.put(None)\n",
    "                break\n",
    "            path, frame = item\n",
    "            H, W = frame.shape[:2]\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                infer_start_ts = time.perf_counter()\n",
    "\n",
    "                # YOLO (device)\n",
    "                res = yolo_model.predict(frame, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                                         device=yolo_device, conf=CONF, iou=IOU,\n",
    "                                         max_det=30, verbose=False, half=half)[0]\n",
    "\n",
    "                # RF-DETR (CPU to overlap by default)\n",
    "                jake_xyxy = None\n",
    "                try:\n",
    "                    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                    det_dev = \"cpu\" if DET_ON_CPU else (\"cpu\" if yolo_device != 0 else 0)\n",
    "                    dets = jake_model.predict(pil_img, threshold=0.5, device=det_dev)[0]\n",
    "                    if hasattr(dets, \"xyxy\") and len(dets.xyxy) > 0:\n",
    "                        x1, y1, x2, y2 = dets.xyxy[0].astype(int).tolist()\n",
    "                        # clamp\n",
    "                        x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "                        y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "                        if x2 > x1 and y2 > y1:\n",
    "                            jake_xyxy = (x1, y1, x2, y2)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                infer_end_ts = time.perf_counter()\n",
    "\n",
    "            if res.masks is None:\n",
    "                self.out_q.put((path, frame, None, None, jake_xyxy, infer_start_ts, infer_end_ts))\n",
    "                continue\n",
    "\n",
    "            masks   = res.masks.data.cpu().numpy()  # (N, h_m, w_m)\n",
    "            classes = (res.masks.cls.cpu().numpy() if hasattr(res.masks, \"cls\")\n",
    "                       else res.boxes.cls.cpu().numpy())\n",
    "            classes = np.asarray(classes, dtype=int).ravel()\n",
    "\n",
    "            self.out_q.put((path, frame, masks, classes, jake_xyxy, infer_start_ts, infer_end_ts))\n",
    "\n",
    "# =======================\n",
    "# Prefetcher\n",
    "# =======================\n",
    "class FramePrefetcher(threading.Thread):\n",
    "    def __init__(self, paths, out_q, maxsize=PREFETCH):\n",
    "        super().__init__(daemon=True)\n",
    "        self.paths = paths\n",
    "        self.q = out_q\n",
    "        self.stop = False\n",
    "\n",
    "    def run(self):\n",
    "        for p in self.paths:\n",
    "            if self.stop: break\n",
    "            img = cv2.imread(p)\n",
    "            self.q.put((p, img))\n",
    "        self.q.put(None)  # sentinel\n",
    "\n",
    "# =======================\n",
    "# Main (JN-friendly, honest timing)\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path.home() / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "    if not folder.is_dir():\n",
    "        print(f\"[ERROR] frames folder not found: {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(str(folder / \"frame_*.jpg\")) +\n",
    "        glob.glob(str(folder / \"frame_*.png\")) +\n",
    "        glob.glob(str(folder / \"*.jpg\")) +\n",
    "        glob.glob(str(folder / \"*.png\"))\n",
    "    )\n",
    "    if not paths:\n",
    "        print(f\"[ERROR] No frame images found in {folder}\", file=sys.stderr); sys.exit(1)\n",
    "\n",
    "    # Queues\n",
    "    prefetch_q = queue.Queue(maxsize=PREFETCH)\n",
    "    infer_in_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "    infer_out_q = queue.Queue(maxsize=INFER_QUEUE)\n",
    "\n",
    "    # Threads\n",
    "    pf = FramePrefetcher(paths, prefetch_q, maxsize=PREFETCH)\n",
    "    pf.start()\n",
    "\n",
    "    iw = InferenceWorker(infer_in_q, infer_out_q)\n",
    "    iw.start()\n",
    "\n",
    "    # Prime inference queue with a few frames\n",
    "    buffered = 0\n",
    "    while buffered < INFER_QUEUE:\n",
    "        item = prefetch_q.get()\n",
    "        infer_in_q.put(item)\n",
    "        if item is None: break\n",
    "        buffered += 1\n",
    "\n",
    "    # Timing accumulators (end-to-end), and also separate components\n",
    "    total_ms_list = []\n",
    "    infer_ms_list = []\n",
    "    post_ms_list  = []\n",
    "\n",
    "    processed = 0\n",
    "    shown = 0\n",
    "    t_all_start = time.perf_counter()\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        # Keep inference fed\n",
    "        while not prefetch_q.empty() and infer_in_q.qsize() < INFER_QUEUE:\n",
    "            infer_in_q.put(prefetch_q.get())\n",
    "\n",
    "        out = infer_out_q.get()\n",
    "        if out is None:\n",
    "            break\n",
    "\n",
    "        p, frame, masks, classes, jake_xyxy, infer_start_ts, infer_end_ts = out\n",
    "        if frame is None:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if classes is not None:\n",
    "            classes = np.asarray(classes, dtype=int).ravel()\n",
    "\n",
    "        # ───────────── POST-PROC TIMING (processing only) ─────────────\n",
    "        post_start_ts = time.perf_counter()\n",
    "\n",
    "        H, W = frame.shape[:2]\n",
    "        if masks is None or classes is None:\n",
    "            left = frame.copy(); right = frame.copy()\n",
    "            heat = cv2.applyColorMap(np.zeros((H, W), np.uint8), cv2.COLORMAP_JET)\n",
    "        else:\n",
    "            h_m, w_m = masks.shape[1:]\n",
    "            rail_union = np.zeros((h_m, w_m), dtype=bool)\n",
    "            for m, c in zip(masks, classes):\n",
    "                if int(c) == RAIL_ID:\n",
    "                    rail_union |= m.astype(bool)\n",
    "            rail_mask = cv2.resize(rail_union.astype(np.uint8), (W, H),\n",
    "                                   interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "            # Green/red + score\n",
    "            green = highlight_rails_mask_only_fast(frame, rail_mask,\n",
    "                                                   TARGET_COLORS_RGB, TOLERANCE,\n",
    "                                                   MIN_REGION_SIZE, MIN_REGION_HEIGHT)\n",
    "            red   = rail_mask & ~green\n",
    "            score = red_vs_green_score(red, green, HEAT_BLUR_KSIZE)\n",
    "\n",
    "            # Exclude bands\n",
    "            top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "            bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "            score[:top_ex, :] = 0\n",
    "            if bot_ex: score[H-bot_ex:, :] = 0\n",
    "\n",
    "            dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "            dark = cv2.morphologyEx(\n",
    "                dark, cv2.MORPH_OPEN,\n",
    "                cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "                iterations=1\n",
    "            )\n",
    "\n",
    "            total_dark_area  = int(dark.sum())\n",
    "            frac_area_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark_area))\n",
    "\n",
    "            # LEFT labels + under-mask tint\n",
    "            left    = frame.copy()\n",
    "            overlay = left.copy()\n",
    "\n",
    "            # Jake overlap (low-res bbox)\n",
    "            best_idx = None\n",
    "            if jake_xyxy and masks is not None:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                sx, sy = w_m / W, h_m / H\n",
    "                mx1, mx2 = max(0, int(x1 * sx)), min(w_m, int(x2 * sx))\n",
    "                my1, my2 = max(0, int(y1 * sy)), min(h_m, int(y2 * sy))\n",
    "            else:\n",
    "                mx1 = mx2 = my1 = my2 = None\n",
    "\n",
    "            for idx in range(len(classes)):\n",
    "                cid = int(classes[idx])\n",
    "                if cid == RAIL_ID:\n",
    "                    continue\n",
    "                m_low = masks[idx]\n",
    "                mask_full = cv2.resize(m_low.astype(np.uint8), (W, H),\n",
    "                                       interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                colour = CLASS_COLOURS.get(cid, (255,255,255))\n",
    "                overlay[mask_full] = colour\n",
    "\n",
    "                ys, xs = np.where(mask_full)\n",
    "                if len(xs):\n",
    "                    x_c, y_c = int(xs.mean()), int(ys.mean())\n",
    "                    label = obstacle_classes.get(cid, f\"CLASS {cid}\")\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(overlay, label, (x_c-40, y_c),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "                if jake_xyxy and (mx2 > mx1) and (my2 > my1):\n",
    "                    area = int(m_low[my1:my2, mx1:mx2].sum())\n",
    "                    if best_idx is None:\n",
    "                        best_idx = idx\n",
    "                    else:\n",
    "                        prev = int(masks[best_idx][my1:my2, mx1:mx2].sum())\n",
    "                        if area > prev:\n",
    "                            best_idx = idx\n",
    "\n",
    "            left = cv2.addWeighted(overlay, 0.6, left, 0.4, 0)\n",
    "\n",
    "            # Purple-triangle warnings\n",
    "            n_lbl, lbl_mat, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "            for lbl in range(1, n_lbl):\n",
    "                area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "                if area < MIN_DARK_RED_AREA or area < frac_area_thresh:\n",
    "                    continue\n",
    "                ys, xs = np.where(lbl_mat == lbl)\n",
    "                y_top  = ys.min()\n",
    "                x_mid  = int(xs[ys == ys.min()].mean())\n",
    "                draw_triangle(left, x_mid, y_top)\n",
    "\n",
    "            # Jake bbox + under-mask tint\n",
    "            if jake_xyxy:\n",
    "                x1, y1, x2, y2 = jake_xyxy\n",
    "                cv2.rectangle(left, (x1, y1), (x2, y2), JAKE_BOX_CLR, 2)\n",
    "                if best_idx is not None:\n",
    "                    best_mask_full = cv2.resize(masks[best_idx].astype(np.uint8), (W, H),\n",
    "                                                interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "                    pink_layer = left.copy()\n",
    "                    pink_layer[best_mask_full] = UNDER_TINT_BGR\n",
    "                    left = cv2.addWeighted(pink_layer, 0.35, left, 0.65, 0)\n",
    "\n",
    "            # RIGHT rails + green\n",
    "            right = frame.copy()\n",
    "            rails_tinted = right.copy()\n",
    "            rails_tinted[rail_mask] = (0,0,255)\n",
    "            right = cv2.addWeighted(rails_tinted, ALPHA, right, 1-ALPHA, 0)\n",
    "            right[green] = (0,255,0)\n",
    "\n",
    "            # BOTTOM heat\n",
    "            heat = cv2.applyColorMap(score, cv2.COLORMAP_JET)\n",
    "            heat = cv2.resize(heat, (left.shape[1] + right.shape[1], H),\n",
    "                              interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        post_end_ts = time.perf_counter()\n",
    "        # ───────────── END TIMING ─────────────\n",
    "\n",
    "        # Calculate timings\n",
    "        infer_ms = (infer_end_ts - infer_start_ts) * 1000.0\n",
    "        post_ms  = (post_end_ts  - post_start_ts) * 1000.0\n",
    "        total_ms = (post_end_ts  - infer_start_ts) * 1000.0  # honest end-to-end\n",
    "\n",
    "        # record timing for non-warmup frames\n",
    "        if i >= WARMUP_FRAMES:\n",
    "            infer_ms_list.append(infer_ms)\n",
    "            post_ms_list.append(post_ms)\n",
    "            total_ms_list.append(total_ms)\n",
    "        processed += 1\n",
    "\n",
    "        # ── DISPLAY (not timed): assemble, resize, annotate, convert, show ──\n",
    "        if _HAS_IPY and shown < SHOW_FIRST_N:\n",
    "            canvas = assemble_canvas(left, right, heat)\n",
    "            canvas = resize_to_width(canvas, DISPLAY_MAX_W)\n",
    "            tag = (f\"{os.path.basename(p)} | infer: {infer_ms:.1f} ms | \"\n",
    "                   f\"post: {post_ms:.1f} ms | total: {total_ms:.1f} ms\")\n",
    "            cv2.putText(canvas, tag, (12, 28),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, TEXT_SCALE, TEXT_CLR, TEXT_THICK, cv2.LINE_AA)\n",
    "            rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "            display(Image.fromarray(rgb))\n",
    "            shown += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # Done\n",
    "    total_time = (time.perf_counter() - t_all_start)\n",
    "    if total_ms_list:\n",
    "        avg_total = statistics.mean(total_ms_list)\n",
    "        avg_infer = statistics.mean(infer_ms_list)\n",
    "        avg_post  = statistics.mean(post_ms_list)\n",
    "        print(\"\\n───── Speed-test summary (warm-up skipped) ─────\")\n",
    "        print(f\"Total frames           : {processed}\")\n",
    "        print(f\"Warm-up frames ignored : {min(WARMUP_FRAMES, processed)}\")\n",
    "        print(f\"Frames timed           : {len(total_ms_list)}\")\n",
    "        print(f\"Total wall-clock time  : {total_time:,.2f} s\")\n",
    "        print(f\"Average inference      : {avg_infer:,.2f} ms\")\n",
    "        print(f\"Average postproc       : {avg_post:,.2f} ms\")\n",
    "        print(f\"Average end-to-end     : {avg_total:,.2f} ms  ({1000.0/avg_total:,.2f} FPS)\")\n",
    "        print(f\"Median end-to-end      : {statistics.median(total_ms_list):,.2f} ms\")\n",
    "        print(f\"Fastest end-to-end     : {min(total_ms_list):,.2f} ms\")\n",
    "        print(f\"Slowest end-to-end     : {max(total_ms_list):,.2f} ms\")\n",
    "        print(\"────────────────────────────────────────────────\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c0e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
