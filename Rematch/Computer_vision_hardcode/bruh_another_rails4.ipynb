{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c42f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, no-UI, no-prints, batched pipeline with threaded I/O\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config (tweak for your box)\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 16           # adjust to saturate your GPU\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)  # file I/O overlap\n",
    "SHOW_FIRST_N        = None         # None → all frames\n",
    "RETURN_TIMINGS      = False        # True if you want per-frame timing dicts returned\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try:\n",
    "    cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup (avoids first-batch penalty; keep on device)\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                  device=device, conf=CONF, iou=IOU,\n",
    "                  verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed constants\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers (vectorized/fast)\n",
    "# =======================\n",
    "def load_image(path: str):\n",
    "    # Fast path cv2.imread; IMREAD_COLOR is default; avoid extra conversions\n",
    "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    # Color match on ROI only, then CC filter by area/height\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    # [h,w,1,3] - [1,1,K,3] → [h,w,K,3]\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)                       # [h,w,K]\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)                # [h,w]\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)            # bool\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    if n <= 1:\n",
    "        out = np.zeros_like(combined)\n",
    "        full = np.zeros((H, W), dtype=bool)\n",
    "        return full\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    # vectorized filter: get idx of components satisfying both constraints\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    if keep.size:\n",
    "        # fast mask assembly\n",
    "        for k in keep:\n",
    "            good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    # Use box blur; separable under the hood in OpenCV\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def purple_triangle_from_dark_map(score, H):\n",
    "    # Mask score with top/bottom exclusions, morph open, then take CCs\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex:\n",
    "        dark[:top_ex, :] = 0\n",
    "    if bot_ex:\n",
    "        dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None  # no triangle\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    # Keep components meeting both absolute and fractional thresholds\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # For the triangle location: pick the component whose topmost y is smallest\n",
    "    # (closest to top after exclusions), and place triangle at (x_mid, y_top).\n",
    "    y_mins = []\n",
    "    x_mids = []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0:\n",
    "            continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None\n",
    "\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx]))  # (x, y)\n",
    "\n",
    "# =======================\n",
    "# Core processing of one frame (expects YOLO result already on CPU)\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    # masks at model size → union rails → upsample to frame size\n",
    "    if yolo_res.masks is None:\n",
    "        return None  # triangle pos: None\n",
    "\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()          # [n,h,w]\n",
    "    # class vector: prefer masks.cls if present, else boxes.cls\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # union only rail masks\n",
    "    if classes_np.size == 0:\n",
    "        return None\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None\n",
    "\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)          # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8)   # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    # green (target color on rails) vs red\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "\n",
    "    # heat precursor\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri = purple_triangle_from_dark_map(score, H)\n",
    "    return tri  # (x, y) or None\n",
    "\n",
    "# =======================\n",
    "# Batched execution with overlapped disk I/O\n",
    "# =======================\n",
    "def run_pipeline():\n",
    "    # List frames\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    results_triangle_xy = [None] * len(paths)\n",
    "    timings = [None] * len(paths) if RETURN_TIMINGS else None\n",
    "\n",
    "    # Threaded I/O loader\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            future_to_idx = {ex.submit(load_image, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(future_to_idx):\n",
    "                i = future_to_idx[fut]\n",
    "                img = fut.result()\n",
    "                imgs[i] = img\n",
    "        # drop unreadables\n",
    "        ok = [(p, im) for p, im in zip(batch_paths, imgs) if im is not None]\n",
    "        if not ok:\n",
    "            return [], []\n",
    "        batch_paths2, imgs2 = zip(*ok)\n",
    "        return list(batch_paths2), list(imgs2)\n",
    "\n",
    "    # Process in batches\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr = load_batch(batch_paths)\n",
    "        if not imgs_bgr:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        # Inference (batched)\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=len(imgs_bgr)\n",
    "        )\n",
    "        # Ensure device sync so post timing reflects host-only work\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        # Post-process each frame (CPU, vectorized where possible)\n",
    "        t2 = time.perf_counter()\n",
    "        for j, (img, yres) in enumerate(zip(imgs_bgr, res_list)):\n",
    "            tri = process_frame_post(img, yres)\n",
    "            results_triangle_xy[idx_global + j] = tri\n",
    "        t3 = time.perf_counter()\n",
    "\n",
    "        if RETURN_TIMINGS:\n",
    "            # same timings for each frame in batch (approximate)\n",
    "            infer_ms = (t1 - t0) * 1000.0 / max(1, len(imgs_bgr))\n",
    "            post_ms  = (t3 - t2) * 1000.0 / max(1, len(imgs_bgr))\n",
    "            for j in range(len(imgs_bgr)):\n",
    "                timings[idx_global + j] = {\"infer_ms\": infer_ms, \"post_ms\": post_ms}\n",
    "\n",
    "        idx_global += len(imgs_bgr)\n",
    "\n",
    "    return (results_triangle_xy, timings) if RETURN_TIMINGS else results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a73a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 40.0 | infer 675.7 | to_cpu 0.7 | post 151.9 => proc 828.2 ms\n",
      "[2/79] frame_00001.png  read 38.8 | infer 49.6 | to_cpu 1.0 | post 160.2 => proc 210.8 ms\n",
      "[3/79] frame_00002.png  read 36.4 | infer 59.7 | to_cpu 0.9 | post 172.2 => proc 232.7 ms\n",
      "[4/79] frame_00003.png  read 36.4 | infer 37.7 | to_cpu 0.8 | post 170.3 => proc 208.8 ms\n",
      "[5/79] frame_00004.png  read 36.0 | infer 42.0 | to_cpu 0.9 | post 143.9 => proc 186.9 ms\n",
      "[6/79] frame_00005.png  read 43.0 | infer 40.7 | to_cpu 1.0 | post 125.9 => proc 167.6 ms\n",
      "[7/79] frame_00006.png  read 39.8 | infer 41.0 | to_cpu 1.0 | post 122.9 => proc 164.9 ms\n",
      "[8/79] frame_00007.png  read 37.4 | infer 42.4 | to_cpu 1.0 | post 147.6 => proc 191.1 ms\n",
      "[9/79] frame_00008.png  read 37.1 | infer 41.7 | to_cpu 0.8 | post 143.9 => proc 186.4 ms\n",
      "[10/79] frame_00009.png  read 38.1 | infer 40.7 | to_cpu 0.8 | post 156.8 => proc 198.3 ms\n",
      "[11/79] frame_00010.png  read 39.5 | infer 37.8 | to_cpu 0.9 | post 121.0 => proc 159.7 ms\n",
      "[12/79] frame_00011.png  read 38.4 | infer 35.0 | to_cpu 0.8 | post 89.9 => proc 125.8 ms\n",
      "[13/79] frame_00012.png  read 35.8 | infer 34.0 | to_cpu 1.0 | post 47.6 => proc 82.6 ms\n",
      "[14/79] frame_00013.png  read 37.6 | infer 34.9 | to_cpu 0.9 | post 139.1 => proc 174.9 ms\n",
      "[15/79] frame_00014.png  read 36.5 | infer 39.9 | to_cpu 0.8 | post 140.0 => proc 180.7 ms\n",
      "[16/79] frame_00015.png  read 36.6 | infer 41.0 | to_cpu 0.8 | post 90.3 => proc 132.0 ms\n",
      "[17/79] frame_00016.png  read 37.5 | infer 40.5 | to_cpu 0.9 | post 166.9 => proc 208.2 ms\n",
      "[18/79] frame_00017.png  read 37.6 | infer 35.2 | to_cpu 0.9 | post 160.9 => proc 196.9 ms\n",
      "[19/79] frame_00018.png  read 37.3 | infer 45.0 | to_cpu 0.9 | post 149.2 => proc 195.0 ms\n",
      "[20/79] frame_00019.png  read 36.9 | infer 37.4 | to_cpu 0.8 | post 141.0 => proc 179.3 ms\n",
      "[21/79] frame_00020.png  read 38.2 | infer 35.9 | to_cpu 0.9 | post 125.4 => proc 162.2 ms\n",
      "[22/79] frame_00021.png  read 37.6 | infer 42.0 | to_cpu 0.9 | post 156.6 => proc 199.4 ms\n",
      "[23/79] frame_00022.png  read 38.3 | infer 40.8 | to_cpu 0.8 | post 148.5 => proc 190.2 ms\n",
      "[24/79] frame_00023.png  read 37.5 | infer 43.2 | to_cpu 1.0 | post 149.2 => proc 193.4 ms\n",
      "[25/79] frame_00024.png  read 37.4 | infer 40.1 | to_cpu 1.2 | post 154.9 => proc 196.2 ms\n",
      "[26/79] frame_00025.png  read 37.4 | infer 34.9 | to_cpu 0.8 | post 121.4 => proc 157.1 ms\n",
      "[27/79] frame_00026.png  read 47.5 | infer 38.5 | to_cpu 0.8 | post 105.5 => proc 144.8 ms\n",
      "[28/79] frame_00027.png  read 37.8 | infer 34.6 | to_cpu 0.9 | post 161.1 => proc 196.6 ms\n",
      "[29/79] frame_00028.png  read 37.2 | infer 40.6 | to_cpu 1.1 | post 124.1 => proc 165.8 ms\n",
      "[30/79] frame_00029.png  read 38.4 | infer 42.9 | to_cpu 1.1 | post 114.8 => proc 158.8 ms\n",
      "[31/79] frame_00030.png  read 37.1 | infer 39.7 | to_cpu 0.8 | post 115.8 => proc 156.3 ms\n",
      "[32/79] frame_00031.png  read 37.5 | infer 38.4 | to_cpu 0.8 | post 157.7 => proc 196.9 ms\n",
      "[33/79] frame_00032.png  read 36.9 | infer 37.7 | to_cpu 0.8 | post 145.3 => proc 183.7 ms\n",
      "[34/79] frame_00033.png  read 37.5 | infer 43.5 | to_cpu 1.0 | post 98.8 => proc 143.3 ms\n",
      "[35/79] frame_00034.png  read 35.0 | infer 41.0 | to_cpu 0.8 | post 165.7 => proc 207.4 ms\n",
      "[36/79] frame_00035.png  read 31.2 | infer 42.8 | to_cpu 0.6 | post 96.8 => proc 140.2 ms\n",
      "[37/79] frame_00036.png  read 37.5 | infer 40.6 | to_cpu 1.1 | post 155.0 => proc 196.7 ms\n",
      "[38/79] frame_00037.png  read 36.5 | infer 43.2 | to_cpu 0.8 | post 175.1 => proc 219.2 ms\n",
      "[39/79] frame_00038.png  read 36.5 | infer 37.2 | to_cpu 1.0 | post 161.3 => proc 199.5 ms\n",
      "[40/79] frame_00039.png  read 36.1 | infer 38.4 | to_cpu 0.9 | post 0.0 => proc 39.3 ms\n",
      "[41/79] frame_00040.png  read 36.5 | infer 42.2 | to_cpu 1.1 | post 80.7 => proc 124.0 ms\n",
      "[42/79] frame_00041.png  read 37.8 | infer 44.2 | to_cpu 1.0 | post 88.5 => proc 133.7 ms\n",
      "[43/79] frame_00042.png  read 38.3 | infer 38.7 | to_cpu 0.9 | post 81.7 => proc 121.2 ms\n",
      "[44/79] frame_00043.png  read 38.6 | infer 45.9 | to_cpu 1.0 | post 85.7 => proc 132.6 ms\n",
      "[45/79] frame_00044.png  read 36.9 | infer 39.9 | to_cpu 0.9 | post 58.0 => proc 98.7 ms\n",
      "[46/79] frame_00045.png  read 37.7 | infer 38.7 | to_cpu 1.0 | post 121.4 => proc 161.2 ms\n",
      "[47/79] frame_00046.png  read 38.4 | infer 40.9 | to_cpu 1.8 | post 83.2 => proc 125.9 ms\n",
      "[48/79] frame_00047.png  read 38.7 | infer 40.6 | to_cpu 1.1 | post 90.6 => proc 132.3 ms\n",
      "[49/79] frame_00048.png  read 37.6 | infer 39.4 | to_cpu 1.0 | post 95.7 => proc 136.1 ms\n",
      "[50/79] frame_00049.png  read 36.6 | infer 40.1 | to_cpu 0.9 | post 150.6 => proc 191.5 ms\n",
      "[51/79] frame_00050.png  read 37.2 | infer 38.7 | to_cpu 0.8 | post 148.7 => proc 188.2 ms\n",
      "[52/79] frame_00051.png  read 36.9 | infer 41.2 | to_cpu 0.9 | post 61.7 => proc 103.8 ms\n",
      "[53/79] frame_00052.png  read 59.9 | infer 43.0 | to_cpu 1.0 | post 120.4 => proc 164.4 ms\n",
      "[54/79] frame_00053.png  read 37.5 | infer 39.7 | to_cpu 0.8 | post 138.7 => proc 179.2 ms\n",
      "[55/79] frame_00054.png  read 35.9 | infer 38.1 | to_cpu 0.8 | post 157.2 => proc 196.2 ms\n",
      "[56/79] frame_00055.png  read 35.8 | infer 39.5 | to_cpu 0.8 | post 152.5 => proc 192.8 ms\n",
      "[57/79] frame_00056.png  read 36.2 | infer 43.6 | to_cpu 0.7 | post 154.3 => proc 198.6 ms\n",
      "[58/79] frame_00057.png  read 35.8 | infer 32.3 | to_cpu 0.9 | post 130.1 => proc 163.2 ms\n",
      "[59/79] frame_00058.png  read 35.6 | infer 39.0 | to_cpu 0.8 | post 157.3 => proc 197.1 ms\n",
      "[60/79] frame_00059.png  read 35.5 | infer 46.2 | to_cpu 1.5 | post 154.6 => proc 202.2 ms\n",
      "[61/79] frame_00060.png  read 37.3 | infer 46.1 | to_cpu 0.9 | post 162.0 => proc 208.9 ms\n",
      "[62/79] frame_00061.png  read 37.1 | infer 35.7 | to_cpu 1.0 | post 162.4 => proc 199.2 ms\n",
      "[63/79] frame_00062.png  read 37.2 | infer 36.6 | to_cpu 1.0 | post 0.0 => proc 37.6 ms\n",
      "[64/79] frame_00063.png  read 37.5 | infer 42.5 | to_cpu 1.1 | post 0.0 => proc 43.6 ms\n",
      "[65/79] frame_00064.png  read 37.9 | infer 37.5 | to_cpu 1.0 | post 134.5 => proc 173.1 ms\n",
      "[66/79] frame_00065.png  read 37.4 | infer 38.7 | to_cpu 0.7 | post 156.3 => proc 195.8 ms\n",
      "[67/79] frame_00066.png  read 36.9 | infer 39.2 | to_cpu 0.8 | post 152.7 => proc 192.7 ms\n",
      "[68/79] frame_00067.png  read 36.7 | infer 45.9 | to_cpu 1.1 | post 0.0 => proc 47.0 ms\n",
      "[69/79] frame_00068.png  read 36.7 | infer 39.6 | to_cpu 0.8 | post 95.5 => proc 135.9 ms\n",
      "[70/79] frame_00069.png  read 37.4 | infer 34.9 | to_cpu 0.7 | post 129.4 => proc 165.0 ms\n",
      "[71/79] frame_00070.png  read 36.5 | infer 43.0 | to_cpu 0.8 | post 155.6 => proc 199.3 ms\n",
      "[72/79] frame_00071.png  read 36.6 | infer 32.7 | to_cpu 0.7 | post 159.7 => proc 193.0 ms\n",
      "[73/79] frame_00072.png  read 36.6 | infer 39.4 | to_cpu 0.7 | post 167.4 => proc 207.5 ms\n",
      "[74/79] frame_00073.png  read 36.9 | infer 41.3 | to_cpu 0.6 | post 167.0 => proc 208.9 ms\n",
      "[75/79] frame_00074.png  read 34.8 | infer 41.5 | to_cpu 0.9 | post 170.4 => proc 212.8 ms\n",
      "[76/79] frame_00075.png  read 27.2 | infer 55.5 | to_cpu 0.6 | post 77.5 => proc 133.6 ms\n",
      "[77/79] frame_00076.png  read 17.7 | infer 22.3 | to_cpu 0.0 | post 0.0 => proc 22.3 ms\n",
      "[78/79] frame_00077.png  read 17.6 | infer 22.7 | to_cpu 0.0 | post 0.0 => proc 22.7 ms\n",
      "[79/79] frame_00078.png  read 17.4 | infer 23.1 | to_cpu 0.0 | post 0.0 => proc 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing prints\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1                            # tune to your GPU\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None                          # None → all frames\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed constants\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def purple_triangle_from_dark_map(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    y_mins, x_mids = [], []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0: continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx]))\n",
    "\n",
    "# Return: tri, to_cpu_ms, post_ms (per-frame)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if classes_np.size == 0:\n",
    "        return None, to_cpu_ms, 0.0\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, to_cpu_ms, 0.0\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri   = purple_triangle_from_dark_map(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri, to_cpu_ms, post_ms\n",
    "\n",
    "# =======================\n",
    "# Batched execution with overlapped disk I/O + per-frame prints\n",
    "# =======================\n",
    "def run_pipeline_with_prints():\n",
    "    # Gather frames\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    # Threaded I/O\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        # Batched inference\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        # Device sync so timing is clean\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B  # approx per-frame share\n",
    "\n",
    "        # Per-frame post + prints\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            t0_post_all = time.perf_counter()\n",
    "            tri, to_cpu_ms, post_ms = process_frame_post(img, yres)\n",
    "            t1_post_all = time.perf_counter()  # includes everything inside post\n",
    "            results_triangle_xy[idx_global + j] = tri\n",
    "\n",
    "            # Compose per-frame timing\n",
    "            infer_ms = infer_ms_share\n",
    "            # post_ms already measured (CPU only after to_cpu)\n",
    "            proc_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91a0bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 49.8 | infer 131.7 | to_cpu 0.8 | post 157.2 | masks 4 | triangles 1 => proc 289.8 ms\n",
      "[2/79] frame_00001.png  read 44.2 | infer 46.9 | to_cpu 1.2 | post 164.3 | masks 6 | triangles 1 => proc 212.4 ms\n",
      "[3/79] frame_00002.png  read 37.2 | infer 55.9 | to_cpu 0.9 | post 316.5 | masks 3 | triangles 3 => proc 373.3 ms\n",
      "[4/79] frame_00003.png  read 36.6 | infer 39.6 | to_cpu 0.7 | post 157.4 | masks 3 | triangles 2 => proc 197.7 ms\n",
      "[5/79] frame_00004.png  read 45.6 | infer 45.6 | to_cpu 0.8 | post 187.1 | masks 5 | triangles 1 => proc 233.5 ms\n",
      "[6/79] frame_00005.png  read 36.3 | infer 43.9 | to_cpu 0.9 | post 130.8 | masks 4 | triangles 1 => proc 175.6 ms\n",
      "[7/79] frame_00006.png  read 37.1 | infer 44.3 | to_cpu 1.1 | post 122.8 | masks 5 | triangles 1 => proc 168.1 ms\n",
      "[8/79] frame_00007.png  read 38.0 | infer 41.0 | to_cpu 1.0 | post 148.0 | masks 6 | triangles 2 => proc 190.0 ms\n",
      "[9/79] frame_00008.png  read 38.5 | infer 43.6 | to_cpu 2.3 | post 146.1 | masks 6 | triangles 2 => proc 192.0 ms\n",
      "[10/79] frame_00009.png  read 38.1 | infer 45.5 | to_cpu 1.3 | post 162.1 | masks 4 | triangles 2 => proc 208.9 ms\n",
      "[11/79] frame_00010.png  read 39.5 | infer 38.6 | to_cpu 0.8 | post 119.8 | masks 4 | triangles 1 => proc 159.2 ms\n",
      "[12/79] frame_00011.png  read 38.0 | infer 34.6 | to_cpu 1.4 | post 91.6 | masks 4 | triangles 1 => proc 127.7 ms\n",
      "[13/79] frame_00012.png  read 41.9 | infer 42.6 | to_cpu 1.0 | post 51.7 | masks 6 | triangles 1 => proc 95.3 ms\n",
      "[14/79] frame_00013.png  read 37.8 | infer 36.5 | to_cpu 0.9 | post 135.9 | masks 5 | triangles 2 => proc 173.4 ms\n",
      "[15/79] frame_00014.png  read 37.8 | infer 43.1 | to_cpu 0.8 | post 140.0 | masks 4 | triangles 2 => proc 183.9 ms\n",
      "[16/79] frame_00015.png  read 36.8 | infer 46.6 | to_cpu 0.9 | post 88.5 | masks 4 | triangles 1 => proc 136.0 ms\n",
      "[17/79] frame_00016.png  read 37.6 | infer 44.7 | to_cpu 1.8 | post 164.6 | masks 5 | triangles 2 => proc 211.1 ms\n",
      "[18/79] frame_00017.png  read 36.7 | infer 37.2 | to_cpu 0.9 | post 166.8 | masks 5 | triangles 2 => proc 204.9 ms\n",
      "[19/79] frame_00018.png  read 36.9 | infer 42.1 | to_cpu 1.0 | post 155.6 | masks 6 | triangles 2 => proc 198.7 ms\n",
      "[20/79] frame_00019.png  read 37.7 | infer 38.3 | to_cpu 1.1 | post 147.5 | masks 4 | triangles 2 => proc 186.9 ms\n",
      "[21/79] frame_00020.png  read 37.5 | infer 40.1 | to_cpu 0.9 | post 131.4 | masks 4 | triangles 1 => proc 172.4 ms\n",
      "[22/79] frame_00021.png  read 36.9 | infer 41.2 | to_cpu 1.0 | post 159.9 | masks 5 | triangles 2 => proc 202.1 ms\n",
      "[23/79] frame_00022.png  read 37.8 | infer 40.2 | to_cpu 0.9 | post 144.8 | masks 5 | triangles 2 => proc 185.9 ms\n",
      "[24/79] frame_00023.png  read 38.7 | infer 43.6 | to_cpu 1.1 | post 147.6 | masks 8 | triangles 1 => proc 192.2 ms\n",
      "[25/79] frame_00024.png  read 37.7 | infer 49.0 | to_cpu 0.8 | post 153.5 | masks 5 | triangles 2 => proc 203.3 ms\n",
      "[26/79] frame_00025.png  read 38.1 | infer 34.3 | to_cpu 0.8 | post 117.9 | masks 4 | triangles 1 => proc 153.0 ms\n",
      "[27/79] frame_00026.png  read 37.7 | infer 38.5 | to_cpu 0.9 | post 105.9 | masks 3 | triangles 1 => proc 145.2 ms\n",
      "[28/79] frame_00027.png  read 37.2 | infer 35.3 | to_cpu 0.8 | post 156.9 | masks 4 | triangles 2 => proc 193.1 ms\n",
      "[29/79] frame_00028.png  read 37.9 | infer 41.7 | to_cpu 0.9 | post 124.9 | masks 5 | triangles 1 => proc 167.5 ms\n",
      "[30/79] frame_00029.png  read 38.5 | infer 36.5 | to_cpu 1.1 | post 115.4 | masks 5 | triangles 1 => proc 153.0 ms\n",
      "[31/79] frame_00030.png  read 37.7 | infer 39.2 | to_cpu 0.7 | post 115.9 | masks 3 | triangles 2 => proc 155.9 ms\n",
      "[32/79] frame_00031.png  read 38.1 | infer 37.9 | to_cpu 1.0 | post 160.9 | masks 4 | triangles 2 => proc 199.8 ms\n",
      "[33/79] frame_00032.png  read 37.8 | infer 37.1 | to_cpu 0.9 | post 150.1 | masks 3 | triangles 2 => proc 188.1 ms\n",
      "[34/79] frame_00033.png  read 38.0 | infer 42.6 | to_cpu 1.0 | post 87.9 | masks 5 | triangles 1 => proc 131.5 ms\n",
      "[35/79] frame_00034.png  read 36.0 | infer 50.0 | to_cpu 0.7 | post 163.8 | masks 4 | triangles 2 => proc 214.5 ms\n",
      "[36/79] frame_00035.png  read 30.5 | infer 47.1 | to_cpu 0.7 | post 97.6 | masks 2 | triangles 1 => proc 145.4 ms\n",
      "[37/79] frame_00036.png  read 37.5 | infer 38.7 | to_cpu 0.8 | post 159.4 | masks 4 | triangles 2 => proc 199.0 ms\n",
      "[38/79] frame_00037.png  read 37.4 | infer 42.3 | to_cpu 0.8 | post 176.7 | masks 4 | triangles 3 => proc 219.9 ms\n",
      "[39/79] frame_00038.png  read 36.9 | infer 38.4 | to_cpu 0.8 | post 158.0 | masks 4 | triangles 2 => proc 197.2 ms\n",
      "[40/79] frame_00039.png  read 36.6 | infer 37.5 | to_cpu 0.9 | post 0.0 | masks 5 | triangles 0 => proc 38.3 ms\n",
      "[41/79] frame_00040.png  read 36.7 | infer 44.4 | to_cpu 1.2 | post 83.9 | masks 8 | triangles 1 => proc 129.5 ms\n",
      "[42/79] frame_00041.png  read 36.9 | infer 42.5 | to_cpu 1.3 | post 88.9 | masks 9 | triangles 1 => proc 132.7 ms\n",
      "[43/79] frame_00042.png  read 40.5 | infer 38.3 | to_cpu 1.5 | post 82.8 | masks 5 | triangles 1 => proc 122.5 ms\n",
      "[44/79] frame_00043.png  read 37.9 | infer 42.0 | to_cpu 0.9 | post 85.8 | masks 7 | triangles 2 => proc 128.7 ms\n",
      "[45/79] frame_00044.png  read 36.6 | infer 54.3 | to_cpu 1.1 | post 58.3 | masks 6 | triangles 1 => proc 113.8 ms\n",
      "[46/79] frame_00045.png  read 37.5 | infer 39.1 | to_cpu 0.9 | post 123.3 | masks 5 | triangles 2 => proc 163.3 ms\n",
      "[47/79] frame_00046.png  read 41.3 | infer 39.8 | to_cpu 0.9 | post 84.1 | masks 5 | triangles 2 => proc 124.8 ms\n",
      "[48/79] frame_00047.png  read 37.9 | infer 40.1 | to_cpu 0.9 | post 89.2 | masks 7 | triangles 2 => proc 130.2 ms\n",
      "[49/79] frame_00048.png  read 41.1 | infer 38.6 | to_cpu 0.9 | post 93.0 | masks 5 | triangles 1 => proc 132.4 ms\n",
      "[50/79] frame_00049.png  read 37.5 | infer 62.4 | to_cpu 0.9 | post 142.7 | masks 4 | triangles 1 => proc 205.9 ms\n",
      "[51/79] frame_00050.png  read 38.1 | infer 37.7 | to_cpu 1.0 | post 164.7 | masks 3 | triangles 3 => proc 203.4 ms\n",
      "[52/79] frame_00051.png  read 37.7 | infer 41.9 | to_cpu 1.0 | post 62.4 | masks 6 | triangles 2 => proc 105.4 ms\n",
      "[53/79] frame_00052.png  read 37.3 | infer 40.7 | to_cpu 1.0 | post 117.7 | masks 8 | triangles 1 => proc 159.5 ms\n",
      "[54/79] frame_00053.png  read 37.3 | infer 41.0 | to_cpu 0.9 | post 139.6 | masks 6 | triangles 2 => proc 181.5 ms\n",
      "[55/79] frame_00054.png  read 35.6 | infer 43.4 | to_cpu 0.9 | post 156.4 | masks 5 | triangles 3 => proc 200.7 ms\n",
      "[56/79] frame_00055.png  read 36.3 | infer 39.1 | to_cpu 0.8 | post 145.7 | masks 4 | triangles 1 => proc 185.6 ms\n",
      "[57/79] frame_00056.png  read 36.3 | infer 44.4 | to_cpu 0.8 | post 154.5 | masks 3 | triangles 2 => proc 199.6 ms\n",
      "[58/79] frame_00057.png  read 36.8 | infer 34.9 | to_cpu 0.9 | post 121.6 | masks 4 | triangles 1 => proc 157.3 ms\n",
      "[59/79] frame_00058.png  read 35.0 | infer 40.9 | to_cpu 0.8 | post 156.2 | masks 4 | triangles 2 => proc 197.9 ms\n",
      "[60/79] frame_00059.png  read 36.1 | infer 41.8 | to_cpu 1.3 | post 157.3 | masks 6 | triangles 2 => proc 200.3 ms\n",
      "[61/79] frame_00060.png  read 41.7 | infer 50.0 | to_cpu 0.9 | post 161.1 | masks 5 | triangles 3 => proc 212.1 ms\n",
      "[62/79] frame_00061.png  read 38.4 | infer 34.2 | to_cpu 1.0 | post 154.7 | masks 6 | triangles 2 => proc 189.8 ms\n",
      "[63/79] frame_00062.png  read 37.5 | infer 36.1 | to_cpu 1.0 | post 0.0 | masks 6 | triangles 0 => proc 37.1 ms\n",
      "[64/79] frame_00063.png  read 38.0 | infer 41.7 | to_cpu 1.1 | post 0.0 | masks 8 | triangles 0 => proc 42.8 ms\n",
      "[65/79] frame_00064.png  read 38.0 | infer 38.2 | to_cpu 0.9 | post 132.2 | masks 7 | triangles 3 => proc 171.3 ms\n",
      "[66/79] frame_00065.png  read 37.0 | infer 39.3 | to_cpu 0.7 | post 155.3 | masks 3 | triangles 2 => proc 195.4 ms\n",
      "[67/79] frame_00066.png  read 37.8 | infer 37.9 | to_cpu 1.6 | post 149.6 | masks 5 | triangles 2 => proc 189.1 ms\n",
      "[68/79] frame_00067.png  read 37.2 | infer 41.7 | to_cpu 1.0 | post 0.0 | masks 7 | triangles 0 => proc 42.6 ms\n",
      "[69/79] frame_00068.png  read 36.0 | infer 40.9 | to_cpu 0.8 | post 94.6 | masks 4 | triangles 1 => proc 136.2 ms\n",
      "[70/79] frame_00069.png  read 38.3 | infer 36.4 | to_cpu 0.8 | post 245.9 | masks 3 | triangles 1 => proc 283.1 ms\n",
      "[71/79] frame_00070.png  read 37.2 | infer 42.0 | to_cpu 0.7 | post 160.1 | masks 2 | triangles 2 => proc 202.7 ms\n",
      "[72/79] frame_00071.png  read 37.0 | infer 33.5 | to_cpu 0.6 | post 157.3 | masks 2 | triangles 2 => proc 191.4 ms\n",
      "[73/79] frame_00072.png  read 37.7 | infer 41.9 | to_cpu 0.6 | post 167.7 | masks 2 | triangles 2 => proc 210.3 ms\n",
      "[74/79] frame_00073.png  read 37.2 | infer 42.0 | to_cpu 0.8 | post 172.1 | masks 2 | triangles 2 => proc 214.9 ms\n",
      "[75/79] frame_00074.png  read 35.4 | infer 39.3 | to_cpu 0.9 | post 170.8 | masks 3 | triangles 2 => proc 211.0 ms\n",
      "[76/79] frame_00075.png  read 27.0 | infer 34.6 | to_cpu 0.7 | post 74.5 | masks 2 | triangles 1 => proc 109.7 ms\n",
      "[77/79] frame_00076.png  read 18.1 | infer 22.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.1 ms\n",
      "[78/79] frame_00077.png  read 17.4 | infer 23.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.6 ms\n",
      "[79/79] frame_00078.png  read 17.2 | infer 21.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None  # None → all\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "# Returns: (best_triangle_xy or None, triangle_count)\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None, 0\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None, 0\n",
    "\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    tri_count = len(candidates)\n",
    "    if tri_count == 0:\n",
    "        return None, 0\n",
    "\n",
    "    y_mins, x_mids = [], []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0: \n",
    "            continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None, tri_count\n",
    "\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx])), tri_count\n",
    "\n",
    "# Returns: (tri_xy, tri_count, mask_count, to_cpu_ms, post_ms)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_xy, tri_count = purple_triangles(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_xy, tri_count, mask_count, to_cpu_ms, post_ms\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints\n",
    "# =======================\n",
    "def run_pipeline_with_prints():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            tri_xy, tri_count, mask_count, to_cpu_ms, post_ms = process_frame_post(img, yres)\n",
    "            results_triangle_xy[idx_global + j] = tri_xy\n",
    "\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            # NEW: print mask_count and triangle_count\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eaa1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 40.8 | infer 344.9 | to_cpu 1.2 | post 156.2 | masks 4 | triangles 1 => proc 502.3 ms\n",
      "[2/79] frame_00001.png  read 36.6 | infer 64.2 | to_cpu 1.0 | post 161.6 | masks 6 | triangles 1 => proc 226.8 ms\n",
      "[3/79] frame_00002.png  read 90.8 | infer 330.4 | to_cpu 0.8 | post 179.6 | masks 3 | triangles 3 => proc 510.8 ms\n",
      "[4/79] frame_00003.png  read 44.1 | infer 45.2 | to_cpu 0.7 | post 154.6 | masks 3 | triangles 2 => proc 200.5 ms\n",
      "[5/79] frame_00004.png  read 36.7 | infer 63.4 | to_cpu 0.9 | post 144.7 | masks 5 | triangles 1 => proc 209.0 ms\n",
      "[6/79] frame_00005.png  read 36.4 | infer 46.0 | to_cpu 0.8 | post 119.1 | masks 4 | triangles 1 => proc 165.9 ms\n",
      "[7/79] frame_00006.png  read 38.5 | infer 46.8 | to_cpu 0.8 | post 117.7 | masks 5 | triangles 1 => proc 165.3 ms\n",
      "[8/79] frame_00007.png  read 36.8 | infer 47.7 | to_cpu 0.9 | post 155.4 | masks 6 | triangles 2 => proc 204.0 ms\n",
      "[9/79] frame_00008.png  read 37.7 | infer 43.3 | to_cpu 1.0 | post 143.4 | masks 6 | triangles 2 => proc 187.8 ms\n",
      "[10/79] frame_00009.png  read 36.5 | infer 48.4 | to_cpu 0.7 | post 159.3 | masks 4 | triangles 2 => proc 208.5 ms\n",
      "[11/79] frame_00010.png  read 38.3 | infer 42.3 | to_cpu 0.8 | post 123.3 | masks 4 | triangles 1 => proc 166.4 ms\n",
      "[12/79] frame_00011.png  read 36.9 | infer 34.7 | to_cpu 0.9 | post 91.6 | masks 4 | triangles 1 => proc 127.3 ms\n",
      "[13/79] frame_00012.png  read 36.3 | infer 33.1 | to_cpu 0.9 | post 52.9 | masks 6 | triangles 1 => proc 86.9 ms\n",
      "[14/79] frame_00013.png  read 37.6 | infer 37.8 | to_cpu 1.0 | post 134.5 | masks 5 | triangles 2 => proc 173.2 ms\n",
      "[15/79] frame_00014.png  read 36.8 | infer 42.3 | to_cpu 0.8 | post 143.5 | masks 4 | triangles 2 => proc 186.5 ms\n",
      "[16/79] frame_00015.png  read 35.9 | infer 41.9 | to_cpu 0.7 | post 87.6 | masks 4 | triangles 1 => proc 130.2 ms\n",
      "[17/79] frame_00016.png  read 38.5 | infer 46.7 | to_cpu 0.8 | post 164.9 | masks 5 | triangles 2 => proc 212.4 ms\n",
      "[18/79] frame_00017.png  read 37.0 | infer 33.9 | to_cpu 0.9 | post 161.2 | masks 5 | triangles 2 => proc 196.1 ms\n",
      "[19/79] frame_00018.png  read 38.7 | infer 43.2 | to_cpu 0.8 | post 150.5 | masks 6 | triangles 2 => proc 194.5 ms\n",
      "[20/79] frame_00019.png  read 36.5 | infer 33.3 | to_cpu 0.9 | post 140.5 | masks 4 | triangles 2 => proc 174.7 ms\n",
      "[21/79] frame_00020.png  read 37.9 | infer 33.4 | to_cpu 0.8 | post 127.5 | masks 4 | triangles 1 => proc 161.8 ms\n",
      "[22/79] frame_00021.png  read 37.1 | infer 52.7 | to_cpu 1.0 | post 156.4 | masks 5 | triangles 2 => proc 210.1 ms\n",
      "[23/79] frame_00022.png  read 39.0 | infer 45.8 | to_cpu 0.8 | post 162.8 | masks 5 | triangles 2 => proc 209.5 ms\n",
      "[24/79] frame_00023.png  read 37.4 | infer 53.8 | to_cpu 0.9 | post 145.8 | masks 8 | triangles 1 => proc 200.6 ms\n",
      "[25/79] frame_00024.png  read 37.5 | infer 41.5 | to_cpu 0.8 | post 161.2 | masks 5 | triangles 2 => proc 203.5 ms\n",
      "[26/79] frame_00025.png  read 37.6 | infer 33.1 | to_cpu 0.8 | post 118.8 | masks 4 | triangles 1 => proc 152.7 ms\n",
      "[27/79] frame_00026.png  read 36.8 | infer 38.0 | to_cpu 0.7 | post 103.9 | masks 3 | triangles 1 => proc 142.7 ms\n",
      "[28/79] frame_00027.png  read 36.5 | infer 37.6 | to_cpu 0.7 | post 162.3 | masks 4 | triangles 2 => proc 200.6 ms\n",
      "[29/79] frame_00028.png  read 38.3 | infer 41.9 | to_cpu 0.8 | post 135.5 | masks 5 | triangles 1 => proc 178.2 ms\n",
      "[30/79] frame_00029.png  read 38.2 | infer 41.2 | to_cpu 1.0 | post 117.1 | masks 5 | triangles 1 => proc 159.2 ms\n",
      "[31/79] frame_00030.png  read 38.3 | infer 50.0 | to_cpu 0.9 | post 126.9 | masks 3 | triangles 2 => proc 177.8 ms\n",
      "[32/79] frame_00031.png  read 42.4 | infer 208.5 | to_cpu 1.0 | post 196.5 | masks 4 | triangles 2 => proc 406.0 ms\n",
      "[33/79] frame_00032.png  read 37.9 | infer 42.6 | to_cpu 0.7 | post 152.2 | masks 3 | triangles 2 => proc 195.5 ms\n",
      "[34/79] frame_00033.png  read 37.5 | infer 49.4 | to_cpu 0.9 | post 87.7 | masks 5 | triangles 1 => proc 138.1 ms\n",
      "[35/79] frame_00034.png  read 35.9 | infer 49.6 | to_cpu 0.7 | post 182.5 | masks 4 | triangles 2 => proc 232.8 ms\n",
      "[36/79] frame_00035.png  read 33.1 | infer 90.7 | to_cpu 0.8 | post 109.1 | masks 2 | triangles 1 => proc 200.7 ms\n",
      "[37/79] frame_00036.png  read 36.4 | infer 49.1 | to_cpu 0.8 | post 168.0 | masks 4 | triangles 2 => proc 217.9 ms\n",
      "[38/79] frame_00037.png  read 37.0 | infer 58.8 | to_cpu 0.9 | post 188.1 | masks 4 | triangles 3 => proc 247.8 ms\n",
      "[39/79] frame_00038.png  read 44.0 | infer 50.4 | to_cpu 0.8 | post 195.4 | masks 4 | triangles 2 => proc 246.7 ms\n",
      "[40/79] frame_00039.png  read 37.1 | infer 43.7 | to_cpu 1.0 | post 0.0 | masks 5 | triangles 0 => proc 44.7 ms\n",
      "[41/79] frame_00040.png  read 42.4 | infer 56.2 | to_cpu 1.6 | post 114.5 | masks 8 | triangles 1 => proc 172.3 ms\n",
      "[42/79] frame_00041.png  read 36.2 | infer 68.5 | to_cpu 1.0 | post 98.0 | masks 9 | triangles 1 => proc 167.5 ms\n",
      "[43/79] frame_00042.png  read 45.1 | infer 59.5 | to_cpu 0.9 | post 99.5 | masks 5 | triangles 1 => proc 159.9 ms\n",
      "[44/79] frame_00043.png  read 38.0 | infer 74.6 | to_cpu 1.9 | post 97.3 | masks 7 | triangles 2 => proc 173.8 ms\n",
      "[45/79] frame_00044.png  read 36.8 | infer 56.2 | to_cpu 1.0 | post 61.5 | masks 6 | triangles 1 => proc 118.7 ms\n",
      "[46/79] frame_00045.png  read 37.1 | infer 51.6 | to_cpu 1.0 | post 134.1 | masks 5 | triangles 2 => proc 186.8 ms\n",
      "[47/79] frame_00046.png  read 48.7 | infer 59.9 | to_cpu 0.8 | post 88.7 | masks 5 | triangles 2 => proc 149.4 ms\n",
      "[48/79] frame_00047.png  read 62.6 | infer 65.2 | to_cpu 1.1 | post 106.1 | masks 7 | triangles 2 => proc 172.4 ms\n",
      "[49/79] frame_00048.png  read 38.4 | infer 38.8 | to_cpu 1.7 | post 95.9 | masks 5 | triangles 1 => proc 136.3 ms\n",
      "[50/79] frame_00049.png  read 38.6 | infer 46.9 | to_cpu 1.0 | post 147.7 | masks 4 | triangles 1 => proc 195.7 ms\n",
      "[51/79] frame_00050.png  read 36.9 | infer 40.3 | to_cpu 0.7 | post 153.3 | masks 3 | triangles 3 => proc 194.3 ms\n",
      "[52/79] frame_00051.png  read 39.6 | infer 50.4 | to_cpu 0.8 | post 63.6 | masks 6 | triangles 2 => proc 114.8 ms\n",
      "[53/79] frame_00052.png  read 41.8 | infer 48.6 | to_cpu 1.1 | post 117.5 | masks 8 | triangles 1 => proc 167.2 ms\n",
      "[54/79] frame_00053.png  read 37.6 | infer 35.7 | to_cpu 1.0 | post 140.8 | masks 6 | triangles 2 => proc 177.5 ms\n",
      "[55/79] frame_00054.png  read 36.1 | infer 45.0 | to_cpu 0.8 | post 160.9 | masks 5 | triangles 3 => proc 206.7 ms\n",
      "[56/79] frame_00055.png  read 35.0 | infer 53.0 | to_cpu 7.6 | post 155.5 | masks 4 | triangles 1 => proc 216.1 ms\n",
      "[57/79] frame_00056.png  read 36.3 | infer 45.7 | to_cpu 0.7 | post 157.2 | masks 3 | triangles 2 => proc 203.5 ms\n",
      "[58/79] frame_00057.png  read 37.3 | infer 35.4 | to_cpu 0.8 | post 121.9 | masks 4 | triangles 1 => proc 158.1 ms\n",
      "[59/79] frame_00058.png  read 37.2 | infer 40.2 | to_cpu 0.8 | post 161.0 | masks 4 | triangles 2 => proc 202.0 ms\n",
      "[60/79] frame_00059.png  read 35.7 | infer 40.5 | to_cpu 1.0 | post 155.6 | masks 6 | triangles 2 => proc 197.0 ms\n",
      "[61/79] frame_00060.png  read 36.5 | infer 45.6 | to_cpu 0.8 | post 161.9 | masks 5 | triangles 3 => proc 208.3 ms\n",
      "[62/79] frame_00061.png  read 40.8 | infer 36.3 | to_cpu 0.9 | post 162.3 | masks 6 | triangles 2 => proc 199.4 ms\n",
      "[63/79] frame_00062.png  read 39.3 | infer 36.0 | to_cpu 1.0 | post 0.0 | masks 6 | triangles 0 => proc 37.0 ms\n",
      "[64/79] frame_00063.png  read 37.6 | infer 42.6 | to_cpu 1.1 | post 0.0 | masks 8 | triangles 0 => proc 43.7 ms\n",
      "[65/79] frame_00064.png  read 37.9 | infer 39.5 | to_cpu 1.0 | post 143.3 | masks 7 | triangles 3 => proc 183.9 ms\n",
      "[66/79] frame_00065.png  read 47.1 | infer 36.5 | to_cpu 0.8 | post 160.5 | masks 3 | triangles 2 => proc 197.8 ms\n",
      "[67/79] frame_00066.png  read 38.4 | infer 38.9 | to_cpu 1.0 | post 152.2 | masks 5 | triangles 2 => proc 192.1 ms\n",
      "[68/79] frame_00067.png  read 37.5 | infer 45.9 | to_cpu 0.9 | post 0.0 | masks 7 | triangles 0 => proc 46.8 ms\n",
      "[69/79] frame_00068.png  read 37.8 | infer 40.5 | to_cpu 0.8 | post 101.0 | masks 4 | triangles 1 => proc 142.3 ms\n",
      "[70/79] frame_00069.png  read 37.6 | infer 34.7 | to_cpu 0.8 | post 132.1 | masks 3 | triangles 1 => proc 167.6 ms\n",
      "[71/79] frame_00070.png  read 36.5 | infer 50.7 | to_cpu 0.9 | post 157.1 | masks 2 | triangles 2 => proc 208.7 ms\n",
      "[72/79] frame_00071.png  read 36.8 | infer 33.1 | to_cpu 0.7 | post 155.4 | masks 2 | triangles 2 => proc 189.2 ms\n",
      "[73/79] frame_00072.png  read 36.8 | infer 47.0 | to_cpu 0.7 | post 167.1 | masks 2 | triangles 2 => proc 214.7 ms\n",
      "[74/79] frame_00073.png  read 38.0 | infer 45.3 | to_cpu 0.5 | post 162.9 | masks 2 | triangles 2 => proc 208.8 ms\n",
      "[75/79] frame_00074.png  read 34.6 | infer 43.9 | to_cpu 0.8 | post 163.4 | masks 3 | triangles 2 => proc 208.1 ms\n",
      "[76/79] frame_00075.png  read 30.7 | infer 33.8 | to_cpu 0.7 | post 75.1 | masks 2 | triangles 1 => proc 109.5 ms\n",
      "[77/79] frame_00076.png  read 18.4 | infer 22.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.2 ms\n",
      "[78/79] frame_00077.png  read 17.8 | infer 23.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.5 ms\n",
      "[79/79] frame_00078.png  read 17.3 | infer 32.0 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 32.0 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now also renders ALL masks + purple triangles onto ORIGINAL frames for first N=20 (excluded from timings)\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None  # None → all frames\n",
    "RENDER_FIRST_N      = 50    # render overlays for first 20 frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "# Returns: (list_of_triangle_xy, best_xy_or_None)\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: \n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    # best is the one with smallest y (closest to top)\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, and purple triangles on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        # upsample masks to frame res only once per mask\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            # overlay\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            # label near centroid\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Rail tint + green highlight (if available)\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Draw ALL purple triangles we found\n",
    "    for (x, y) in tri_positions:\n",
    "        draw_triangle(out, x, y)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            # Timing/diagnostic print (no rendering time included)\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f02bdef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code runs with triangles scanning for obstacles above them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d073cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 42.0 | infer 114.3 | to_cpu 2.8 | post 393.0 | masks 4 | triangles 1 => proc 510.1 ms\n",
      "[2/79] frame_00001.png  read 37.5 | infer 55.0 | to_cpu 2.0 | post 199.1 | masks 6 | triangles 1 => proc 256.1 ms\n",
      "[3/79] frame_00002.png  read 42.6 | infer 53.2 | to_cpu 0.7 | post 176.3 | masks 3 | triangles 3 => proc 230.2 ms\n",
      "[4/79] frame_00003.png  read 101.2 | infer 57.7 | to_cpu 0.9 | post 155.8 | masks 3 | triangles 2 => proc 214.4 ms\n",
      "[5/79] frame_00004.png  read 81.6 | infer 47.5 | to_cpu 0.9 | post 148.0 | masks 5 | triangles 1 => proc 196.4 ms\n",
      "[6/79] frame_00005.png  read 37.0 | infer 49.7 | to_cpu 1.8 | post 134.9 | masks 4 | triangles 1 => proc 186.4 ms\n",
      "[7/79] frame_00006.png  read 41.7 | infer 47.4 | to_cpu 1.3 | post 121.2 | masks 5 | triangles 1 => proc 170.0 ms\n",
      "[8/79] frame_00007.png  read 37.2 | infer 52.2 | to_cpu 0.9 | post 149.6 | masks 6 | triangles 2 => proc 202.7 ms\n",
      "[9/79] frame_00008.png  read 38.0 | infer 53.5 | to_cpu 0.9 | post 142.1 | masks 6 | triangles 2 => proc 196.5 ms\n",
      "[10/79] frame_00009.png  read 36.5 | infer 46.0 | to_cpu 0.9 | post 170.0 | masks 4 | triangles 2 => proc 216.9 ms\n",
      "[11/79] frame_00010.png  read 36.8 | infer 43.6 | to_cpu 0.6 | post 127.2 | masks 4 | triangles 1 => proc 171.4 ms\n",
      "[12/79] frame_00011.png  read 37.6 | infer 34.8 | to_cpu 0.8 | post 91.5 | masks 4 | triangles 1 => proc 127.1 ms\n",
      "[13/79] frame_00012.png  read 35.6 | infer 37.8 | to_cpu 0.9 | post 48.5 | masks 6 | triangles 1 => proc 87.2 ms\n",
      "[14/79] frame_00013.png  read 37.0 | infer 42.8 | to_cpu 1.0 | post 154.1 | masks 5 | triangles 2 => proc 197.9 ms\n",
      "[15/79] frame_00014.png  read 36.3 | infer 44.1 | to_cpu 0.7 | post 149.0 | masks 4 | triangles 2 => proc 193.8 ms\n",
      "[16/79] frame_00015.png  read 35.8 | infer 44.6 | to_cpu 0.7 | post 90.5 | masks 4 | triangles 1 => proc 135.9 ms\n",
      "[17/79] frame_00016.png  read 36.7 | infer 46.6 | to_cpu 1.6 | post 164.9 | masks 5 | triangles 2 => proc 213.1 ms\n",
      "[18/79] frame_00017.png  read 36.9 | infer 36.0 | to_cpu 0.9 | post 182.6 | masks 5 | triangles 2 => proc 219.4 ms\n",
      "[19/79] frame_00018.png  read 37.6 | infer 41.8 | to_cpu 1.8 | post 194.7 | masks 6 | triangles 2 => proc 238.2 ms\n",
      "[20/79] frame_00019.png  read 36.7 | infer 33.6 | to_cpu 0.9 | post 142.1 | masks 4 | triangles 2 => proc 176.6 ms\n",
      "[21/79] frame_00020.png  read 37.9 | infer 34.1 | to_cpu 1.0 | post 124.6 | masks 4 | triangles 1 => proc 159.6 ms\n",
      "[22/79] frame_00021.png  read 46.2 | infer 43.7 | to_cpu 1.1 | post 160.7 | masks 5 | triangles 2 => proc 205.5 ms\n",
      "[23/79] frame_00022.png  read 37.2 | infer 52.9 | to_cpu 0.9 | post 175.6 | masks 5 | triangles 2 => proc 229.4 ms\n",
      "[24/79] frame_00023.png  read 43.6 | infer 331.6 | to_cpu 2.0 | post 192.8 | masks 8 | triangles 1 => proc 526.3 ms\n",
      "[25/79] frame_00024.png  read 37.3 | infer 48.2 | to_cpu 0.9 | post 155.5 | masks 5 | triangles 2 => proc 204.6 ms\n",
      "[26/79] frame_00025.png  read 38.2 | infer 40.1 | to_cpu 0.8 | post 220.2 | masks 4 | triangles 1 => proc 261.1 ms\n",
      "[27/79] frame_00026.png  read 38.6 | infer 50.9 | to_cpu 0.9 | post 110.0 | masks 3 | triangles 1 => proc 161.8 ms\n",
      "[28/79] frame_00027.png  read 37.4 | infer 40.8 | to_cpu 1.4 | post 168.0 | masks 4 | triangles 2 => proc 210.1 ms\n",
      "[29/79] frame_00028.png  read 38.2 | infer 46.6 | to_cpu 1.4 | post 131.6 | masks 5 | triangles 1 => proc 179.6 ms\n",
      "[30/79] frame_00029.png  read 38.7 | infer 48.0 | to_cpu 1.5 | post 117.4 | masks 5 | triangles 1 => proc 167.0 ms\n",
      "[31/79] frame_00030.png  read 37.8 | infer 45.1 | to_cpu 0.7 | post 133.3 | masks 3 | triangles 2 => proc 179.1 ms\n",
      "[32/79] frame_00031.png  read 40.5 | infer 38.8 | to_cpu 0.8 | post 228.5 | masks 4 | triangles 2 => proc 268.1 ms\n",
      "[33/79] frame_00032.png  read 37.4 | infer 41.0 | to_cpu 0.8 | post 150.3 | masks 3 | triangles 2 => proc 192.1 ms\n",
      "[34/79] frame_00033.png  read 37.3 | infer 43.9 | to_cpu 0.9 | post 86.1 | masks 5 | triangles 1 => proc 130.8 ms\n",
      "[35/79] frame_00034.png  read 35.5 | infer 42.9 | to_cpu 0.8 | post 163.3 | masks 4 | triangles 2 => proc 207.1 ms\n",
      "[36/79] frame_00035.png  read 31.2 | infer 59.7 | to_cpu 0.7 | post 97.9 | masks 2 | triangles 1 => proc 158.3 ms\n",
      "[37/79] frame_00036.png  read 37.1 | infer 39.7 | to_cpu 0.9 | post 154.5 | masks 4 | triangles 2 => proc 195.2 ms\n",
      "[38/79] frame_00037.png  read 39.1 | infer 49.6 | to_cpu 1.4 | post 180.7 | masks 4 | triangles 3 => proc 231.7 ms\n",
      "[39/79] frame_00038.png  read 37.0 | infer 42.1 | to_cpu 0.8 | post 155.6 | masks 4 | triangles 2 => proc 198.5 ms\n",
      "[40/79] frame_00039.png  read 37.4 | infer 41.9 | to_cpu 1.5 | post 0.0 | masks 5 | triangles 0 => proc 43.3 ms\n",
      "[41/79] frame_00040.png  read 38.6 | infer 181.8 | to_cpu 1.0 | post 85.2 | masks 8 | triangles 1 => proc 268.1 ms\n",
      "[42/79] frame_00041.png  read 36.1 | infer 49.8 | to_cpu 1.4 | post 116.5 | masks 9 | triangles 1 => proc 167.7 ms\n",
      "[43/79] frame_00042.png  read 46.4 | infer 49.4 | to_cpu 1.1 | post 80.5 | masks 5 | triangles 1 => proc 131.0 ms\n",
      "[44/79] frame_00043.png  read 38.1 | infer 45.7 | to_cpu 2.4 | post 96.9 | masks 7 | triangles 2 => proc 145.0 ms\n",
      "[45/79] frame_00044.png  read 37.6 | infer 48.9 | to_cpu 0.9 | post 60.3 | masks 6 | triangles 1 => proc 110.1 ms\n",
      "[46/79] frame_00045.png  read 40.4 | infer 40.4 | to_cpu 0.8 | post 126.7 | masks 5 | triangles 2 => proc 167.9 ms\n",
      "[47/79] frame_00046.png  read 37.6 | infer 47.0 | to_cpu 0.9 | post 98.9 | masks 5 | triangles 2 => proc 146.9 ms\n",
      "[48/79] frame_00047.png  read 41.1 | infer 80.0 | to_cpu 1.8 | post 97.1 | masks 7 | triangles 2 => proc 178.9 ms\n",
      "[49/79] frame_00048.png  read 39.4 | infer 40.8 | to_cpu 1.0 | post 90.1 | masks 5 | triangles 1 => proc 131.8 ms\n",
      "[50/79] frame_00049.png  read 39.7 | infer 47.3 | to_cpu 1.7 | post 143.8 | masks 4 | triangles 1 => proc 192.7 ms\n",
      "[51/79] frame_00050.png  read 37.8 | infer 40.9 | to_cpu 1.0 | post 222.5 | masks 3 | triangles 3 => proc 264.4 ms\n",
      "[52/79] frame_00051.png  read 38.0 | infer 44.6 | to_cpu 1.4 | post 73.4 | masks 6 | triangles 2 => proc 119.4 ms\n",
      "[53/79] frame_00052.png  read 36.8 | infer 88.8 | to_cpu 1.1 | post 116.8 | masks 8 | triangles 1 => proc 206.7 ms\n",
      "[54/79] frame_00053.png  read 42.7 | infer 40.9 | to_cpu 1.0 | post 140.8 | masks 6 | triangles 2 => proc 182.6 ms\n",
      "[55/79] frame_00054.png  read 43.5 | infer 46.1 | to_cpu 1.5 | post 151.0 | masks 5 | triangles 3 => proc 198.7 ms\n",
      "[56/79] frame_00055.png  read 34.7 | infer 54.7 | to_cpu 1.2 | post 141.9 | masks 4 | triangles 1 => proc 197.7 ms\n",
      "[57/79] frame_00056.png  read 41.0 | infer 46.2 | to_cpu 1.0 | post 152.3 | masks 3 | triangles 2 => proc 199.5 ms\n",
      "[58/79] frame_00057.png  read 42.5 | infer 42.0 | to_cpu 0.9 | post 123.4 | masks 4 | triangles 1 => proc 166.3 ms\n",
      "[59/79] frame_00058.png  read 41.5 | infer 46.6 | to_cpu 0.9 | post 152.2 | masks 4 | triangles 2 => proc 199.7 ms\n",
      "[60/79] frame_00059.png  read 37.3 | infer 47.8 | to_cpu 0.9 | post 163.7 | masks 6 | triangles 2 => proc 212.4 ms\n",
      "[61/79] frame_00060.png  read 51.9 | infer 47.4 | to_cpu 0.9 | post 180.0 | masks 5 | triangles 3 => proc 228.3 ms\n",
      "[62/79] frame_00061.png  read 37.8 | infer 36.2 | to_cpu 1.6 | post 155.0 | masks 6 | triangles 2 => proc 192.7 ms\n",
      "[63/79] frame_00062.png  read 115.6 | infer 40.0 | to_cpu 1.0 | post 0.0 | masks 6 | triangles 0 => proc 41.0 ms\n",
      "[64/79] frame_00063.png  read 38.7 | infer 74.4 | to_cpu 1.2 | post 0.0 | masks 8 | triangles 0 => proc 75.6 ms\n",
      "[65/79] frame_00064.png  read 38.5 | infer 49.0 | to_cpu 2.6 | post 132.8 | masks 7 | triangles 3 => proc 184.4 ms\n",
      "[66/79] frame_00065.png  read 38.0 | infer 43.0 | to_cpu 0.7 | post 152.9 | masks 3 | triangles 2 => proc 196.7 ms\n",
      "[67/79] frame_00066.png  read 38.9 | infer 48.5 | to_cpu 1.4 | post 149.1 | masks 5 | triangles 2 => proc 199.1 ms\n",
      "[68/79] frame_00067.png  read 37.3 | infer 50.7 | to_cpu 1.3 | post 0.0 | masks 7 | triangles 0 => proc 51.9 ms\n",
      "[69/79] frame_00068.png  read 44.7 | infer 70.1 | to_cpu 0.9 | post 130.3 | masks 4 | triangles 1 => proc 201.3 ms\n",
      "[70/79] frame_00069.png  read 38.7 | infer 38.4 | to_cpu 1.7 | post 124.2 | masks 3 | triangles 1 => proc 164.2 ms\n",
      "[71/79] frame_00070.png  read 41.3 | infer 46.0 | to_cpu 0.8 | post 155.6 | masks 2 | triangles 2 => proc 202.5 ms\n",
      "[72/79] frame_00071.png  read 36.6 | infer 37.2 | to_cpu 1.3 | post 155.4 | masks 2 | triangles 2 => proc 193.8 ms\n",
      "[73/79] frame_00072.png  read 37.7 | infer 65.7 | to_cpu 1.8 | post 167.0 | masks 2 | triangles 2 => proc 234.5 ms\n",
      "[74/79] frame_00073.png  read 42.8 | infer 49.8 | to_cpu 0.9 | post 155.6 | masks 2 | triangles 2 => proc 206.3 ms\n",
      "[75/79] frame_00074.png  read 37.6 | infer 47.8 | to_cpu 1.5 | post 168.8 | masks 3 | triangles 2 => proc 218.2 ms\n",
      "[76/79] frame_00075.png  read 27.3 | infer 109.0 | to_cpu 1.1 | post 77.7 | masks 2 | triangles 1 => proc 187.7 ms\n",
      "[77/79] frame_00076.png  read 18.8 | infer 23.9 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.9 ms\n",
      "[78/79] frame_00077.png  read 17.4 | infer 22.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.1 ms\n",
      "[79/79] frame_00078.png  read 17.5 | infer 22.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.6 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now renders ALL masks + triangles coloured by the mask sampled N px above the tip\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Triangle mask scan distance (N pixels above tip)\n",
    "SAMPLE_UP_PX        = 55\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)  # readable pink\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None   # None → all frames\n",
    "RENDER_FIRST_N      = 50     # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "SAFE_GREEN = {9, 10}          # rails or sidewalk or no mask -> green\n",
    "WARN_YELLOW = {2,3,4,5,6,8}   # barrier/jump/train/ramp -> yellow\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ---- Triangle classification by sampling masks N px above tip (no resizes) ----\n",
    "def classify_triangles_at_sample(tri_positions, masks_np, classes_np, frame_H, frame_W, sample_up=SAMPLE_UP_PX):\n",
    "    \"\"\"\n",
    "    For each triangle (x,y), sample (x, y - N) and determine which mask/class covers it.\n",
    "    If no mask there: GREEN. If class==0: PINK. If class in {2,3,4,5,6,8}: YELLOW.\n",
    "    If class in {9,10}: GREEN. Else: RED.\n",
    "    Uses scale mapping into masks grid; avoids resizing masks.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "\n",
    "    colours = []\n",
    "    for (x, y) in tri_positions:\n",
    "        ys = max(0, y - sample_up)\n",
    "        mx = int(round(x * sx))\n",
    "        my = int(round(ys * sy))\n",
    "        if mx < 0: mx = 0\n",
    "        elif mx >= mw: mx = mw - 1\n",
    "        if my < 0: my = 0\n",
    "        elif my >= mh: my = mh - 1\n",
    "\n",
    "        cls_here = None\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            if m[my, mx] > 0.5:  # mask hit\n",
    "                cls_here = int(c)\n",
    "                break\n",
    "\n",
    "        if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "            colours.append(COLOR_GREEN)\n",
    "        elif cls_here == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif cls_here in WARN_YELLOW:\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "\n",
    "    return colours\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # classify triangles by sampling masks above tip\n",
    "    tri_colours = classify_triangles_at_sample(tri_positions, masks_np, classes_np, H, W, SAMPLE_UP_PX)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, and coloured triangles on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Draw triangles with per-triangle colours\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf780be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated logic for finding triangles and classifying them based on masks above the tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad52c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 36.9 | infer 99.5 | to_cpu 0.8 | post 151.5 | masks 4 | triangles 1 => proc 251.8 ms\n",
      "[2/79] frame_00001.png  read 37.4 | infer 40.9 | to_cpu 0.9 | post 162.0 | masks 6 | triangles 1 => proc 203.9 ms\n",
      "[3/79] frame_00002.png  read 37.4 | infer 223.6 | to_cpu 16.7 | post 212.5 | masks 3 | triangles 3 => proc 452.9 ms\n",
      "[4/79] frame_00003.png  read 37.7 | infer 76.8 | to_cpu 1.1 | post 168.5 | masks 3 | triangles 2 => proc 246.5 ms\n",
      "[5/79] frame_00004.png  read 38.9 | infer 57.3 | to_cpu 0.7 | post 171.3 | masks 5 | triangles 1 => proc 229.3 ms\n",
      "[6/79] frame_00005.png  read 38.5 | infer 47.2 | to_cpu 0.9 | post 123.7 | masks 4 | triangles 1 => proc 171.8 ms\n",
      "[7/79] frame_00006.png  read 37.2 | infer 43.8 | to_cpu 1.2 | post 123.0 | masks 5 | triangles 1 => proc 167.9 ms\n",
      "[8/79] frame_00007.png  read 38.7 | infer 163.5 | to_cpu 1.1 | post 165.7 | masks 6 | triangles 2 => proc 330.3 ms\n",
      "[9/79] frame_00008.png  read 37.3 | infer 47.4 | to_cpu 1.8 | post 153.3 | masks 6 | triangles 2 => proc 202.4 ms\n",
      "[10/79] frame_00009.png  read 36.9 | infer 43.5 | to_cpu 0.7 | post 169.0 | masks 4 | triangles 2 => proc 213.2 ms\n",
      "[11/79] frame_00010.png  read 187.3 | infer 54.9 | to_cpu 1.0 | post 144.8 | masks 4 | triangles 1 => proc 200.7 ms\n",
      "[12/79] frame_00011.png  read 57.4 | infer 48.5 | to_cpu 0.8 | post 94.5 | masks 4 | triangles 1 => proc 143.8 ms\n",
      "[13/79] frame_00012.png  read 36.1 | infer 38.6 | to_cpu 0.9 | post 62.6 | masks 6 | triangles 1 => proc 102.0 ms\n",
      "[14/79] frame_00013.png  read 36.2 | infer 36.9 | to_cpu 0.9 | post 200.2 | masks 5 | triangles 2 => proc 238.1 ms\n",
      "[15/79] frame_00014.png  read 37.9 | infer 41.2 | to_cpu 0.8 | post 144.5 | masks 4 | triangles 2 => proc 186.5 ms\n",
      "[16/79] frame_00015.png  read 35.7 | infer 38.0 | to_cpu 0.7 | post 92.8 | masks 4 | triangles 1 => proc 131.6 ms\n",
      "[17/79] frame_00016.png  read 37.6 | infer 50.0 | to_cpu 1.1 | post 450.2 | masks 5 | triangles 2 => proc 501.3 ms\n",
      "[18/79] frame_00017.png  read 37.5 | infer 38.7 | to_cpu 1.0 | post 166.1 | masks 5 | triangles 2 => proc 205.8 ms\n",
      "[19/79] frame_00018.png  read 37.4 | infer 44.6 | to_cpu 0.9 | post 162.9 | masks 6 | triangles 2 => proc 208.4 ms\n",
      "[20/79] frame_00019.png  read 39.0 | infer 33.9 | to_cpu 1.9 | post 145.3 | masks 4 | triangles 2 => proc 181.0 ms\n",
      "[21/79] frame_00020.png  read 37.9 | infer 39.3 | to_cpu 0.7 | post 136.8 | masks 4 | triangles 1 => proc 176.8 ms\n",
      "[22/79] frame_00021.png  read 37.2 | infer 40.7 | to_cpu 0.7 | post 162.1 | masks 5 | triangles 2 => proc 203.5 ms\n",
      "[23/79] frame_00022.png  read 39.0 | infer 46.3 | to_cpu 0.9 | post 149.6 | masks 5 | triangles 2 => proc 196.7 ms\n",
      "[24/79] frame_00023.png  read 47.1 | infer 325.4 | to_cpu 1.2 | post 197.0 | masks 8 | triangles 1 => proc 523.6 ms\n",
      "[25/79] frame_00024.png  read 37.6 | infer 66.9 | to_cpu 0.8 | post 175.8 | masks 5 | triangles 2 => proc 243.6 ms\n",
      "[26/79] frame_00025.png  read 43.9 | infer 39.8 | to_cpu 1.0 | post 127.1 | masks 4 | triangles 1 => proc 167.9 ms\n",
      "[27/79] frame_00026.png  read 37.2 | infer 38.4 | to_cpu 0.6 | post 103.7 | masks 3 | triangles 1 => proc 142.8 ms\n",
      "[28/79] frame_00027.png  read 36.6 | infer 37.0 | to_cpu 0.9 | post 172.1 | masks 4 | triangles 2 => proc 210.0 ms\n",
      "[29/79] frame_00028.png  read 37.2 | infer 40.3 | to_cpu 0.7 | post 130.0 | masks 5 | triangles 1 => proc 171.0 ms\n",
      "[30/79] frame_00029.png  read 37.2 | infer 40.7 | to_cpu 0.8 | post 118.8 | masks 5 | triangles 1 => proc 160.3 ms\n",
      "[31/79] frame_00030.png  read 36.6 | infer 43.2 | to_cpu 0.7 | post 115.4 | masks 3 | triangles 2 => proc 159.3 ms\n",
      "[32/79] frame_00031.png  read 36.4 | infer 37.0 | to_cpu 0.8 | post 158.4 | masks 4 | triangles 2 => proc 196.2 ms\n",
      "[33/79] frame_00032.png  read 36.4 | infer 39.0 | to_cpu 0.7 | post 146.9 | masks 3 | triangles 2 => proc 186.6 ms\n",
      "[34/79] frame_00033.png  read 36.8 | infer 42.2 | to_cpu 0.9 | post 90.9 | masks 5 | triangles 1 => proc 134.1 ms\n",
      "[35/79] frame_00034.png  read 34.7 | infer 40.7 | to_cpu 0.8 | post 165.4 | masks 4 | triangles 2 => proc 206.9 ms\n",
      "[36/79] frame_00035.png  read 31.2 | infer 47.2 | to_cpu 0.9 | post 94.4 | masks 2 | triangles 1 => proc 142.5 ms\n",
      "[37/79] frame_00036.png  read 36.7 | infer 38.3 | to_cpu 0.8 | post 156.7 | masks 4 | triangles 2 => proc 195.9 ms\n",
      "[38/79] frame_00037.png  read 38.2 | infer 42.6 | to_cpu 0.8 | post 174.2 | masks 4 | triangles 3 => proc 217.6 ms\n",
      "[39/79] frame_00038.png  read 36.3 | infer 37.7 | to_cpu 0.8 | post 154.0 | masks 4 | triangles 2 => proc 192.4 ms\n",
      "[40/79] frame_00039.png  read 37.8 | infer 40.8 | to_cpu 0.9 | post 0.0 | masks 5 | triangles 0 => proc 41.7 ms\n",
      "[41/79] frame_00040.png  read 37.2 | infer 181.9 | to_cpu 1.1 | post 100.5 | masks 8 | triangles 1 => proc 283.5 ms\n",
      "[42/79] frame_00041.png  read 36.2 | infer 52.6 | to_cpu 1.3 | post 104.0 | masks 9 | triangles 1 => proc 157.9 ms\n",
      "[43/79] frame_00042.png  read 36.9 | infer 40.5 | to_cpu 1.0 | post 93.1 | masks 5 | triangles 1 => proc 134.6 ms\n",
      "[44/79] frame_00043.png  read 36.7 | infer 45.0 | to_cpu 1.2 | post 95.0 | masks 7 | triangles 2 => proc 141.3 ms\n",
      "[45/79] frame_00044.png  read 37.7 | infer 41.2 | to_cpu 0.9 | post 64.4 | masks 6 | triangles 1 => proc 106.5 ms\n",
      "[46/79] frame_00045.png  read 37.2 | infer 44.4 | to_cpu 2.2 | post 142.6 | masks 5 | triangles 2 => proc 189.2 ms\n",
      "[47/79] frame_00046.png  read 37.0 | infer 39.9 | to_cpu 0.9 | post 87.9 | masks 5 | triangles 2 => proc 128.7 ms\n",
      "[48/79] frame_00047.png  read 44.4 | infer 72.2 | to_cpu 1.2 | post 96.9 | masks 7 | triangles 2 => proc 170.3 ms\n",
      "[49/79] frame_00048.png  read 37.1 | infer 36.0 | to_cpu 0.8 | post 104.9 | masks 5 | triangles 1 => proc 141.6 ms\n",
      "[50/79] frame_00049.png  read 36.6 | infer 40.9 | to_cpu 0.7 | post 143.9 | masks 4 | triangles 1 => proc 185.5 ms\n",
      "[51/79] frame_00050.png  read 36.4 | infer 40.8 | to_cpu 0.7 | post 151.1 | masks 3 | triangles 3 => proc 192.5 ms\n",
      "[52/79] frame_00051.png  read 36.6 | infer 39.2 | to_cpu 1.3 | post 66.9 | masks 6 | triangles 2 => proc 107.5 ms\n",
      "[53/79] frame_00052.png  read 36.3 | infer 78.3 | to_cpu 1.2 | post 125.3 | masks 8 | triangles 1 => proc 204.9 ms\n",
      "[54/79] frame_00053.png  read 36.7 | infer 34.2 | to_cpu 0.9 | post 146.6 | masks 6 | triangles 2 => proc 181.7 ms\n",
      "[55/79] frame_00054.png  read 35.4 | infer 43.3 | to_cpu 0.8 | post 151.9 | masks 5 | triangles 3 => proc 196.1 ms\n",
      "[56/79] frame_00055.png  read 35.7 | infer 39.8 | to_cpu 0.9 | post 148.8 | masks 4 | triangles 1 => proc 189.5 ms\n",
      "[57/79] frame_00056.png  read 37.4 | infer 41.0 | to_cpu 0.7 | post 153.9 | masks 3 | triangles 2 => proc 195.6 ms\n",
      "[58/79] frame_00057.png  read 36.2 | infer 34.5 | to_cpu 0.9 | post 129.3 | masks 4 | triangles 1 => proc 164.7 ms\n",
      "[59/79] frame_00058.png  read 38.5 | infer 43.4 | to_cpu 0.9 | post 163.3 | masks 4 | triangles 2 => proc 207.7 ms\n",
      "[60/79] frame_00059.png  read 36.9 | infer 62.5 | to_cpu 1.3 | post 171.0 | masks 6 | triangles 2 => proc 234.8 ms\n",
      "[61/79] frame_00060.png  read 36.1 | infer 51.2 | to_cpu 0.9 | post 162.2 | masks 5 | triangles 3 => proc 214.3 ms\n",
      "[62/79] frame_00061.png  read 39.8 | infer 35.2 | to_cpu 0.8 | post 163.1 | masks 6 | triangles 2 => proc 199.1 ms\n",
      "[63/79] frame_00062.png  read 36.5 | infer 35.9 | to_cpu 1.1 | post 0.0 | masks 6 | triangles 0 => proc 36.9 ms\n",
      "[64/79] frame_00063.png  read 37.4 | infer 93.0 | to_cpu 1.7 | post 0.0 | masks 8 | triangles 0 => proc 94.7 ms\n",
      "[65/79] frame_00064.png  read 38.8 | infer 36.0 | to_cpu 0.9 | post 141.1 | masks 7 | triangles 3 => proc 178.0 ms\n",
      "[66/79] frame_00065.png  read 36.8 | infer 41.9 | to_cpu 2.6 | post 166.6 | masks 3 | triangles 2 => proc 211.2 ms\n",
      "[67/79] frame_00066.png  read 37.7 | infer 46.3 | to_cpu 1.1 | post 152.6 | masks 5 | triangles 2 => proc 199.9 ms\n",
      "[68/79] frame_00067.png  read 56.7 | infer 40.4 | to_cpu 1.0 | post 0.0 | masks 7 | triangles 0 => proc 41.4 ms\n",
      "[69/79] frame_00068.png  read 36.5 | infer 48.6 | to_cpu 2.2 | post 100.3 | masks 4 | triangles 1 => proc 151.1 ms\n",
      "[70/79] frame_00069.png  read 38.2 | infer 36.3 | to_cpu 0.9 | post 129.6 | masks 3 | triangles 1 => proc 166.8 ms\n",
      "[71/79] frame_00070.png  read 37.9 | infer 45.1 | to_cpu 0.7 | post 153.0 | masks 2 | triangles 2 => proc 198.8 ms\n",
      "[72/79] frame_00071.png  read 40.7 | infer 39.0 | to_cpu 0.6 | post 156.5 | masks 2 | triangles 2 => proc 196.1 ms\n",
      "[73/79] frame_00072.png  read 36.7 | infer 40.1 | to_cpu 0.9 | post 171.7 | masks 2 | triangles 2 => proc 212.7 ms\n",
      "[74/79] frame_00073.png  read 37.5 | infer 44.9 | to_cpu 0.6 | post 159.8 | masks 2 | triangles 2 => proc 205.3 ms\n",
      "[75/79] frame_00074.png  read 35.0 | infer 41.1 | to_cpu 0.7 | post 170.0 | masks 3 | triangles 2 => proc 211.8 ms\n",
      "[76/79] frame_00075.png  read 27.5 | infer 34.6 | to_cpu 0.9 | post 71.2 | masks 2 | triangles 1 => proc 106.7 ms\n",
      "[77/79] frame_00076.png  read 18.1 | infer 22.4 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.4 ms\n",
      "[78/79] frame_00077.png  read 17.9 | infer 22.8 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.8 ms\n",
      "[79/79] frame_00078.png  read 17.1 | infer 23.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.6 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Renders ALL masks + triangles coloured by nearest-mask class when y < 0.4H\n",
    "# (Rails/SIDEWALK ignored for nearest search; triangles >= threshold are GREEN)\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_tri_scan\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Threshold line for nearest-mask search\n",
    "THRESH_FRAC         = 0.50  # y < 0.40*H triggers nearest-mask classification\n",
    "\n",
    "# Colours (BGR) for triangle output\n",
    "COLOR_GREEN  = (0, 255, 0)      # triangles at/above threshold\n",
    "COLOR_PINK   = (203, 192, 255)  # class 0\n",
    "COLOR_YELLOW = (0, 255, 255)    # classes {2,3,4,5,8}\n",
    "COLOR_RED    = (0, 0, 255)      # otherwise\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None  # None → all frames\n",
    "RENDER_FIRST_N      = 50    # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "# Returns: (list_of_triangle_xy, best_xy_or_None)\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ---- NEW: classify triangles by nearest eligible mask when y < 0.4H (ignore 9/10) ----\n",
    "def classify_triangles_by_nearest_mask(tri_positions, masks_np, classes_np, frame_H, frame_W, thresh_frac=THRESH_FRAC):\n",
    "    \"\"\"\n",
    "    For triangles with y < thresh*H, find nearest *eligible* mask centroid (ignoring class 9:RAILS, 10:SIDEWALK).\n",
    "    Colour mapping:\n",
    "      - class==0 -> PINK\n",
    "      - class in {2,3,4,5,8} -> YELLOW\n",
    "      - anything else -> RED\n",
    "    Triangles at/above threshold are GREEN.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    H, W = frame_H, frame_W\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    # scale mask->frame coords (avoid resizing)\n",
    "    sx = (W - 1) / max(1, (mw - 1))\n",
    "    sy = (H - 1) / max(1, (mh - 1))\n",
    "\n",
    "    # Precompute eligible mask centroids in frame coords\n",
    "    elig = []  # (cx_frame, cy_frame, class_id)\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        ci = int(c)\n",
    "        if ci in (9, 10):  # ignore Rails and Sidewalk\n",
    "            continue\n",
    "        ys, xs = np.where(m > 0.5)\n",
    "        if xs.size == 0:\n",
    "            continue\n",
    "        cx_frame = xs.mean() * sx\n",
    "        cy_frame = ys.mean() * sy\n",
    "        elig.append((cx_frame, cy_frame, ci))\n",
    "\n",
    "    y_thresh = H * thresh_frac\n",
    "    colours = []\n",
    "    if not elig:\n",
    "        # If no eligible masks, all below-threshold become RED; above/at threshold GREEN\n",
    "        for (x, y) in tri_positions:\n",
    "            colours.append(COLOR_GREEN if y >= y_thresh else COLOR_RED)\n",
    "        return colours\n",
    "\n",
    "    for (x, y) in tri_positions:\n",
    "        if y >= y_thresh:\n",
    "            colours.append(COLOR_GREEN)\n",
    "            continue\n",
    "\n",
    "        # find nearest eligible centroid (squared distance)\n",
    "        best_ci = None\n",
    "        best_d2 = 1e18\n",
    "        for (cx, cy, ci) in elig:\n",
    "            dx = cx - x\n",
    "            dy = cy - y\n",
    "            d2 = dx*dx + dy*dy\n",
    "            if d2 < best_d2:\n",
    "                best_d2 = d2\n",
    "                best_ci = ci\n",
    "\n",
    "        if best_ci == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif best_ci in (2,3,4,5,8):\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "\n",
    "    return colours\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # classify triangles by nearest eligible mask when below threshold; else GREEN\n",
    "    tri_colours = classify_triangles_by_nearest_mask(tri_positions, masks_np, classes_np, H, W, THRESH_FRAC)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, and coloured triangles on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        # upsample masks to frame res only once per mask\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            # overlay\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            # label near centroid\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Rail tint + green highlight (if available)\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Draw triangles with per-triangle colours\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            # Timing/diagnostic print (no rendering time included)\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929f2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updates pxl scanning verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c00a448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 42.3 | infer 117.7 | to_cpu 0.9 | post 196.5 | masks 4 | triangles 1 => proc 315.1 ms\n",
      "[2/79] frame_00001.png  read 36.5 | infer 57.7 | to_cpu 1.1 | post 161.3 | masks 6 | triangles 1 => proc 220.0 ms\n",
      "[3/79] frame_00002.png  read 38.4 | infer 45.6 | to_cpu 0.7 | post 176.2 | masks 3 | triangles 3 => proc 222.5 ms\n",
      "[4/79] frame_00003.png  read 37.0 | infer 39.0 | to_cpu 0.6 | post 148.2 | masks 3 | triangles 2 => proc 187.9 ms\n",
      "[5/79] frame_00004.png  read 36.8 | infer 45.5 | to_cpu 0.8 | post 146.3 | masks 5 | triangles 1 => proc 192.7 ms\n",
      "[6/79] frame_00005.png  read 36.6 | infer 46.3 | to_cpu 1.2 | post 136.6 | masks 4 | triangles 1 => proc 184.1 ms\n",
      "[7/79] frame_00006.png  read 37.2 | infer 40.3 | to_cpu 0.8 | post 113.0 | masks 5 | triangles 1 => proc 154.1 ms\n",
      "[8/79] frame_00007.png  read 37.2 | infer 43.5 | to_cpu 1.1 | post 141.0 | masks 6 | triangles 2 => proc 185.6 ms\n",
      "[9/79] frame_00008.png  read 39.7 | infer 46.1 | to_cpu 1.0 | post 163.1 | masks 6 | triangles 2 => proc 210.2 ms\n",
      "[10/79] frame_00009.png  read 36.4 | infer 42.9 | to_cpu 0.9 | post 162.9 | masks 4 | triangles 2 => proc 206.7 ms\n",
      "[11/79] frame_00010.png  read 38.4 | infer 42.4 | to_cpu 1.0 | post 121.3 | masks 4 | triangles 1 => proc 164.7 ms\n",
      "[12/79] frame_00011.png  read 43.0 | infer 37.6 | to_cpu 0.8 | post 93.0 | masks 4 | triangles 1 => proc 131.4 ms\n",
      "[13/79] frame_00012.png  read 35.9 | infer 39.8 | to_cpu 1.0 | post 51.6 | masks 6 | triangles 1 => proc 92.4 ms\n",
      "[14/79] frame_00013.png  read 36.7 | infer 35.1 | to_cpu 0.9 | post 135.0 | masks 5 | triangles 2 => proc 171.0 ms\n",
      "[15/79] frame_00014.png  read 36.9 | infer 43.9 | to_cpu 0.8 | post 146.1 | masks 4 | triangles 2 => proc 190.7 ms\n",
      "[16/79] frame_00015.png  read 36.6 | infer 46.3 | to_cpu 0.8 | post 107.2 | masks 4 | triangles 1 => proc 154.3 ms\n",
      "[17/79] frame_00016.png  read 38.9 | infer 57.1 | to_cpu 1.3 | post 200.3 | masks 5 | triangles 2 => proc 258.8 ms\n",
      "[18/79] frame_00017.png  read 36.7 | infer 37.4 | to_cpu 0.9 | post 182.4 | masks 5 | triangles 2 => proc 220.7 ms\n",
      "[19/79] frame_00018.png  read 37.5 | infer 49.6 | to_cpu 1.0 | post 143.6 | masks 6 | triangles 2 => proc 194.2 ms\n",
      "[20/79] frame_00019.png  read 38.0 | infer 72.9 | to_cpu 1.3 | post 169.6 | masks 4 | triangles 2 => proc 243.9 ms\n",
      "[21/79] frame_00020.png  read 37.5 | infer 36.2 | to_cpu 0.8 | post 126.3 | masks 4 | triangles 1 => proc 163.3 ms\n",
      "[22/79] frame_00021.png  read 37.1 | infer 41.5 | to_cpu 1.8 | post 156.2 | masks 5 | triangles 2 => proc 199.5 ms\n",
      "[23/79] frame_00022.png  read 37.0 | infer 48.4 | to_cpu 1.0 | post 145.0 | masks 5 | triangles 2 => proc 194.3 ms\n",
      "[24/79] frame_00023.png  read 37.3 | infer 277.7 | to_cpu 2.2 | post 155.0 | masks 8 | triangles 1 => proc 434.9 ms\n",
      "[25/79] frame_00024.png  read 37.9 | infer 46.0 | to_cpu 0.9 | post 152.1 | masks 5 | triangles 2 => proc 199.0 ms\n",
      "[26/79] frame_00025.png  read 45.8 | infer 36.7 | to_cpu 0.9 | post 115.5 | masks 4 | triangles 1 => proc 153.0 ms\n",
      "[27/79] frame_00026.png  read 37.2 | infer 38.7 | to_cpu 0.8 | post 106.0 | masks 3 | triangles 1 => proc 145.5 ms\n",
      "[28/79] frame_00027.png  read 36.7 | infer 42.1 | to_cpu 0.8 | post 162.0 | masks 4 | triangles 2 => proc 204.9 ms\n",
      "[29/79] frame_00028.png  read 37.6 | infer 41.2 | to_cpu 0.9 | post 119.2 | masks 5 | triangles 1 => proc 161.4 ms\n",
      "[30/79] frame_00029.png  read 38.0 | infer 38.9 | to_cpu 0.9 | post 115.4 | masks 5 | triangles 1 => proc 155.3 ms\n",
      "[31/79] frame_00030.png  read 107.0 | infer 131.8 | to_cpu 1.8 | post 117.9 | masks 3 | triangles 2 => proc 251.4 ms\n",
      "[32/79] frame_00031.png  read 41.3 | infer 41.0 | to_cpu 0.8 | post 171.5 | masks 4 | triangles 2 => proc 213.3 ms\n",
      "[33/79] frame_00032.png  read 39.8 | infer 44.6 | to_cpu 1.5 | post 178.7 | masks 3 | triangles 2 => proc 224.8 ms\n",
      "[34/79] frame_00033.png  read 37.5 | infer 51.6 | to_cpu 1.1 | post 104.9 | masks 5 | triangles 1 => proc 157.6 ms\n",
      "[35/79] frame_00034.png  read 35.2 | infer 42.1 | to_cpu 0.8 | post 169.6 | masks 4 | triangles 2 => proc 212.6 ms\n",
      "[36/79] frame_00035.png  read 30.2 | infer 45.4 | to_cpu 0.7 | post 95.3 | masks 2 | triangles 1 => proc 141.3 ms\n",
      "[37/79] frame_00036.png  read 37.6 | infer 35.2 | to_cpu 0.8 | post 158.1 | masks 4 | triangles 2 => proc 194.1 ms\n",
      "[38/79] frame_00037.png  read 36.9 | infer 49.5 | to_cpu 2.2 | post 173.2 | masks 4 | triangles 3 => proc 224.8 ms\n",
      "[39/79] frame_00038.png  read 38.2 | infer 38.6 | to_cpu 0.9 | post 156.0 | masks 4 | triangles 2 => proc 195.5 ms\n",
      "[40/79] frame_00039.png  read 36.3 | infer 51.3 | to_cpu 1.0 | post 0.0 | masks 5 | triangles 0 => proc 52.3 ms\n",
      "[41/79] frame_00040.png  read 37.3 | infer 249.0 | to_cpu 1.0 | post 139.6 | masks 8 | triangles 1 => proc 389.6 ms\n",
      "[42/79] frame_00041.png  read 36.5 | infer 54.6 | to_cpu 1.5 | post 97.1 | masks 9 | triangles 1 => proc 153.3 ms\n",
      "[43/79] frame_00042.png  read 37.5 | infer 36.7 | to_cpu 1.2 | post 86.7 | masks 5 | triangles 1 => proc 124.6 ms\n",
      "[44/79] frame_00043.png  read 37.3 | infer 50.7 | to_cpu 1.3 | post 122.4 | masks 7 | triangles 2 => proc 174.4 ms\n",
      "[45/79] frame_00044.png  read 36.1 | infer 42.8 | to_cpu 0.9 | post 66.8 | masks 6 | triangles 1 => proc 110.5 ms\n",
      "[46/79] frame_00045.png  read 37.7 | infer 54.3 | to_cpu 0.8 | post 125.0 | masks 5 | triangles 2 => proc 180.2 ms\n",
      "[47/79] frame_00046.png  read 37.2 | infer 46.9 | to_cpu 1.0 | post 82.5 | masks 5 | triangles 2 => proc 130.4 ms\n",
      "[48/79] frame_00047.png  read 37.1 | infer 57.7 | to_cpu 1.1 | post 88.4 | masks 7 | triangles 2 => proc 147.3 ms\n",
      "[49/79] frame_00048.png  read 37.0 | infer 40.2 | to_cpu 0.8 | post 98.3 | masks 5 | triangles 1 => proc 139.2 ms\n",
      "[50/79] frame_00049.png  read 39.0 | infer 43.9 | to_cpu 0.8 | post 148.6 | masks 4 | triangles 1 => proc 193.3 ms\n",
      "[51/79] frame_00050.png  read 39.1 | infer 36.8 | to_cpu 0.7 | post 150.9 | masks 3 | triangles 3 => proc 188.4 ms\n",
      "[52/79] frame_00051.png  read 38.2 | infer 40.1 | to_cpu 1.0 | post 62.2 | masks 6 | triangles 2 => proc 103.3 ms\n",
      "[53/79] frame_00052.png  read 39.7 | infer 69.9 | to_cpu 1.3 | post 114.7 | masks 8 | triangles 1 => proc 185.8 ms\n",
      "[54/79] frame_00053.png  read 36.6 | infer 40.5 | to_cpu 0.9 | post 146.2 | masks 6 | triangles 2 => proc 187.6 ms\n",
      "[55/79] frame_00054.png  read 261.5 | infer 82.7 | to_cpu 1.3 | post 168.1 | masks 5 | triangles 3 => proc 252.1 ms\n",
      "[56/79] frame_00055.png  read 35.2 | infer 48.6 | to_cpu 1.1 | post 145.6 | masks 4 | triangles 1 => proc 195.3 ms\n",
      "[57/79] frame_00056.png  read 36.8 | infer 81.9 | to_cpu 2.8 | post 159.8 | masks 3 | triangles 2 => proc 244.5 ms\n",
      "[58/79] frame_00057.png  read 35.8 | infer 34.3 | to_cpu 0.7 | post 124.2 | masks 4 | triangles 1 => proc 159.2 ms\n",
      "[59/79] frame_00058.png  read 35.7 | infer 39.2 | to_cpu 0.8 | post 198.4 | masks 4 | triangles 2 => proc 238.4 ms\n",
      "[60/79] frame_00059.png  read 40.2 | infer 42.1 | to_cpu 1.0 | post 154.6 | masks 6 | triangles 2 => proc 197.7 ms\n",
      "[61/79] frame_00060.png  read 36.4 | infer 223.6 | to_cpu 1.0 | post 171.8 | masks 5 | triangles 3 => proc 396.5 ms\n",
      "[62/79] frame_00061.png  read 38.5 | infer 36.5 | to_cpu 1.1 | post 152.3 | masks 6 | triangles 2 => proc 190.0 ms\n",
      "[63/79] frame_00062.png  read 37.5 | infer 35.4 | to_cpu 1.0 | post 0.0 | masks 6 | triangles 0 => proc 36.3 ms\n",
      "[64/79] frame_00063.png  read 37.4 | infer 234.9 | to_cpu 1.4 | post 0.0 | masks 8 | triangles 0 => proc 236.4 ms\n",
      "[65/79] frame_00064.png  read 49.5 | infer 40.8 | to_cpu 0.9 | post 138.3 | masks 7 | triangles 3 => proc 179.9 ms\n",
      "[66/79] frame_00065.png  read 37.6 | infer 52.1 | to_cpu 0.7 | post 161.4 | masks 3 | triangles 2 => proc 214.2 ms\n",
      "[67/79] frame_00066.png  read 38.5 | infer 49.0 | to_cpu 0.8 | post 161.9 | masks 5 | triangles 2 => proc 211.7 ms\n",
      "[68/79] frame_00067.png  read 37.0 | infer 41.8 | to_cpu 0.9 | post 0.0 | masks 7 | triangles 0 => proc 42.8 ms\n",
      "[69/79] frame_00068.png  read 36.3 | infer 41.3 | to_cpu 1.0 | post 97.6 | masks 4 | triangles 1 => proc 139.8 ms\n",
      "[70/79] frame_00069.png  read 39.4 | infer 34.9 | to_cpu 0.7 | post 123.2 | masks 3 | triangles 1 => proc 158.8 ms\n",
      "[71/79] frame_00070.png  read 37.5 | infer 40.2 | to_cpu 0.7 | post 159.9 | masks 2 | triangles 2 => proc 200.8 ms\n",
      "[72/79] frame_00071.png  read 36.6 | infer 31.3 | to_cpu 1.1 | post 156.9 | masks 2 | triangles 2 => proc 189.3 ms\n",
      "[73/79] frame_00072.png  read 43.1 | infer 41.2 | to_cpu 0.9 | post 173.3 | masks 2 | triangles 2 => proc 215.4 ms\n",
      "[74/79] frame_00073.png  read 45.7 | infer 50.0 | to_cpu 0.6 | post 177.3 | masks 2 | triangles 2 => proc 227.9 ms\n",
      "[75/79] frame_00074.png  read 36.9 | infer 52.5 | to_cpu 1.3 | post 336.3 | masks 3 | triangles 2 => proc 390.0 ms\n",
      "[76/79] frame_00075.png  read 27.9 | infer 37.1 | to_cpu 0.7 | post 72.5 | masks 2 | triangles 1 => proc 110.3 ms\n",
      "[77/79] frame_00076.png  read 17.3 | infer 23.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.1 ms\n",
      "[78/79] frame_00077.png  read 17.1 | infer 23.2 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.2 ms\n",
      "[79/79] frame_00078.png  read 17.2 | infer 22.7 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.7 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now renders ALL masks + triangles coloured by the mask sampled N px above the tip\n",
    "# + Scout lines: per-pixel coloured line from tip to sample point (render-only)\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays2\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Triangle mask scan distance (N pixels above tip)\n",
    "SAMPLE_UP_PX        = 55\n",
    "\n",
    "# Colours (BGR)\n",
    "COLOR_GREEN  = (0, 255, 0)\n",
    "COLOR_PINK   = (203, 192, 255)  # readable pink\n",
    "COLOR_YELLOW = (0, 255, 255)\n",
    "COLOR_RED    = (0, 0, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None   # None → all frames\n",
    "RENDER_FIRST_N      = 50     # render overlays for first N frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "SAFE_GREEN = {9, 10}          # rails or sidewalk or no mask -> green\n",
    "WARN_YELLOW = {2,3,4,5,8}   # barrier/jump/train/ramp -> yellow\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0:\n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# ---- Triangle classification by sampling masks N px above tip (no resizes) ----\n",
    "def classify_triangles_at_sample(tri_positions, masks_np, classes_np, frame_H, frame_W, sample_up=SAMPLE_UP_PX):\n",
    "    \"\"\"\n",
    "    For each triangle (x,y), sample (x, y - N) and determine which mask/class covers it.\n",
    "    If no mask there: GREEN. If class==0: PINK. If class in {2,3,4,5,6,8}: YELLOW.\n",
    "    If class in {9,10}: GREEN. Else: RED.\n",
    "    Uses scale mapping into masks grid; avoids resizing masks.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or len(tri_positions) == 0:\n",
    "        return []\n",
    "\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "\n",
    "    colours = []\n",
    "    for (x, y) in tri_positions:\n",
    "        ys = max(0, y - sample_up)\n",
    "        mx = int(round(x * sx))\n",
    "        my = int(round(ys * sy))\n",
    "        if mx < 0: mx = 0\n",
    "        elif mx >= mw: mx = mw - 1\n",
    "        if my < 0: my = 0\n",
    "        elif my >= mh: my = mh - 1\n",
    "\n",
    "        cls_here = None\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            if m[my, mx] > 0.5:  # mask hit\n",
    "                cls_here = int(c)\n",
    "                break\n",
    "\n",
    "        if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "            colours.append(COLOR_GREEN)\n",
    "        elif cls_here == 0:\n",
    "            colours.append(COLOR_PINK)\n",
    "        elif cls_here in WARN_YELLOW:\n",
    "            colours.append(COLOR_YELLOW)\n",
    "        else:\n",
    "            colours.append(COLOR_RED)\n",
    "\n",
    "    return colours\n",
    "\n",
    "# --- NEW (render-only): colour for any frame-point via masks (no resizes) ---\n",
    "def _colour_for_point(x, y, masks_np, classes_np, frame_H, frame_W):\n",
    "    \"\"\"\n",
    "    Determine display colour at frame point (x,y) using same mapping rules as classifier.\n",
    "    No mask or class in SAFE_GREEN -> GREEN; class==0 -> PINK; class in WARN_YELLOW -> YELLOW; else RED.\n",
    "    \"\"\"\n",
    "    if masks_np is None or classes_np is None or masks_np.size == 0:\n",
    "        return COLOR_GREEN\n",
    "    mh, mw = masks_np.shape[1], masks_np.shape[2]\n",
    "    # Precompute scales\n",
    "    sx = (mw - 1) / max(1, (frame_W - 1))\n",
    "    sy = (mh - 1) / max(1, (frame_H - 1))\n",
    "    mx = int(round(x * sx))\n",
    "    my = int(round(y * sy))\n",
    "    if mx < 0: mx = 0\n",
    "    elif mx >= mw: mx = mw - 1\n",
    "    if my < 0: my = 0\n",
    "    elif my >= mh: my = mh - 1\n",
    "\n",
    "    cls_here = None\n",
    "    for m, c in zip(masks_np, classes_np):\n",
    "        if m[my, mx] > 0.5:\n",
    "            cls_here = int(c)\n",
    "            break\n",
    "\n",
    "    if (cls_here is None) or (cls_here in SAFE_GREEN):\n",
    "        return COLOR_GREEN\n",
    "    if cls_here == 0:\n",
    "        return COLOR_PINK\n",
    "    if cls_here in WARN_YELLOW:\n",
    "        return COLOR_YELLOW\n",
    "    return COLOR_RED\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, [], []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, [], []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "\n",
    "    # classify triangles by sampling masks above tip\n",
    "    tri_colours = classify_triangles_at_sample(tri_positions, masks_np, classes_np, H, W, SAMPLE_UP_PX)\n",
    "\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions, tri_colours\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=COLOR_RED):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, coloured triangles, and scout lines on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # --- Scout lines (render-only): per-pixel coloured vertical line up to sample point ---\n",
    "    if tri_positions:\n",
    "        for (x, y) in tri_positions:\n",
    "            y_end = max(0, y - SAMPLE_UP_PX)\n",
    "            # Draw 1px dots along path; color per mask under that pixel\n",
    "            # (Cheap: ≤ SAMPLE_UP_PX points per triangle)\n",
    "            for yy in range(y, y_end - 1, -1):\n",
    "                col = _colour_for_point(x, yy, masks_np, classes_np, H, W)\n",
    "                # draw a 1px point\n",
    "                out[yy, x] = col  # direct assign faster than cv2.circle for 1px\n",
    "\n",
    "    # Draw triangles with per-triangle colours (after scout lines so tips are visible)\n",
    "    for (x, y), col in zip(tri_positions, tri_colours):\n",
    "        draw_triangle(out, x, y, colour=col)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions, tri_colours)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236a798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
