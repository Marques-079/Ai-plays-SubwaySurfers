{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c42f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, no-UI, no-prints, batched pipeline with threaded I/O\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config (tweak for your box)\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 16           # adjust to saturate your GPU\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)  # file I/O overlap\n",
    "SHOW_FIRST_N        = None         # None → all frames\n",
    "RETURN_TIMINGS      = False        # True if you want per-frame timing dicts returned\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try:\n",
    "    cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup (avoids first-batch penalty; keep on device)\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE,\n",
    "                  device=device, conf=CONF, iou=IOU,\n",
    "                  verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed constants\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers (vectorized/fast)\n",
    "# =======================\n",
    "def load_image(path: str):\n",
    "    # Fast path cv2.imread; IMREAD_COLOR is default; avoid extra conversions\n",
    "    return cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    # Color match on ROI only, then CC filter by area/height\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    # [h,w,1,3] - [1,1,K,3] → [h,w,K,3]\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)                       # [h,w,K]\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)                # [h,w]\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)            # bool\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    if n <= 1:\n",
    "        out = np.zeros_like(combined)\n",
    "        full = np.zeros((H, W), dtype=bool)\n",
    "        return full\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    # vectorized filter: get idx of components satisfying both constraints\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    if keep.size:\n",
    "        # fast mask assembly\n",
    "        for k in keep:\n",
    "            good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    # Use box blur; separable under the hood in OpenCV\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def purple_triangle_from_dark_map(score, H):\n",
    "    # Mask score with top/bottom exclusions, morph open, then take CCs\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex:\n",
    "        dark[:top_ex, :] = 0\n",
    "    if bot_ex:\n",
    "        dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None  # no triangle\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    # Keep components meeting both absolute and fractional thresholds\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # For the triangle location: pick the component whose topmost y is smallest\n",
    "    # (closest to top after exclusions), and place triangle at (x_mid, y_top).\n",
    "    y_mins = []\n",
    "    x_mids = []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0:\n",
    "            continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None\n",
    "\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx]))  # (x, y)\n",
    "\n",
    "# =======================\n",
    "# Core processing of one frame (expects YOLO result already on CPU)\n",
    "# =======================\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    # masks at model size → union rails → upsample to frame size\n",
    "    if yolo_res.masks is None:\n",
    "        return None  # triangle pos: None\n",
    "\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()          # [n,h,w]\n",
    "    # class vector: prefer masks.cls if present, else boxes.cls\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    # union only rail masks\n",
    "    if classes_np.size == 0:\n",
    "        return None\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None\n",
    "\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)          # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8)   # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    # green (target color on rails) vs red\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "\n",
    "    # heat precursor\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri = purple_triangle_from_dark_map(score, H)\n",
    "    return tri  # (x, y) or None\n",
    "\n",
    "# =======================\n",
    "# Batched execution with overlapped disk I/O\n",
    "# =======================\n",
    "def run_pipeline():\n",
    "    # List frames\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    results_triangle_xy = [None] * len(paths)\n",
    "    timings = [None] * len(paths) if RETURN_TIMINGS else None\n",
    "\n",
    "    # Threaded I/O loader\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            future_to_idx = {ex.submit(load_image, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(future_to_idx):\n",
    "                i = future_to_idx[fut]\n",
    "                img = fut.result()\n",
    "                imgs[i] = img\n",
    "        # drop unreadables\n",
    "        ok = [(p, im) for p, im in zip(batch_paths, imgs) if im is not None]\n",
    "        if not ok:\n",
    "            return [], []\n",
    "        batch_paths2, imgs2 = zip(*ok)\n",
    "        return list(batch_paths2), list(imgs2)\n",
    "\n",
    "    # Process in batches\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr = load_batch(batch_paths)\n",
    "        if not imgs_bgr:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        # Inference (batched)\n",
    "        t0 = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=len(imgs_bgr)\n",
    "        )\n",
    "        # Ensure device sync so post timing reflects host-only work\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        # Post-process each frame (CPU, vectorized where possible)\n",
    "        t2 = time.perf_counter()\n",
    "        for j, (img, yres) in enumerate(zip(imgs_bgr, res_list)):\n",
    "            tri = process_frame_post(img, yres)\n",
    "            results_triangle_xy[idx_global + j] = tri\n",
    "        t3 = time.perf_counter()\n",
    "\n",
    "        if RETURN_TIMINGS:\n",
    "            # same timings for each frame in batch (approximate)\n",
    "            infer_ms = (t1 - t0) * 1000.0 / max(1, len(imgs_bgr))\n",
    "            post_ms  = (t3 - t2) * 1000.0 / max(1, len(imgs_bgr))\n",
    "            for j in range(len(imgs_bgr)):\n",
    "                timings[idx_global + j] = {\"infer_ms\": infer_ms, \"post_ms\": post_ms}\n",
    "\n",
    "        idx_global += len(imgs_bgr)\n",
    "\n",
    "    return (results_triangle_xy, timings) if RETURN_TIMINGS else results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a73a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 40.0 | infer 675.7 | to_cpu 0.7 | post 151.9 => proc 828.2 ms\n",
      "[2/79] frame_00001.png  read 38.8 | infer 49.6 | to_cpu 1.0 | post 160.2 => proc 210.8 ms\n",
      "[3/79] frame_00002.png  read 36.4 | infer 59.7 | to_cpu 0.9 | post 172.2 => proc 232.7 ms\n",
      "[4/79] frame_00003.png  read 36.4 | infer 37.7 | to_cpu 0.8 | post 170.3 => proc 208.8 ms\n",
      "[5/79] frame_00004.png  read 36.0 | infer 42.0 | to_cpu 0.9 | post 143.9 => proc 186.9 ms\n",
      "[6/79] frame_00005.png  read 43.0 | infer 40.7 | to_cpu 1.0 | post 125.9 => proc 167.6 ms\n",
      "[7/79] frame_00006.png  read 39.8 | infer 41.0 | to_cpu 1.0 | post 122.9 => proc 164.9 ms\n",
      "[8/79] frame_00007.png  read 37.4 | infer 42.4 | to_cpu 1.0 | post 147.6 => proc 191.1 ms\n",
      "[9/79] frame_00008.png  read 37.1 | infer 41.7 | to_cpu 0.8 | post 143.9 => proc 186.4 ms\n",
      "[10/79] frame_00009.png  read 38.1 | infer 40.7 | to_cpu 0.8 | post 156.8 => proc 198.3 ms\n",
      "[11/79] frame_00010.png  read 39.5 | infer 37.8 | to_cpu 0.9 | post 121.0 => proc 159.7 ms\n",
      "[12/79] frame_00011.png  read 38.4 | infer 35.0 | to_cpu 0.8 | post 89.9 => proc 125.8 ms\n",
      "[13/79] frame_00012.png  read 35.8 | infer 34.0 | to_cpu 1.0 | post 47.6 => proc 82.6 ms\n",
      "[14/79] frame_00013.png  read 37.6 | infer 34.9 | to_cpu 0.9 | post 139.1 => proc 174.9 ms\n",
      "[15/79] frame_00014.png  read 36.5 | infer 39.9 | to_cpu 0.8 | post 140.0 => proc 180.7 ms\n",
      "[16/79] frame_00015.png  read 36.6 | infer 41.0 | to_cpu 0.8 | post 90.3 => proc 132.0 ms\n",
      "[17/79] frame_00016.png  read 37.5 | infer 40.5 | to_cpu 0.9 | post 166.9 => proc 208.2 ms\n",
      "[18/79] frame_00017.png  read 37.6 | infer 35.2 | to_cpu 0.9 | post 160.9 => proc 196.9 ms\n",
      "[19/79] frame_00018.png  read 37.3 | infer 45.0 | to_cpu 0.9 | post 149.2 => proc 195.0 ms\n",
      "[20/79] frame_00019.png  read 36.9 | infer 37.4 | to_cpu 0.8 | post 141.0 => proc 179.3 ms\n",
      "[21/79] frame_00020.png  read 38.2 | infer 35.9 | to_cpu 0.9 | post 125.4 => proc 162.2 ms\n",
      "[22/79] frame_00021.png  read 37.6 | infer 42.0 | to_cpu 0.9 | post 156.6 => proc 199.4 ms\n",
      "[23/79] frame_00022.png  read 38.3 | infer 40.8 | to_cpu 0.8 | post 148.5 => proc 190.2 ms\n",
      "[24/79] frame_00023.png  read 37.5 | infer 43.2 | to_cpu 1.0 | post 149.2 => proc 193.4 ms\n",
      "[25/79] frame_00024.png  read 37.4 | infer 40.1 | to_cpu 1.2 | post 154.9 => proc 196.2 ms\n",
      "[26/79] frame_00025.png  read 37.4 | infer 34.9 | to_cpu 0.8 | post 121.4 => proc 157.1 ms\n",
      "[27/79] frame_00026.png  read 47.5 | infer 38.5 | to_cpu 0.8 | post 105.5 => proc 144.8 ms\n",
      "[28/79] frame_00027.png  read 37.8 | infer 34.6 | to_cpu 0.9 | post 161.1 => proc 196.6 ms\n",
      "[29/79] frame_00028.png  read 37.2 | infer 40.6 | to_cpu 1.1 | post 124.1 => proc 165.8 ms\n",
      "[30/79] frame_00029.png  read 38.4 | infer 42.9 | to_cpu 1.1 | post 114.8 => proc 158.8 ms\n",
      "[31/79] frame_00030.png  read 37.1 | infer 39.7 | to_cpu 0.8 | post 115.8 => proc 156.3 ms\n",
      "[32/79] frame_00031.png  read 37.5 | infer 38.4 | to_cpu 0.8 | post 157.7 => proc 196.9 ms\n",
      "[33/79] frame_00032.png  read 36.9 | infer 37.7 | to_cpu 0.8 | post 145.3 => proc 183.7 ms\n",
      "[34/79] frame_00033.png  read 37.5 | infer 43.5 | to_cpu 1.0 | post 98.8 => proc 143.3 ms\n",
      "[35/79] frame_00034.png  read 35.0 | infer 41.0 | to_cpu 0.8 | post 165.7 => proc 207.4 ms\n",
      "[36/79] frame_00035.png  read 31.2 | infer 42.8 | to_cpu 0.6 | post 96.8 => proc 140.2 ms\n",
      "[37/79] frame_00036.png  read 37.5 | infer 40.6 | to_cpu 1.1 | post 155.0 => proc 196.7 ms\n",
      "[38/79] frame_00037.png  read 36.5 | infer 43.2 | to_cpu 0.8 | post 175.1 => proc 219.2 ms\n",
      "[39/79] frame_00038.png  read 36.5 | infer 37.2 | to_cpu 1.0 | post 161.3 => proc 199.5 ms\n",
      "[40/79] frame_00039.png  read 36.1 | infer 38.4 | to_cpu 0.9 | post 0.0 => proc 39.3 ms\n",
      "[41/79] frame_00040.png  read 36.5 | infer 42.2 | to_cpu 1.1 | post 80.7 => proc 124.0 ms\n",
      "[42/79] frame_00041.png  read 37.8 | infer 44.2 | to_cpu 1.0 | post 88.5 => proc 133.7 ms\n",
      "[43/79] frame_00042.png  read 38.3 | infer 38.7 | to_cpu 0.9 | post 81.7 => proc 121.2 ms\n",
      "[44/79] frame_00043.png  read 38.6 | infer 45.9 | to_cpu 1.0 | post 85.7 => proc 132.6 ms\n",
      "[45/79] frame_00044.png  read 36.9 | infer 39.9 | to_cpu 0.9 | post 58.0 => proc 98.7 ms\n",
      "[46/79] frame_00045.png  read 37.7 | infer 38.7 | to_cpu 1.0 | post 121.4 => proc 161.2 ms\n",
      "[47/79] frame_00046.png  read 38.4 | infer 40.9 | to_cpu 1.8 | post 83.2 => proc 125.9 ms\n",
      "[48/79] frame_00047.png  read 38.7 | infer 40.6 | to_cpu 1.1 | post 90.6 => proc 132.3 ms\n",
      "[49/79] frame_00048.png  read 37.6 | infer 39.4 | to_cpu 1.0 | post 95.7 => proc 136.1 ms\n",
      "[50/79] frame_00049.png  read 36.6 | infer 40.1 | to_cpu 0.9 | post 150.6 => proc 191.5 ms\n",
      "[51/79] frame_00050.png  read 37.2 | infer 38.7 | to_cpu 0.8 | post 148.7 => proc 188.2 ms\n",
      "[52/79] frame_00051.png  read 36.9 | infer 41.2 | to_cpu 0.9 | post 61.7 => proc 103.8 ms\n",
      "[53/79] frame_00052.png  read 59.9 | infer 43.0 | to_cpu 1.0 | post 120.4 => proc 164.4 ms\n",
      "[54/79] frame_00053.png  read 37.5 | infer 39.7 | to_cpu 0.8 | post 138.7 => proc 179.2 ms\n",
      "[55/79] frame_00054.png  read 35.9 | infer 38.1 | to_cpu 0.8 | post 157.2 => proc 196.2 ms\n",
      "[56/79] frame_00055.png  read 35.8 | infer 39.5 | to_cpu 0.8 | post 152.5 => proc 192.8 ms\n",
      "[57/79] frame_00056.png  read 36.2 | infer 43.6 | to_cpu 0.7 | post 154.3 => proc 198.6 ms\n",
      "[58/79] frame_00057.png  read 35.8 | infer 32.3 | to_cpu 0.9 | post 130.1 => proc 163.2 ms\n",
      "[59/79] frame_00058.png  read 35.6 | infer 39.0 | to_cpu 0.8 | post 157.3 => proc 197.1 ms\n",
      "[60/79] frame_00059.png  read 35.5 | infer 46.2 | to_cpu 1.5 | post 154.6 => proc 202.2 ms\n",
      "[61/79] frame_00060.png  read 37.3 | infer 46.1 | to_cpu 0.9 | post 162.0 => proc 208.9 ms\n",
      "[62/79] frame_00061.png  read 37.1 | infer 35.7 | to_cpu 1.0 | post 162.4 => proc 199.2 ms\n",
      "[63/79] frame_00062.png  read 37.2 | infer 36.6 | to_cpu 1.0 | post 0.0 => proc 37.6 ms\n",
      "[64/79] frame_00063.png  read 37.5 | infer 42.5 | to_cpu 1.1 | post 0.0 => proc 43.6 ms\n",
      "[65/79] frame_00064.png  read 37.9 | infer 37.5 | to_cpu 1.0 | post 134.5 => proc 173.1 ms\n",
      "[66/79] frame_00065.png  read 37.4 | infer 38.7 | to_cpu 0.7 | post 156.3 => proc 195.8 ms\n",
      "[67/79] frame_00066.png  read 36.9 | infer 39.2 | to_cpu 0.8 | post 152.7 => proc 192.7 ms\n",
      "[68/79] frame_00067.png  read 36.7 | infer 45.9 | to_cpu 1.1 | post 0.0 => proc 47.0 ms\n",
      "[69/79] frame_00068.png  read 36.7 | infer 39.6 | to_cpu 0.8 | post 95.5 => proc 135.9 ms\n",
      "[70/79] frame_00069.png  read 37.4 | infer 34.9 | to_cpu 0.7 | post 129.4 => proc 165.0 ms\n",
      "[71/79] frame_00070.png  read 36.5 | infer 43.0 | to_cpu 0.8 | post 155.6 => proc 199.3 ms\n",
      "[72/79] frame_00071.png  read 36.6 | infer 32.7 | to_cpu 0.7 | post 159.7 => proc 193.0 ms\n",
      "[73/79] frame_00072.png  read 36.6 | infer 39.4 | to_cpu 0.7 | post 167.4 => proc 207.5 ms\n",
      "[74/79] frame_00073.png  read 36.9 | infer 41.3 | to_cpu 0.6 | post 167.0 => proc 208.9 ms\n",
      "[75/79] frame_00074.png  read 34.8 | infer 41.5 | to_cpu 0.9 | post 170.4 => proc 212.8 ms\n",
      "[76/79] frame_00075.png  read 27.2 | infer 55.5 | to_cpu 0.6 | post 77.5 => proc 133.6 ms\n",
      "[77/79] frame_00076.png  read 17.7 | infer 22.3 | to_cpu 0.0 | post 0.0 => proc 22.3 ms\n",
      "[78/79] frame_00077.png  read 17.6 | infer 22.7 | to_cpu 0.0 | post 0.0 => proc 22.7 ms\n",
      "[79/79] frame_00078.png  read 17.4 | infer 23.1 | to_cpu 0.0 | post 0.0 => proc 23.1 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing prints\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1                            # tune to your GPU\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None                          # None → all frames\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed constants\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "def purple_triangle_from_dark_map(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None\n",
    "\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    y_mins, x_mids = [], []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0: continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx]))\n",
    "\n",
    "# Return: tri, to_cpu_ms, post_ms (per-frame)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if classes_np.size == 0:\n",
    "        return None, to_cpu_ms, 0.0\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, to_cpu_ms, 0.0\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri   = purple_triangle_from_dark_map(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri, to_cpu_ms, post_ms\n",
    "\n",
    "# =======================\n",
    "# Batched execution with overlapped disk I/O + per-frame prints\n",
    "# =======================\n",
    "def run_pipeline_with_prints():\n",
    "    # Gather frames\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    # Threaded I/O\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        # Batched inference\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        # Device sync so timing is clean\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B  # approx per-frame share\n",
    "\n",
    "        # Per-frame post + prints\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            t0_post_all = time.perf_counter()\n",
    "            tri, to_cpu_ms, post_ms = process_frame_post(img, yres)\n",
    "            t1_post_all = time.perf_counter()  # includes everything inside post\n",
    "            results_triangle_xy[idx_global + j] = tri\n",
    "\n",
    "            # Compose per-frame timing\n",
    "            infer_ms = infer_ms_share\n",
    "            # post_ms already measured (CPU only after to_cpu)\n",
    "            proc_ms = infer_ms + to_cpu_ms + post_ms\n",
    "\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91a0bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 49.8 | infer 131.7 | to_cpu 0.8 | post 157.2 | masks 4 | triangles 1 => proc 289.8 ms\n",
      "[2/79] frame_00001.png  read 44.2 | infer 46.9 | to_cpu 1.2 | post 164.3 | masks 6 | triangles 1 => proc 212.4 ms\n",
      "[3/79] frame_00002.png  read 37.2 | infer 55.9 | to_cpu 0.9 | post 316.5 | masks 3 | triangles 3 => proc 373.3 ms\n",
      "[4/79] frame_00003.png  read 36.6 | infer 39.6 | to_cpu 0.7 | post 157.4 | masks 3 | triangles 2 => proc 197.7 ms\n",
      "[5/79] frame_00004.png  read 45.6 | infer 45.6 | to_cpu 0.8 | post 187.1 | masks 5 | triangles 1 => proc 233.5 ms\n",
      "[6/79] frame_00005.png  read 36.3 | infer 43.9 | to_cpu 0.9 | post 130.8 | masks 4 | triangles 1 => proc 175.6 ms\n",
      "[7/79] frame_00006.png  read 37.1 | infer 44.3 | to_cpu 1.1 | post 122.8 | masks 5 | triangles 1 => proc 168.1 ms\n",
      "[8/79] frame_00007.png  read 38.0 | infer 41.0 | to_cpu 1.0 | post 148.0 | masks 6 | triangles 2 => proc 190.0 ms\n",
      "[9/79] frame_00008.png  read 38.5 | infer 43.6 | to_cpu 2.3 | post 146.1 | masks 6 | triangles 2 => proc 192.0 ms\n",
      "[10/79] frame_00009.png  read 38.1 | infer 45.5 | to_cpu 1.3 | post 162.1 | masks 4 | triangles 2 => proc 208.9 ms\n",
      "[11/79] frame_00010.png  read 39.5 | infer 38.6 | to_cpu 0.8 | post 119.8 | masks 4 | triangles 1 => proc 159.2 ms\n",
      "[12/79] frame_00011.png  read 38.0 | infer 34.6 | to_cpu 1.4 | post 91.6 | masks 4 | triangles 1 => proc 127.7 ms\n",
      "[13/79] frame_00012.png  read 41.9 | infer 42.6 | to_cpu 1.0 | post 51.7 | masks 6 | triangles 1 => proc 95.3 ms\n",
      "[14/79] frame_00013.png  read 37.8 | infer 36.5 | to_cpu 0.9 | post 135.9 | masks 5 | triangles 2 => proc 173.4 ms\n",
      "[15/79] frame_00014.png  read 37.8 | infer 43.1 | to_cpu 0.8 | post 140.0 | masks 4 | triangles 2 => proc 183.9 ms\n",
      "[16/79] frame_00015.png  read 36.8 | infer 46.6 | to_cpu 0.9 | post 88.5 | masks 4 | triangles 1 => proc 136.0 ms\n",
      "[17/79] frame_00016.png  read 37.6 | infer 44.7 | to_cpu 1.8 | post 164.6 | masks 5 | triangles 2 => proc 211.1 ms\n",
      "[18/79] frame_00017.png  read 36.7 | infer 37.2 | to_cpu 0.9 | post 166.8 | masks 5 | triangles 2 => proc 204.9 ms\n",
      "[19/79] frame_00018.png  read 36.9 | infer 42.1 | to_cpu 1.0 | post 155.6 | masks 6 | triangles 2 => proc 198.7 ms\n",
      "[20/79] frame_00019.png  read 37.7 | infer 38.3 | to_cpu 1.1 | post 147.5 | masks 4 | triangles 2 => proc 186.9 ms\n",
      "[21/79] frame_00020.png  read 37.5 | infer 40.1 | to_cpu 0.9 | post 131.4 | masks 4 | triangles 1 => proc 172.4 ms\n",
      "[22/79] frame_00021.png  read 36.9 | infer 41.2 | to_cpu 1.0 | post 159.9 | masks 5 | triangles 2 => proc 202.1 ms\n",
      "[23/79] frame_00022.png  read 37.8 | infer 40.2 | to_cpu 0.9 | post 144.8 | masks 5 | triangles 2 => proc 185.9 ms\n",
      "[24/79] frame_00023.png  read 38.7 | infer 43.6 | to_cpu 1.1 | post 147.6 | masks 8 | triangles 1 => proc 192.2 ms\n",
      "[25/79] frame_00024.png  read 37.7 | infer 49.0 | to_cpu 0.8 | post 153.5 | masks 5 | triangles 2 => proc 203.3 ms\n",
      "[26/79] frame_00025.png  read 38.1 | infer 34.3 | to_cpu 0.8 | post 117.9 | masks 4 | triangles 1 => proc 153.0 ms\n",
      "[27/79] frame_00026.png  read 37.7 | infer 38.5 | to_cpu 0.9 | post 105.9 | masks 3 | triangles 1 => proc 145.2 ms\n",
      "[28/79] frame_00027.png  read 37.2 | infer 35.3 | to_cpu 0.8 | post 156.9 | masks 4 | triangles 2 => proc 193.1 ms\n",
      "[29/79] frame_00028.png  read 37.9 | infer 41.7 | to_cpu 0.9 | post 124.9 | masks 5 | triangles 1 => proc 167.5 ms\n",
      "[30/79] frame_00029.png  read 38.5 | infer 36.5 | to_cpu 1.1 | post 115.4 | masks 5 | triangles 1 => proc 153.0 ms\n",
      "[31/79] frame_00030.png  read 37.7 | infer 39.2 | to_cpu 0.7 | post 115.9 | masks 3 | triangles 2 => proc 155.9 ms\n",
      "[32/79] frame_00031.png  read 38.1 | infer 37.9 | to_cpu 1.0 | post 160.9 | masks 4 | triangles 2 => proc 199.8 ms\n",
      "[33/79] frame_00032.png  read 37.8 | infer 37.1 | to_cpu 0.9 | post 150.1 | masks 3 | triangles 2 => proc 188.1 ms\n",
      "[34/79] frame_00033.png  read 38.0 | infer 42.6 | to_cpu 1.0 | post 87.9 | masks 5 | triangles 1 => proc 131.5 ms\n",
      "[35/79] frame_00034.png  read 36.0 | infer 50.0 | to_cpu 0.7 | post 163.8 | masks 4 | triangles 2 => proc 214.5 ms\n",
      "[36/79] frame_00035.png  read 30.5 | infer 47.1 | to_cpu 0.7 | post 97.6 | masks 2 | triangles 1 => proc 145.4 ms\n",
      "[37/79] frame_00036.png  read 37.5 | infer 38.7 | to_cpu 0.8 | post 159.4 | masks 4 | triangles 2 => proc 199.0 ms\n",
      "[38/79] frame_00037.png  read 37.4 | infer 42.3 | to_cpu 0.8 | post 176.7 | masks 4 | triangles 3 => proc 219.9 ms\n",
      "[39/79] frame_00038.png  read 36.9 | infer 38.4 | to_cpu 0.8 | post 158.0 | masks 4 | triangles 2 => proc 197.2 ms\n",
      "[40/79] frame_00039.png  read 36.6 | infer 37.5 | to_cpu 0.9 | post 0.0 | masks 5 | triangles 0 => proc 38.3 ms\n",
      "[41/79] frame_00040.png  read 36.7 | infer 44.4 | to_cpu 1.2 | post 83.9 | masks 8 | triangles 1 => proc 129.5 ms\n",
      "[42/79] frame_00041.png  read 36.9 | infer 42.5 | to_cpu 1.3 | post 88.9 | masks 9 | triangles 1 => proc 132.7 ms\n",
      "[43/79] frame_00042.png  read 40.5 | infer 38.3 | to_cpu 1.5 | post 82.8 | masks 5 | triangles 1 => proc 122.5 ms\n",
      "[44/79] frame_00043.png  read 37.9 | infer 42.0 | to_cpu 0.9 | post 85.8 | masks 7 | triangles 2 => proc 128.7 ms\n",
      "[45/79] frame_00044.png  read 36.6 | infer 54.3 | to_cpu 1.1 | post 58.3 | masks 6 | triangles 1 => proc 113.8 ms\n",
      "[46/79] frame_00045.png  read 37.5 | infer 39.1 | to_cpu 0.9 | post 123.3 | masks 5 | triangles 2 => proc 163.3 ms\n",
      "[47/79] frame_00046.png  read 41.3 | infer 39.8 | to_cpu 0.9 | post 84.1 | masks 5 | triangles 2 => proc 124.8 ms\n",
      "[48/79] frame_00047.png  read 37.9 | infer 40.1 | to_cpu 0.9 | post 89.2 | masks 7 | triangles 2 => proc 130.2 ms\n",
      "[49/79] frame_00048.png  read 41.1 | infer 38.6 | to_cpu 0.9 | post 93.0 | masks 5 | triangles 1 => proc 132.4 ms\n",
      "[50/79] frame_00049.png  read 37.5 | infer 62.4 | to_cpu 0.9 | post 142.7 | masks 4 | triangles 1 => proc 205.9 ms\n",
      "[51/79] frame_00050.png  read 38.1 | infer 37.7 | to_cpu 1.0 | post 164.7 | masks 3 | triangles 3 => proc 203.4 ms\n",
      "[52/79] frame_00051.png  read 37.7 | infer 41.9 | to_cpu 1.0 | post 62.4 | masks 6 | triangles 2 => proc 105.4 ms\n",
      "[53/79] frame_00052.png  read 37.3 | infer 40.7 | to_cpu 1.0 | post 117.7 | masks 8 | triangles 1 => proc 159.5 ms\n",
      "[54/79] frame_00053.png  read 37.3 | infer 41.0 | to_cpu 0.9 | post 139.6 | masks 6 | triangles 2 => proc 181.5 ms\n",
      "[55/79] frame_00054.png  read 35.6 | infer 43.4 | to_cpu 0.9 | post 156.4 | masks 5 | triangles 3 => proc 200.7 ms\n",
      "[56/79] frame_00055.png  read 36.3 | infer 39.1 | to_cpu 0.8 | post 145.7 | masks 4 | triangles 1 => proc 185.6 ms\n",
      "[57/79] frame_00056.png  read 36.3 | infer 44.4 | to_cpu 0.8 | post 154.5 | masks 3 | triangles 2 => proc 199.6 ms\n",
      "[58/79] frame_00057.png  read 36.8 | infer 34.9 | to_cpu 0.9 | post 121.6 | masks 4 | triangles 1 => proc 157.3 ms\n",
      "[59/79] frame_00058.png  read 35.0 | infer 40.9 | to_cpu 0.8 | post 156.2 | masks 4 | triangles 2 => proc 197.9 ms\n",
      "[60/79] frame_00059.png  read 36.1 | infer 41.8 | to_cpu 1.3 | post 157.3 | masks 6 | triangles 2 => proc 200.3 ms\n",
      "[61/79] frame_00060.png  read 41.7 | infer 50.0 | to_cpu 0.9 | post 161.1 | masks 5 | triangles 3 => proc 212.1 ms\n",
      "[62/79] frame_00061.png  read 38.4 | infer 34.2 | to_cpu 1.0 | post 154.7 | masks 6 | triangles 2 => proc 189.8 ms\n",
      "[63/79] frame_00062.png  read 37.5 | infer 36.1 | to_cpu 1.0 | post 0.0 | masks 6 | triangles 0 => proc 37.1 ms\n",
      "[64/79] frame_00063.png  read 38.0 | infer 41.7 | to_cpu 1.1 | post 0.0 | masks 8 | triangles 0 => proc 42.8 ms\n",
      "[65/79] frame_00064.png  read 38.0 | infer 38.2 | to_cpu 0.9 | post 132.2 | masks 7 | triangles 3 => proc 171.3 ms\n",
      "[66/79] frame_00065.png  read 37.0 | infer 39.3 | to_cpu 0.7 | post 155.3 | masks 3 | triangles 2 => proc 195.4 ms\n",
      "[67/79] frame_00066.png  read 37.8 | infer 37.9 | to_cpu 1.6 | post 149.6 | masks 5 | triangles 2 => proc 189.1 ms\n",
      "[68/79] frame_00067.png  read 37.2 | infer 41.7 | to_cpu 1.0 | post 0.0 | masks 7 | triangles 0 => proc 42.6 ms\n",
      "[69/79] frame_00068.png  read 36.0 | infer 40.9 | to_cpu 0.8 | post 94.6 | masks 4 | triangles 1 => proc 136.2 ms\n",
      "[70/79] frame_00069.png  read 38.3 | infer 36.4 | to_cpu 0.8 | post 245.9 | masks 3 | triangles 1 => proc 283.1 ms\n",
      "[71/79] frame_00070.png  read 37.2 | infer 42.0 | to_cpu 0.7 | post 160.1 | masks 2 | triangles 2 => proc 202.7 ms\n",
      "[72/79] frame_00071.png  read 37.0 | infer 33.5 | to_cpu 0.6 | post 157.3 | masks 2 | triangles 2 => proc 191.4 ms\n",
      "[73/79] frame_00072.png  read 37.7 | infer 41.9 | to_cpu 0.6 | post 167.7 | masks 2 | triangles 2 => proc 210.3 ms\n",
      "[74/79] frame_00073.png  read 37.2 | infer 42.0 | to_cpu 0.8 | post 172.1 | masks 2 | triangles 2 => proc 214.9 ms\n",
      "[75/79] frame_00074.png  read 35.4 | infer 39.3 | to_cpu 0.9 | post 170.8 | masks 3 | triangles 2 => proc 211.0 ms\n",
      "[76/79] frame_00075.png  read 27.0 | infer 34.6 | to_cpu 0.7 | post 74.5 | masks 2 | triangles 1 => proc 109.7 ms\n",
      "[77/79] frame_00076.png  read 18.1 | infer 22.1 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.1 ms\n",
      "[78/79] frame_00077.png  read 17.4 | infer 23.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 23.6 ms\n",
      "[79/79] frame_00078.png  read 17.2 | infer 21.5 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None  # None → all\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "# Returns: (best_triangle_xy or None, triangle_count)\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return None, 0\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return None, 0\n",
    "\n",
    "    candidates = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            candidates.append(lbl)\n",
    "    tri_count = len(candidates)\n",
    "    if tri_count == 0:\n",
    "        return None, 0\n",
    "\n",
    "    y_mins, x_mids = [], []\n",
    "    for lbl in candidates:\n",
    "        ys, xs = np.where(lbls == lbl)\n",
    "        if ys.size == 0: \n",
    "            continue\n",
    "        y_top = ys.min()\n",
    "        x_mid = int(xs[ys == y_top].mean())\n",
    "        y_mins.append(y_top)\n",
    "        x_mids.append(x_mid)\n",
    "    if not y_mins:\n",
    "        return None, tri_count\n",
    "\n",
    "    idx = int(np.argmin(y_mins))\n",
    "    return (int(x_mids[idx]), int(y_mins[idx])), tri_count\n",
    "\n",
    "# Returns: (tri_xy, tri_count, mask_count, to_cpu_ms, post_ms)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_xy, tri_count = purple_triangles(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_xy, tri_count, mask_count, to_cpu_ms, post_ms\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints\n",
    "# =======================\n",
    "def run_pipeline_with_prints():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            tri_xy, tri_count, mask_count, to_cpu_ms, post_ms = process_frame_post(img, yres)\n",
    "            results_triangle_xy[idx_global + j] = tri_xy\n",
    "\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            # NEW: print mask_count and triangle_count\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eaa1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-seg summary (fused): 113 layers, 2,836,908 parameters, 0 gradients, 10.2 GFLOPs\n",
      "[1/79] frame_00000.png  read 37.3 | infer 122.5 | to_cpu 0.7 | post 158.6 | masks 4 | triangles 1 => proc 281.7 ms\n",
      "[2/79] frame_00001.png  read 43.8 | infer 42.1 | to_cpu 2.0 | post 156.4 | masks 6 | triangles 1 => proc 200.5 ms\n",
      "[3/79] frame_00002.png  read 126.1 | infer 53.3 | to_cpu 0.7 | post 178.3 | masks 3 | triangles 3 => proc 232.4 ms\n",
      "[4/79] frame_00003.png  read 37.4 | infer 45.3 | to_cpu 0.9 | post 157.9 | masks 3 | triangles 2 => proc 204.2 ms\n",
      "[5/79] frame_00004.png  read 39.2 | infer 46.0 | to_cpu 1.5 | post 145.1 | masks 5 | triangles 1 => proc 192.5 ms\n",
      "[6/79] frame_00005.png  read 36.8 | infer 48.6 | to_cpu 0.8 | post 120.5 | masks 4 | triangles 1 => proc 169.8 ms\n",
      "[7/79] frame_00006.png  read 37.4 | infer 50.7 | to_cpu 1.1 | post 122.3 | masks 5 | triangles 1 => proc 174.0 ms\n",
      "[8/79] frame_00007.png  read 37.7 | infer 41.3 | to_cpu 0.9 | post 159.4 | masks 6 | triangles 2 => proc 201.6 ms\n",
      "[9/79] frame_00008.png  read 38.5 | infer 43.5 | to_cpu 1.1 | post 143.1 | masks 6 | triangles 2 => proc 187.7 ms\n",
      "[10/79] frame_00009.png  read 41.0 | infer 41.7 | to_cpu 0.7 | post 162.7 | masks 4 | triangles 2 => proc 205.1 ms\n",
      "[11/79] frame_00010.png  read 38.9 | infer 36.9 | to_cpu 0.6 | post 123.6 | masks 4 | triangles 1 => proc 161.1 ms\n",
      "[12/79] frame_00011.png  read 37.9 | infer 34.3 | to_cpu 0.8 | post 88.9 | masks 4 | triangles 1 => proc 124.1 ms\n",
      "[13/79] frame_00012.png  read 36.6 | infer 41.0 | to_cpu 1.0 | post 49.5 | masks 6 | triangles 1 => proc 91.5 ms\n",
      "[14/79] frame_00013.png  read 37.4 | infer 34.0 | to_cpu 0.9 | post 137.1 | masks 5 | triangles 2 => proc 172.0 ms\n",
      "[15/79] frame_00014.png  read 36.5 | infer 48.1 | to_cpu 1.7 | post 156.2 | masks 4 | triangles 2 => proc 206.1 ms\n",
      "[16/79] frame_00015.png  read 36.5 | infer 40.1 | to_cpu 0.8 | post 88.8 | masks 4 | triangles 1 => proc 129.7 ms\n",
      "[17/79] frame_00016.png  read 36.8 | infer 47.3 | to_cpu 1.1 | post 167.1 | masks 5 | triangles 2 => proc 215.5 ms\n",
      "[18/79] frame_00017.png  read 37.5 | infer 35.3 | to_cpu 0.9 | post 173.4 | masks 5 | triangles 2 => proc 209.6 ms\n",
      "[19/79] frame_00018.png  read 38.6 | infer 40.4 | to_cpu 1.0 | post 145.2 | masks 6 | triangles 2 => proc 186.6 ms\n",
      "[20/79] frame_00019.png  read 39.1 | infer 35.8 | to_cpu 0.8 | post 147.7 | masks 4 | triangles 2 => proc 184.3 ms\n",
      "[21/79] frame_00020.png  read 39.1 | infer 34.9 | to_cpu 0.8 | post 128.4 | masks 4 | triangles 1 => proc 164.1 ms\n",
      "[22/79] frame_00021.png  read 40.0 | infer 43.0 | to_cpu 0.9 | post 158.4 | masks 5 | triangles 2 => proc 202.2 ms\n",
      "[23/79] frame_00022.png  read 38.4 | infer 47.2 | to_cpu 1.4 | post 148.1 | masks 5 | triangles 2 => proc 196.7 ms\n",
      "[24/79] frame_00023.png  read 38.7 | infer 44.8 | to_cpu 1.1 | post 151.3 | masks 8 | triangles 1 => proc 197.2 ms\n",
      "[25/79] frame_00024.png  read 37.3 | infer 41.1 | to_cpu 0.9 | post 153.2 | masks 5 | triangles 2 => proc 195.2 ms\n",
      "[26/79] frame_00025.png  read 41.7 | infer 36.4 | to_cpu 1.0 | post 114.2 | masks 4 | triangles 1 => proc 151.6 ms\n",
      "[27/79] frame_00026.png  read 37.1 | infer 41.3 | to_cpu 0.7 | post 105.8 | masks 3 | triangles 1 => proc 147.8 ms\n",
      "[28/79] frame_00027.png  read 37.1 | infer 34.2 | to_cpu 0.8 | post 157.4 | masks 4 | triangles 2 => proc 192.4 ms\n",
      "[29/79] frame_00028.png  read 36.8 | infer 39.9 | to_cpu 0.8 | post 120.7 | masks 5 | triangles 1 => proc 161.3 ms\n",
      "[30/79] frame_00029.png  read 38.1 | infer 39.6 | to_cpu 0.9 | post 142.3 | masks 5 | triangles 1 => proc 182.9 ms\n",
      "[31/79] frame_00030.png  read 36.7 | infer 42.4 | to_cpu 0.7 | post 114.8 | masks 3 | triangles 2 => proc 157.9 ms\n",
      "[32/79] frame_00031.png  read 38.1 | infer 37.5 | to_cpu 0.8 | post 162.5 | masks 4 | triangles 2 => proc 200.8 ms\n",
      "[33/79] frame_00032.png  read 37.9 | infer 38.9 | to_cpu 0.8 | post 144.8 | masks 3 | triangles 2 => proc 184.6 ms\n",
      "[34/79] frame_00033.png  read 38.2 | infer 40.4 | to_cpu 1.0 | post 87.2 | masks 5 | triangles 1 => proc 128.6 ms\n",
      "[35/79] frame_00034.png  read 37.0 | infer 48.4 | to_cpu 2.1 | post 165.3 | masks 4 | triangles 2 => proc 215.8 ms\n",
      "[36/79] frame_00035.png  read 30.6 | infer 48.0 | to_cpu 0.8 | post 97.2 | masks 2 | triangles 1 => proc 146.0 ms\n",
      "[37/79] frame_00036.png  read 37.9 | infer 41.7 | to_cpu 0.8 | post 158.2 | masks 4 | triangles 2 => proc 200.7 ms\n",
      "[38/79] frame_00037.png  read 44.6 | infer 48.5 | to_cpu 0.8 | post 178.5 | masks 4 | triangles 3 => proc 227.9 ms\n",
      "[39/79] frame_00038.png  read 37.6 | infer 47.0 | to_cpu 1.1 | post 167.2 | masks 4 | triangles 2 => proc 215.3 ms\n",
      "[40/79] frame_00039.png  read 35.9 | infer 39.6 | to_cpu 1.0 | post 0.0 | masks 5 | triangles 0 => proc 40.6 ms\n",
      "[41/79] frame_00040.png  read 36.6 | infer 49.4 | to_cpu 0.9 | post 81.6 | masks 8 | triangles 1 => proc 132.0 ms\n",
      "[42/79] frame_00041.png  read 36.9 | infer 44.5 | to_cpu 1.2 | post 90.6 | masks 9 | triangles 1 => proc 136.3 ms\n",
      "[43/79] frame_00042.png  read 39.2 | infer 43.3 | to_cpu 1.0 | post 81.9 | masks 5 | triangles 1 => proc 126.1 ms\n",
      "[44/79] frame_00043.png  read 37.3 | infer 42.5 | to_cpu 1.1 | post 86.6 | masks 7 | triangles 2 => proc 130.1 ms\n",
      "[45/79] frame_00044.png  read 36.6 | infer 209.2 | to_cpu 1.6 | post 57.7 | masks 6 | triangles 1 => proc 268.5 ms\n",
      "[46/79] frame_00045.png  read 44.4 | infer 46.4 | to_cpu 2.2 | post 144.5 | masks 5 | triangles 2 => proc 193.1 ms\n",
      "[47/79] frame_00046.png  read 47.7 | infer 45.0 | to_cpu 1.0 | post 86.8 | masks 5 | triangles 2 => proc 132.8 ms\n",
      "[48/79] frame_00047.png  read 37.1 | infer 44.0 | to_cpu 1.1 | post 94.0 | masks 7 | triangles 2 => proc 139.1 ms\n",
      "[49/79] frame_00048.png  read 38.7 | infer 40.9 | to_cpu 0.9 | post 223.9 | masks 5 | triangles 1 => proc 265.6 ms\n",
      "[50/79] frame_00049.png  read 36.8 | infer 42.3 | to_cpu 0.9 | post 151.6 | masks 4 | triangles 1 => proc 194.8 ms\n",
      "[51/79] frame_00050.png  read 38.4 | infer 38.0 | to_cpu 0.7 | post 151.9 | masks 3 | triangles 3 => proc 190.6 ms\n",
      "[52/79] frame_00051.png  read 41.8 | infer 43.5 | to_cpu 1.0 | post 63.5 | masks 6 | triangles 2 => proc 108.0 ms\n",
      "[53/79] frame_00052.png  read 46.3 | infer 45.3 | to_cpu 1.1 | post 131.5 | masks 8 | triangles 1 => proc 177.9 ms\n",
      "[54/79] frame_00053.png  read 36.8 | infer 36.7 | to_cpu 0.8 | post 145.1 | masks 6 | triangles 2 => proc 182.6 ms\n",
      "[55/79] frame_00054.png  read 36.5 | infer 41.3 | to_cpu 0.8 | post 154.9 | masks 5 | triangles 3 => proc 197.0 ms\n",
      "[56/79] frame_00055.png  read 35.8 | infer 53.3 | to_cpu 1.0 | post 145.6 | masks 4 | triangles 1 => proc 199.9 ms\n",
      "[57/79] frame_00056.png  read 38.9 | infer 43.4 | to_cpu 0.8 | post 159.5 | masks 3 | triangles 2 => proc 203.7 ms\n",
      "[58/79] frame_00057.png  read 36.9 | infer 36.2 | to_cpu 0.9 | post 121.2 | masks 4 | triangles 1 => proc 158.3 ms\n",
      "[59/79] frame_00058.png  read 34.8 | infer 42.7 | to_cpu 1.0 | post 161.2 | masks 4 | triangles 2 => proc 204.9 ms\n",
      "[60/79] frame_00059.png  read 37.3 | infer 45.5 | to_cpu 0.9 | post 167.3 | masks 6 | triangles 2 => proc 213.8 ms\n",
      "[61/79] frame_00060.png  read 39.9 | infer 43.7 | to_cpu 0.8 | post 163.4 | masks 5 | triangles 3 => proc 207.9 ms\n",
      "[62/79] frame_00061.png  read 37.0 | infer 36.3 | to_cpu 2.2 | post 157.8 | masks 6 | triangles 2 => proc 196.3 ms\n",
      "[63/79] frame_00062.png  read 40.0 | infer 35.5 | to_cpu 0.9 | post 0.0 | masks 6 | triangles 0 => proc 36.4 ms\n",
      "[64/79] frame_00063.png  read 37.5 | infer 41.0 | to_cpu 1.2 | post 0.0 | masks 8 | triangles 0 => proc 42.3 ms\n",
      "[65/79] frame_00064.png  read 38.3 | infer 36.7 | to_cpu 0.9 | post 131.6 | masks 7 | triangles 3 => proc 169.1 ms\n",
      "[66/79] frame_00065.png  read 36.8 | infer 39.3 | to_cpu 0.8 | post 154.5 | masks 3 | triangles 2 => proc 194.6 ms\n",
      "[67/79] frame_00066.png  read 38.4 | infer 42.0 | to_cpu 0.9 | post 157.3 | masks 5 | triangles 2 => proc 200.2 ms\n",
      "[68/79] frame_00067.png  read 37.7 | infer 40.6 | to_cpu 1.3 | post 0.0 | masks 7 | triangles 0 => proc 41.9 ms\n",
      "[69/79] frame_00068.png  read 36.5 | infer 41.2 | to_cpu 0.9 | post 95.0 | masks 4 | triangles 1 => proc 137.0 ms\n",
      "[70/79] frame_00069.png  read 38.7 | infer 34.1 | to_cpu 1.5 | post 125.6 | masks 3 | triangles 1 => proc 161.2 ms\n",
      "[71/79] frame_00070.png  read 39.2 | infer 43.3 | to_cpu 1.6 | post 160.4 | masks 2 | triangles 2 => proc 205.2 ms\n",
      "[72/79] frame_00071.png  read 36.1 | infer 34.7 | to_cpu 1.3 | post 154.7 | masks 2 | triangles 2 => proc 190.7 ms\n",
      "[73/79] frame_00072.png  read 37.4 | infer 46.6 | to_cpu 0.9 | post 188.5 | masks 2 | triangles 2 => proc 236.0 ms\n",
      "[74/79] frame_00073.png  read 44.6 | infer 43.7 | to_cpu 0.8 | post 166.0 | masks 2 | triangles 2 => proc 210.5 ms\n",
      "[75/79] frame_00074.png  read 37.9 | infer 42.1 | to_cpu 0.8 | post 170.0 | masks 3 | triangles 2 => proc 212.9 ms\n",
      "[76/79] frame_00075.png  read 27.2 | infer 34.5 | to_cpu 1.0 | post 83.0 | masks 2 | triangles 1 => proc 118.5 ms\n",
      "[77/79] frame_00076.png  read 18.1 | infer 24.9 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 24.9 ms\n",
      "[78/79] frame_00077.png  read 17.5 | infer 24.6 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 24.6 ms\n",
      "[79/79] frame_00078.png  read 17.6 | infer 22.4 | to_cpu 0.0 | post 0.0 | masks 0 | triangles 0 => proc 22.4 ms\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Ultra-fast, batched pipeline with threaded I/O + per-frame timing & counts\n",
    "# Now also renders ALL masks + purple triangles onto ORIGINAL frames for first N=20 (excluded from timings)\n",
    "\n",
    "import os, glob, sys, time\n",
    "import cv2, torch, numpy as np\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# =======================\n",
    "# Config\n",
    "# =======================\n",
    "home       = os.path.expanduser(\"~\")\n",
    "weights    = f\"{home}/models/jakes-loped/jakes-finder-mk1/1/weights.pt\"\n",
    "frames_dir = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"frames\"\n",
    "out_dir    = Path(home) / \"Documents\" / \"GitHub\" / \"Ai-plays-SubwaySurfers\" / \"out_overlays\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAIL_ID    = 9\n",
    "IMG_SIZE   = 512\n",
    "CONF, IOU  = 0.30, 0.45\n",
    "MAX_DET    = 30\n",
    "\n",
    "# Color/region filter\n",
    "TARGET_COLORS_RGB  = [(119,104,67), (81,42,45)]\n",
    "TOLERANCE          = 20.0\n",
    "MIN_REGION_SIZE    = 30\n",
    "MIN_REGION_HEIGHT  = 150\n",
    "\n",
    "# Heat/triangle\n",
    "HEAT_BLUR_KSIZE     = 51\n",
    "RED_SCORE_THRESH    = 220\n",
    "EXCLUDE_TOP_FRAC    = 0.40\n",
    "EXCLUDE_BOTTOM_FRAC = 0.15\n",
    "MIN_DARK_RED_AREA   = 1200\n",
    "MIN_DARK_FRACTION   = 0.15\n",
    "TRI_SIZE_PX         = 18\n",
    "PURPLE              = (255, 0, 255)\n",
    "\n",
    "# Runtime\n",
    "BATCH               = 1\n",
    "THREADS_IO          = max(2, (os.cpu_count() or 4) // 2)\n",
    "SHOW_FIRST_N        = None  # None → all frames\n",
    "RENDER_FIRST_N      = 5    # render overlays for first 20 frames only\n",
    "\n",
    "# =======================\n",
    "# System/Backends\n",
    "# =======================\n",
    "cv2.setUseOptimized(True)\n",
    "try: cv2.setNumThreads(max(1, (os.cpu_count() or 1) - 1))\n",
    "except Exception: pass\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device, half = 0, True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try: torch.set_float32_matmul_precision('high')\n",
    "    except Exception: pass\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    device, half = \"mps\", False\n",
    "else:\n",
    "    device, half = \"cpu\", False\n",
    "\n",
    "# =======================\n",
    "# Model\n",
    "# =======================\n",
    "model = YOLO(weights)\n",
    "try: model.fuse()\n",
    "except Exception: pass\n",
    "\n",
    "# Warmup\n",
    "_dummy = np.zeros((IMG_SIZE, IMG_SIZE, 3), np.uint8)\n",
    "_ = model.predict(_dummy, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "                  conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET)\n",
    "\n",
    "# =======================\n",
    "# Precomputed\n",
    "# =======================\n",
    "TARGETS_BGR_F32 = np.array([(r,g,b)[::-1] for (r,g,b) in TARGET_COLORS_RGB], dtype=np.float32)\n",
    "TOL2            = TOLERANCE * TOLERANCE\n",
    "\n",
    "CLASS_COLOURS = {\n",
    "    0:(255,255,0),1:(192,192,192),2:(0,128,255),3:(0,255,0),\n",
    "    4:(255,0,255),5:(0,255,255),6:(255,128,0),7:(128,0,255),\n",
    "    8:(0,0,128),9:(0,0,255),10:(128,128,0),11:(255,255,102)\n",
    "}\n",
    "LABELS = {\n",
    "    0:\"BOOTS\",1:\"GREYTRAIN\",2:\"HIGHBARRIER1\",3:\"JUMP\",4:\"LOWBARRIER1\",\n",
    "    5:\"LOWBARRIER2\",6:\"ORANGETRAIN\",7:\"PILLAR\",8:\"RAMP\",9:\"RAILS\",\n",
    "    10:\"SIDEWALK\",11:\"YELLOWTRAIN\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# Helpers\n",
    "# =======================\n",
    "def load_image_with_time(path: str):\n",
    "    t0 = time.perf_counter()\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    t1 = time.perf_counter()\n",
    "    return img, (t1 - t0) * 1000.0\n",
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def highlight_rails_mask_only_fast(img_bgr, rail_mask):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    if not rail_mask.any():\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    ys, xs = np.where(rail_mask)\n",
    "    y0, y1 = ys.min(), ys.max()+1\n",
    "    x0, x1 = xs.min(), xs.max()+1\n",
    "\n",
    "    img_roi  = img_bgr[y0:y1, x0:x1]\n",
    "    mask_roi = rail_mask[y0:y1, x0:x1]\n",
    "\n",
    "    img_f = img_roi.astype(np.float32)\n",
    "    diff  = img_f[:, :, None, :] - TARGETS_BGR_F32[None, None, :, :]\n",
    "    dist2 = np.sum(diff * diff, axis=-1)\n",
    "    colour_hit = np.any(dist2 <= TOL2, axis=-1)\n",
    "\n",
    "    combined = np.logical_and(colour_hit, mask_roi)\n",
    "    comp = combined.astype(np.uint8)\n",
    "    n, lbls, stats, _ = cv2.connectedComponentsWithStats(comp, 8)\n",
    "    if n <= 1:\n",
    "        return np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    good = np.zeros_like(combined)\n",
    "    areas  = stats[1:, cv2.CC_STAT_AREA]\n",
    "    hs     = stats[1:, cv2.CC_STAT_HEIGHT]\n",
    "    keep   = np.where((areas >= MIN_REGION_SIZE) & (hs >= MIN_REGION_HEIGHT))[0] + 1\n",
    "    for k in keep:\n",
    "        good[lbls == k] = True\n",
    "\n",
    "    full = np.zeros((H, W), dtype=bool)\n",
    "    full[y0:y1, x0:x1] = good\n",
    "    return full\n",
    "\n",
    "def red_vs_green_score(red_mask, green_mask):\n",
    "    k = (HEAT_BLUR_KSIZE, HEAT_BLUR_KSIZE)\n",
    "    r = cv2.blur(red_mask.astype(np.float32), k)\n",
    "    g = cv2.blur(green_mask.astype(np.float32), k)\n",
    "    diff = r - g\n",
    "    amax = float(np.max(np.abs(diff))) + 1e-6\n",
    "    norm = (diff / (2.0 * amax) + 0.5)\n",
    "    return np.clip(norm * 255.0, 0, 255.0).astype(np.uint8)\n",
    "\n",
    "# Returns: (list_of_triangle_xy, best_xy_or_None)\n",
    "def purple_triangles(score, H):\n",
    "    top_ex = int(H * EXCLUDE_TOP_FRAC)\n",
    "    bot_ex = int(H * EXCLUDE_BOTTOM_FRAC)\n",
    "\n",
    "    dark = (score >= RED_SCORE_THRESH).astype(np.uint8)\n",
    "    if top_ex: dark[:top_ex, :] = 0\n",
    "    if bot_ex: dark[-bot_ex:, :] = 0\n",
    "\n",
    "    dark = cv2.morphologyEx(\n",
    "        dark, cv2.MORPH_OPEN,\n",
    "        cv2.getStructuringElement(cv2.MORPH_RECT, (5, 9)),\n",
    "        iterations=1\n",
    "    )\n",
    "    total_dark = int(dark.sum())\n",
    "    if total_dark == 0:\n",
    "        return [], None\n",
    "\n",
    "    frac_thresh = int(np.ceil(MIN_DARK_FRACTION * total_dark))\n",
    "    n_lbl, lbls, stats, _ = cv2.connectedComponentsWithStats(dark, 8)\n",
    "    if n_lbl <= 1:\n",
    "        return [], None\n",
    "\n",
    "    tris = []\n",
    "    for lbl in range(1, n_lbl):\n",
    "        area = stats[lbl, cv2.CC_STAT_AREA]\n",
    "        if area >= MIN_DARK_RED_AREA and area >= frac_thresh:\n",
    "            ys, xs = np.where(lbls == lbl)\n",
    "            if ys.size == 0: \n",
    "                continue\n",
    "            y_top = ys.min()\n",
    "            x_mid = int(xs[ys == y_top].mean())\n",
    "            tris.append((int(x_mid), int(y_top)))\n",
    "\n",
    "    if not tris:\n",
    "        return [], None\n",
    "\n",
    "    # best is the one with smallest y (closest to top)\n",
    "    best = min(tris, key=lambda xy: xy[1])\n",
    "    return tris, best\n",
    "\n",
    "# Returns: (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions)\n",
    "def process_frame_post(frame_bgr, yolo_res):\n",
    "    H, W = frame_bgr.shape[:2]\n",
    "    if yolo_res.masks is None:\n",
    "        return None, 0, 0, 0.0, 0.0, None, None, None, None, []\n",
    "\n",
    "    t0_to_cpu = time.perf_counter()\n",
    "    masks_np = yolo_res.masks.data.cpu().numpy()  # [n,h,w]\n",
    "    mask_count = int(masks_np.shape[0])\n",
    "    if hasattr(yolo_res.masks, \"cls\") and yolo_res.masks.cls is not None:\n",
    "        classes_np = yolo_res.masks.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        classes_np = yolo_res.boxes.cls.cpu().numpy().astype(int)\n",
    "    t1_to_cpu = time.perf_counter()\n",
    "    to_cpu_ms = (t1_to_cpu - t0_to_cpu) * 1000.0\n",
    "\n",
    "    if mask_count == 0 or classes_np.size == 0:\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, []\n",
    "\n",
    "    rail_sel = (classes_np == RAIL_ID)\n",
    "    if not np.any(rail_sel):\n",
    "        return None, 0, mask_count, to_cpu_ms, 0.0, masks_np, classes_np, None, None, []\n",
    "\n",
    "    t0_post = time.perf_counter()\n",
    "    rail_masks = masks_np[rail_sel].astype(bool)        # [k,h,w]\n",
    "    union = np.any(rail_masks, axis=0).astype(np.uint8) # [h,w]\n",
    "    rail_mask = cv2.resize(union, (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "\n",
    "    green = highlight_rails_mask_only_fast(frame_bgr, rail_mask)\n",
    "    red   = np.logical_and(rail_mask, np.logical_not(green))\n",
    "    score = red_vs_green_score(red, green)\n",
    "    tri_positions, tri_best = purple_triangles(score, H)\n",
    "    t1_post = time.perf_counter()\n",
    "    post_ms = (t1_post - t0_post) * 1000.0\n",
    "\n",
    "    return tri_best, len(tri_positions), mask_count, to_cpu_ms, post_ms, masks_np, classes_np, rail_mask, green, tri_positions\n",
    "\n",
    "# --- rendering (excluded from timing) ---\n",
    "def draw_triangle(img, x, y, size=TRI_SIZE_PX, colour=PURPLE):\n",
    "    h = int(size * 1.2)\n",
    "    pts = np.array([[x, y], [x-size, y+h], [x+size, y+h]], np.int32)\n",
    "    cv2.fillConvexPoly(img, pts, colour)\n",
    "    cv2.polylines(img, [pts.reshape(-1,1,2)], True, (0,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "def render_overlays(frame_bgr, masks_np, classes_np, rail_mask, green_mask, tri_positions):\n",
    "    \"\"\"Draw all masks (class color) + labels, rail tint/green, and purple triangles on a copy of original frame.\"\"\"\n",
    "    out = frame_bgr.copy()\n",
    "    H, W = out.shape[:2]\n",
    "    alpha = 0.45\n",
    "\n",
    "    if masks_np is not None and classes_np is not None and masks_np.size:\n",
    "        # upsample masks to frame res only once per mask\n",
    "        for m, c in zip(masks_np, classes_np):\n",
    "            m_full = m\n",
    "            if m.shape != (H, W):\n",
    "                m_full = cv2.resize(m.astype(np.uint8), (W, H), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "            color = CLASS_COLOURS.get(int(c), (255,255,255))\n",
    "            # overlay\n",
    "            out[m_full] = (np.array(color, dtype=np.uint8) * alpha + out[m_full] * (1 - alpha)).astype(np.uint8)\n",
    "            # label near centroid\n",
    "            ys, xs = np.where(m_full)\n",
    "            if xs.size:\n",
    "                xc, yc = int(xs.mean()), int(ys.mean())\n",
    "                label = LABELS.get(int(c), f\"C{int(c)}\")\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "                cv2.putText(out, label, (max(5, xc-40), max(20, yc)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Rail tint + green highlight (if available)\n",
    "    if rail_mask is not None:\n",
    "        tint = out.copy()\n",
    "        tint[rail_mask] = (0, 0, 255)  # red tint for rails\n",
    "        out = cv2.addWeighted(tint, 0.30, out, 0.70, 0)\n",
    "    if green_mask is not None:\n",
    "        out[green_mask] = (0, 255, 0)\n",
    "\n",
    "    # Draw ALL purple triangles we found\n",
    "    for (x, y) in tri_positions:\n",
    "        draw_triangle(out, x, y)\n",
    "\n",
    "    return out\n",
    "\n",
    "# =======================\n",
    "# Batched execution with prints; overlays saved for first N\n",
    "# =======================\n",
    "def run_pipeline_with_prints_and_overlays():\n",
    "    paths = (\n",
    "        glob.glob(str(frames_dir/\"frame_*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"frame_*.png\")) +\n",
    "        glob.glob(str(frames_dir/\"*.jpg\")) +\n",
    "        glob.glob(str(frames_dir/\"*.png\"))\n",
    "    )\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No images in: {frames_dir}\")\n",
    "    if SHOW_FIRST_N is not None:\n",
    "        paths = paths[:SHOW_FIRST_N]\n",
    "\n",
    "    N = len(paths)\n",
    "    results_triangle_xy = [None] * N\n",
    "\n",
    "    def load_batch(batch_paths):\n",
    "        imgs = [None] * len(batch_paths)\n",
    "        read_ms = [0.0] * len(batch_paths)\n",
    "        with ThreadPoolExecutor(max_workers=THREADS_IO) as ex:\n",
    "            fut2idx = {ex.submit(load_image_with_time, p): i for i, p in enumerate(batch_paths)}\n",
    "            for fut in as_completed(fut2idx):\n",
    "                i = fut2idx[fut]\n",
    "                img, r_ms = fut.result()\n",
    "                imgs[i] = img\n",
    "                read_ms[i] = r_ms\n",
    "        ok = [(p, im, rm) for p, im, rm in zip(batch_paths, imgs, read_ms) if im is not None]\n",
    "        if not ok:\n",
    "            return [], [], []\n",
    "        b_paths, b_imgs, b_read = zip(*ok)\n",
    "        return list(b_paths), list(b_imgs), list(b_read)\n",
    "\n",
    "    idx_global = 0\n",
    "    for batch_paths in chunked(paths, BATCH):\n",
    "        batch_paths, imgs_bgr, read_ms_list = load_batch(batch_paths)\n",
    "        B = len(imgs_bgr)\n",
    "        if B == 0:\n",
    "            idx_global += len(batch_paths)\n",
    "            continue\n",
    "\n",
    "        t0_inf = time.perf_counter()\n",
    "        res_list = model.predict(\n",
    "            imgs_bgr, task=\"segment\", imgsz=IMG_SIZE, device=device,\n",
    "            conf=CONF, iou=IOU, verbose=False, half=half, max_det=MAX_DET,\n",
    "            batch=B\n",
    "        )\n",
    "        try:\n",
    "            if device == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            elif device == \"mps\" and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "                torch.mps.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "        t1_inf = time.perf_counter()\n",
    "        infer_ms_share = ((t1_inf - t0_inf) * 1000.0) / B\n",
    "\n",
    "        for j, (img, yres, read_ms) in enumerate(zip(imgs_bgr, res_list, read_ms_list)):\n",
    "            (tri_best_xy, tri_count, mask_count, to_cpu_ms, post_ms,\n",
    "             masks_np, classes_np, rail_mask, green_mask, tri_positions) = process_frame_post(img, yres)\n",
    "\n",
    "            results_triangle_xy[idx_global + j] = tri_best_xy\n",
    "            proc_ms = infer_ms_share + to_cpu_ms + post_ms\n",
    "            fname = os.path.basename(batch_paths[j])\n",
    "            frame_idx = idx_global + j + 1\n",
    "\n",
    "            # Timing/diagnostic print (no rendering time included)\n",
    "            print(f\"[{frame_idx}/{N}] {fname}  \"\n",
    "                  f\"read {read_ms:.1f} | infer {infer_ms_share:.1f} | \"\n",
    "                  f\"to_cpu {to_cpu_ms:.1f} | post {post_ms:.1f} | \"\n",
    "                  f\"masks {mask_count} | triangles {tri_count} \"\n",
    "                  f\"=> proc {proc_ms:.1f} ms\")\n",
    "\n",
    "            # --- RENDERING (EXCLUDED from timing) ---\n",
    "            if frame_idx <= RENDER_FIRST_N:\n",
    "                overlay = render_overlays(img, masks_np, classes_np, rail_mask, green_mask, tri_positions)\n",
    "                out_path = out_dir / f\"overlay_{frame_idx:04d}_{fname}\"\n",
    "                cv2.imwrite(str(out_path), overlay)\n",
    "\n",
    "        idx_global += B\n",
    "\n",
    "    return results_triangle_xy\n",
    "\n",
    "# =======================\n",
    "# Entry\n",
    "# =======================\n",
    "if __name__ == \"__main__\":\n",
    "    _ = run_pipeline_with_prints_and_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bdef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
